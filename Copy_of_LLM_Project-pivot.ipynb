{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keVc9VWJI9ZI"
      },
      "source": [
        "Project Phase 1: Stepwise API Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUmbb9KsIaRL"
      },
      "source": [
        "Step 1: Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2IWghs9QZVy"
      },
      "outputs": [],
      "source": [
        "!pip install -q requests pandas streamlit pyngrok faiss-cpu sentence-transformers numpy\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUskaUMVEYsn",
        "outputId": "d3cd427f-c71c-44dc-f6bc-c8dbf8849638"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnfATz0x1DYc",
        "outputId": "7d3237f3-92ea-4579-c6d7-ad851f0a6c12"
      },
      "outputs": [],
      "source": [
        "# Secure KEY INPUT\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# Securely Capture Key\n",
        "# Input will be invisible. Paste key and press Enter.\n",
        "key_input = getpass.getpass(\"üîë Enter Gemini API Key (Invisible Input): \")\n",
        "\n",
        "if not key_input.startswith(\"AIza\"):\n",
        "    print(\"‚ö†Ô∏è Warning: Key might be invalid (usually starts with 'AIza').\")\n",
        "else:\n",
        "    print(\"‚úÖ API Key captured securely in Environment Variable.\")\n",
        "\n",
        "# 2. Set as Environment Variable for the Session\n",
        "os.environ[\"GEMINI_API_KEY\"] = key_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mwEwzAoPHlB",
        "outputId": "f47699a6-9674-4dc1-932a-38fa4de98108"
      },
      "outputs": [],
      "source": [
        "%%writefile build_embeddings.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "import json\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# === REAL PATH (from readlink) ===\n",
        "BASE = \"/content/drive/MyDrive/LLM_Based_GenAI_Sem1/data/\"\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Load Data\n",
        "# ---------------------------------------------\n",
        "df = pd.read_csv(f\"{BASE}/clinical_trials_diabetes_full.csv\")\n",
        "\n",
        "df[\"status\"] = df[\"status\"].astype(str).str.strip().str.title()\n",
        "bad_status = [\"Terminated\", \"Withdrawn\", \"Suspended\", \"No Longer Available\", \"Unknown\"]\n",
        "df_clean = df[~df[\"status\"].isin(bad_status)].copy()\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Chunking\n",
        "# ---------------------------------------------\n",
        "chunks = []\n",
        "chunk_map = []\n",
        "\n",
        "for idx, row in df_clean.iterrows():\n",
        "    title = str(row.get(\"brief_title\", \"\")).strip()\n",
        "    summary = str(row.get(\"brief_summary\", \"\")).strip()\n",
        "\n",
        "    if len(summary) < 20:\n",
        "        continue\n",
        "\n",
        "    text = f\"Title: {title}\\nSummary: {summary}\"\n",
        "    chunks.append(text)\n",
        "\n",
        "    chunk_map.append({\n",
        "        \"nct_id\": row[\"nct_id\"],\n",
        "        \"title\": title,\n",
        "        \"text\": text,\n",
        "        \"status\": row[\"status\"]\n",
        "    })\n",
        "\n",
        "print(f\"Created {len(chunks)} chunks.\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Embeddings\n",
        "# ---------------------------------------------\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = embed_model.encode(chunks, batch_size=64, show_progress_bar=True)\n",
        "\n",
        "np.save(f\"{BASE}/clinical_trials_diabetes_full_embeddings.npy\", embeddings)\n",
        "print(\"Saved clinical_trials_diabetes_full_embeddings.npy\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Save chunk map\n",
        "# ---------------------------------------------\n",
        "with open(f\"{BASE}/clinical_trials_diabetes_full_chunk_map.json\", \"w\") as f:\n",
        "    json.dump(chunk_map, f)\n",
        "\n",
        "print(\"Saved clinical_trials_diabetes_full_chunk_map.json\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Build & Save FAISS\n",
        "# ---------------------------------------------\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(embeddings).astype(\"float32\"))\n",
        "faiss.write_index(index, f\"{BASE}/clinical_trials_diabetes_full_faiss.index\")\n",
        "\n",
        "print(\"Saved clinical_trials_diabetes_full_faiss.index\")\n",
        "print(\"‚úÖ Embedding build COMPLETE.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32A5yZO0V4VT",
        "outputId": "a2d7d343-6017-45d7-86f5-36a8886bc9fa"
      },
      "outputs": [],
      "source": [
        "!python build_embeddings.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PXqvXLkXaX7",
        "outputId": "27efcd94-9a4b-438f-d2a2-0d511b77a02a"
      },
      "outputs": [],
      "source": [
        "%%writefile utils.py\n",
        "import json\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# --- Confidence score from distance ---\n",
        "\n",
        "def calculate_confidence_score(distance: float, normalization_factor: float = 1.0) -> float:\n",
        "    \"\"\"Inverse L2 distance score in (0,1]; closer = higher confidence.\"\"\"\n",
        "    return normalization_factor / (normalization_factor + float(distance))\n",
        "\n",
        "\n",
        "# --- Load pre-built index + chunk map ---\n",
        "\n",
        "def load_data_and_index(chunk_map_path: str, faiss_path: str):\n",
        "    \"\"\"Loads pre-built chunks and FAISS index for quick startup.\"\"\"\n",
        "    print(\"‚è≥ Loading pre-built RAG index...\")\n",
        "\n",
        "    with open(chunk_map_path, \"r\") as f:\n",
        "        chunk_map = json.load(f)\n",
        "\n",
        "    index = faiss.read_index(faiss_path)\n",
        "\n",
        "    embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    print(f\"‚úÖ RAG Index Ready: {index.ntotal} vectors loaded.\")\n",
        "    return embed_model, index, chunk_map\n",
        "\n",
        "\n",
        "# --- Provenance logging ---\n",
        "\n",
        "def log_provenance_step(agent_name: str, input_data, output_data, detail=None):\n",
        "    \"\"\"\n",
        "    Creates a detailed log entry for a single agent step.\n",
        "    \"\"\"\n",
        "    log_entry = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"agent\": agent_name,\n",
        "        \"input\": input_data,\n",
        "        \"output\": output_data,\n",
        "        \"detail\": detail or {},\n",
        "        \"model_version\": \"gemini-2.0-flash\",\n",
        "    }\n",
        "    return log_entry\n",
        "\n",
        "\n",
        "# --- Reproducibility hash ---\n",
        "\n",
        "def generate_reproducibility_hash(conversation_history, corpus_version: str = \"v1.0\"):\n",
        "    \"\"\"\n",
        "    Generates a deterministic session hash based on the conversation history.\n",
        "    \"\"\"\n",
        "    queries = [turn.get(\"query\", \"\") for turn in conversation_history]\n",
        "    raw = f\"{corpus_version}|{'|'.join(queries)}\"\n",
        "    return hashlib.md5(raw.encode(\"utf-8\")).hexdigest()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLn6JKXmMFog",
        "outputId": "1b141877-4fae-40c0-a504-8fbd1f38636e"
      },
      "outputs": [],
      "source": [
        "%%writefile run_bot.py\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "\n",
        "# --- Updated Import: Robust Cross-Encoder Initialization ---\n",
        "CrossEncoder = None\n",
        "try:\n",
        "    from sentence_transformers import CrossEncoder\n",
        "    print(\"‚úÖ sentence_transformers imported successfully.\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è sentence_transformers not found. Reranking will be disabled.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error importing CrossEncoder: {e}. Reranking disabled.\")\n",
        "\n",
        "from utils import (\n",
        "    load_data_and_index,\n",
        "    log_provenance_step,\n",
        "    generate_reproducibility_hash,\n",
        "    calculate_confidence_score,\n",
        ")\n",
        "\n",
        "\n",
        "# --- NEW CONFIG (SECURE & 2.0 MODEL) ---\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not API_KEY:\n",
        "    print(\"‚ùå ERROR: API Key not found. Please run the 'Secure Input' cell first.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "# Using the Experimental 2.0 Flash endpoint\n",
        "gemini_model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "CHUNK_PATH = \"/content/drive/MyDrive/LLM_Based_GenAI_Sem1/data/clinical_trials_diabetes_full_chunk_map.json\"\n",
        "FAISS_PATH = \"/content/drive/MyDrive/LLM_Based_GenAI_Sem1/data/clinical_trials_diabetes_full_faiss.index\"\n",
        "\n",
        "# Load embedding model, FAISS index, and chunk metadata\n",
        "embed_model, faiss_index, chunk_map = load_data_and_index(CHUNK_PATH, FAISS_PATH)\n",
        "\n",
        "# --- NEW: Reranker Initialization ---\n",
        "reranker = None\n",
        "if CrossEncoder:\n",
        "    try:\n",
        "        print(\"‚è≥ Loading Reranker Model (Cross-Encoder)...\")\n",
        "        # High precision reranker\n",
        "        reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "        print(\"‚úÖ Reranker Loaded.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Reranker model download failed (using pure FAISS): {e}\")\n",
        "\n",
        "\n",
        "# --- NEW PARSER (UPDATED) ---\n",
        "\n",
        "class SymptomParser:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def parse(self, text: str):\n",
        "        \"\"\"\n",
        "        Enhanced parser for clinical trial search queries\n",
        "        \"\"\"\n",
        "        prompt = (\n",
        "            \"You are a clinical trial search classifier for diabetes research.\\n\"\n",
        "            \"Your job is to determine if the user wants to SEARCH for trials or just learn about diabetes.\\n\\n\"\n",
        "\n",
        "            f'User Input: \"{text}\"\\n\\n'\n",
        "\n",
        "            \"Classification Rules:\\n\"\n",
        "            \"1. If query contains 'trial', 'study', 'research', 'clinical', or asks 'what trials', 'show me trials', 'are there trials' ‚Üí intent='trial_search'\\n\"\n",
        "            \"2. If user states personal info like age, conditions, medications ‚Üí intent='profile_info'\\n\"\n",
        "            \"3. If asking general education questions like 'what is X?', 'how does Y work?' (WITHOUT asking about trials) ‚Üí intent='general_question'\\n\"\n",
        "            \"4. Simple greetings ‚Üí intent='greeting'\\n\"\n",
        "            \"5. Not about diabetes ‚Üí intent='off_topic'\\n\\n\"\n",
        "\n",
        "            \"Return ONLY valid JSON:\\n\"\n",
        "            \"{\\n\"\n",
        "            '  \"intent\": \"trial_search\" | \"profile_info\" | \"general_question\" | \"greeting\" | \"off_topic\",\\n'\n",
        "            '  \"query_type\": \"trial_query\" | \"profile_statement\" | \"knowledge_seeking\" | \"greeting\",\\n'\n",
        "            '  \"search_keywords\": [\"keyword1\", \"keyword2\"],  // Extract main search terms\\n'\n",
        "            '  \"is_diabetes_related\": true/false,\\n'\n",
        "            '  \"user_question\": \"the question in plain English\",\\n'\n",
        "            '  \"trial_interest\": \"what type of trial they want (diet, medication, technology, etc.)\"\\n'\n",
        "            \"}\\n\\n\"\n",
        "\n",
        "            \"Examples:\\n\"\n",
        "            '- \"What trials study liraglutide?\" ‚Üí intent=\"trial_search\", search_keywords=[\"liraglutide\"]\\n'\n",
        "            '- \"I\\'m 55 with diabetes\" ‚Üí intent=\"profile_info\"\\n'\n",
        "            '- \"What is HbA1c?\" ‚Üí intent=\"general_question\"\\n'\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            raw = (res.text or \"\").strip()\n",
        "            match = re.search(r\"\\{.*\\}\", raw, re.DOTALL)\n",
        "            if match:\n",
        "                parsed = json.loads(match.group(0))\n",
        "            else:\n",
        "                parsed = json.loads(raw)\n",
        "\n",
        "            # Force trial_search if keywords present\n",
        "            text_lower = text.lower()\n",
        "            trial_keywords = ['trial', 'study', 'studies', 'research', 'clinical', 'show me', 'are there', 'what trials']\n",
        "            if any(kw in text_lower for kw in trial_keywords):\n",
        "                parsed[\"intent\"] = \"trial_search\"\n",
        "                parsed[\"query_type\"] = \"trial_query\"\n",
        "\n",
        "        except Exception as e:\n",
        "            # Fallback with keyword detection\n",
        "            text_lower = text.lower()\n",
        "            if any(kw in text_lower for kw in ['trial', 'study', 'research']):\n",
        "                parsed = {\n",
        "                    \"intent\": \"trial_search\",\n",
        "                    \"query_type\": \"trial_query\",\n",
        "                    \"search_keywords\": [text],\n",
        "                    \"is_diabetes_related\": True,\n",
        "                    \"user_question\": text,\n",
        "                    \"trial_interest\": \"general\"\n",
        "                }\n",
        "            else:\n",
        "                parsed = {\n",
        "                    \"intent\": \"general_question\",\n",
        "                    \"query_type\": \"knowledge_seeking\",\n",
        "                    \"search_keywords\": [],\n",
        "                    \"is_diabetes_related\": True,\n",
        "                    \"user_question\": text,\n",
        "                    \"trial_interest\": None\n",
        "                }\n",
        "\n",
        "        log = log_provenance_step(\"SymptomParser\", text, parsed)\n",
        "        return parsed, log\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- NEW PROFILE AGENT (STATEFUL) ---\n",
        "class ProfileAgent:\n",
        "    def __init__(self, initial_profile: Dict[str, Any] = None):\n",
        "        if initial_profile is None:\n",
        "            initial_profile = {\n",
        "                \"user_id\": \"Patient\",\n",
        "                \"conditions\": [\"diabetes\"], # Default context\n",
        "                \"extracted_conditions\": [], # Dynamic memory\n",
        "                \"history\": [],\n",
        "            }\n",
        "        self.profile = initial_profile\n",
        "\n",
        "    def update_profile(self, turn_data: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Updates history and extracts persistent medical entities.\n",
        "        \"\"\"\n",
        "        self.profile.setdefault(\"history\", []).append(turn_data)\n",
        "        self.profile.setdefault(\"extracted_conditions\", [])\n",
        "\n",
        "        # Heuristic: Add new symptoms found in this turn to the persistent profile\n",
        "        parsed = turn_data.get(\"parsed\", {})\n",
        "        new_symptoms = parsed.get(\"symptoms\", [])\n",
        "\n",
        "        if new_symptoms:\n",
        "            current_conditions = set(self.profile[\"extracted_conditions\"])\n",
        "            for sym in new_symptoms:\n",
        "                if sym and len(sym) > 3: # Avoid noise\n",
        "                    current_conditions.add(sym.lower())\n",
        "            self.profile[\"extracted_conditions\"] = list(current_conditions)\n",
        "\n",
        "        snapshot = {\n",
        "            \"user_id\": self.profile.get(\"user_id\", \"Patient\"),\n",
        "            \"known_conditions\": self.profile.get(\"extracted_conditions\", []),\n",
        "            \"num_turns\": len(self.profile[\"history\"]),\n",
        "        }\n",
        "        log = log_provenance_step(\"ProfileAgent\", turn_data, {\"profile_snapshot\": snapshot})\n",
        "        return log\n",
        "\n",
        "\n",
        "# --- NEW RETRIEVAL AGENT (RERANKING) ---\n",
        "class RetrievalAgent:\n",
        "    def __init__(self, embed_model, faiss_index, chunk_map, profile_agent: ProfileAgent = None):\n",
        "        self.embed_model = embed_model\n",
        "        self.index = faiss_index\n",
        "        self.chunk_map = chunk_map\n",
        "        self.profile_agent = profile_agent\n",
        "\n",
        "    def retrieve(self, parsed: Dict[str, Any], top_k: int = 5):\n",
        "        # Fetch 3x candidates for reranking\n",
        "        FETCH_K = top_k * 3\n",
        "\n",
        "\n",
        "        symptoms = parsed.get(\"symptoms\") or []\n",
        "        context = parsed.get(\"context\") or \"\"\n",
        "        # user_question usually captures the intent best\n",
        "        query = parsed.get(\"user_question\") or (\" \".join(symptoms) + \" \" + context).strip()\n",
        "\n",
        "        if not query:\n",
        "            retrieval = {\"query\": \"\", \"trials\": [], \"avg_confidence\": 0.0}\n",
        "            log = log_provenance_step(\"RetrievalAgent\", parsed, retrieval, {\"reason\": \"empty_query\"})\n",
        "            return retrieval, log\n",
        "\n",
        "\n",
        "        EXPANSIONS = {\n",
        "            \"insulin\": \"insulin OR insulin therapy OR insulin treatment OR insulin pump\",\n",
        "            \"medication\": \"medication OR drug OR pharmaceutical OR pharmacological OR treatment\",\n",
        "            \"diet\": \"diet OR dietary OR nutrition OR nutritional OR eating\",\n",
        "            \"exercise\": \"exercise OR physical activity OR fitness OR activity\",\n",
        "            \"new\": \"medication OR drug OR pharmacological OR treatment OR therapy OR intervention\",  # Changed!\n",
        "        }\n",
        "\n",
        "\n",
        "        query_lower = query.lower()\n",
        "        for term, expansion in EXPANSIONS.items():\n",
        "            if term in query_lower:\n",
        "                query = f\"{query} {expansion}\"\n",
        "                break  # Only expand once\n",
        "\n",
        "        # 1. FAISS Retrieval (Fast/Dense)\n",
        "        q_emb = self.embed_model.encode([query])\n",
        "        distances, indices = self.index.search(q_emb.astype(\"float32\"), FETCH_K)\n",
        "\n",
        "        initial_candidates = []\n",
        "        for rank, idx in enumerate(indices[0]):\n",
        "            if idx == -1: continue\n",
        "            item = self.chunk_map[idx]\n",
        "            dist = float(distances[0][rank])\n",
        "            initial_candidates.append({\n",
        "                \"nct_id\": item[\"nct_id\"],\n",
        "                \"text\": item[\"text\"],\n",
        "                \"status\": item[\"status\"],\n",
        "                \"faiss_dist\": dist,\n",
        "            })\n",
        "\n",
        "        # 2. Reranking (Cross-Encoder)\n",
        "        final_trials = []\n",
        "        confs = []\n",
        "\n",
        "        if reranker and initial_candidates:\n",
        "            # Score (Query, Doc) pairs\n",
        "            pairs = [[query, cand[\"text\"]] for cand in initial_candidates]\n",
        "            scores = reranker.predict(pairs)\n",
        "\n",
        "            # Attach scores\n",
        "            for i, cand in enumerate(initial_candidates):\n",
        "                cand[\"rerank_score\"] = float(scores[i])\n",
        "\n",
        "            # Sort by rerank score (descending)\n",
        "            initial_candidates.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
        "\n",
        "            # Take top_k\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                # Sigmoid normalization for confidence\n",
        "                logit = item[\"rerank_score\"]\n",
        "                conf = 1 / (1 + np.exp(-logit))\n",
        "                confs.append(conf)\n",
        "\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"text\"].split(\"\\n\")[0].replace(\"Title: \", \"\"),\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": conf,\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"reranked\"\n",
        "                })\n",
        "        else:\n",
        "            # Fallback if reranker is not loaded\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                conf = calculate_confidence_score(item[\"faiss_dist\"])\n",
        "                confs.append(conf)\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"text\"].split(\"\\n\")[0].replace(\"Title: \", \"\"),\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": conf,\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"faiss_only\"\n",
        "                })\n",
        "\n",
        "        avg_conf = float(np.mean(confs)) if confs else 0.0\n",
        "\n",
        "        retrieval = {\n",
        "            \"query\": query,\n",
        "            \"trials\": final_trials,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "        }\n",
        "\n",
        "        detail = {\n",
        "            \"top_k\": top_k,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"num_trials\": len(final_trials),\n",
        "            \"method\": \"reranked\" if reranker else \"faiss_only\"\n",
        "        }\n",
        "\n",
        "        log = log_provenance_step(\"RetrievalAgent\", parsed, retrieval, detail)\n",
        "        return retrieval, log\n",
        "\n",
        "\n",
        "# --- NEW DIAGNOSIS ADVISOR (CONTEXT AWARE) ---\n",
        "class DiagnosisAdvisor:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def _handle_general_question(self, parsed: Dict[str, Any], retrieved: Dict[str, Any]):\n",
        "        \"\"\"Handle general knowledge questions about diabetes\"\"\"\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        user_question = parsed.get(\"user_question\") or \" \".join(parsed.get(\"symptoms\", []))\n",
        "\n",
        "        # Build evidence context (top 3 trials)\n",
        "        evidence_parts = []\n",
        "        for t in trials[:3]:\n",
        "            evidence_parts.append(f\"Trial {t['nct_id']}: {t['text'][:400]}\")\n",
        "        evidence = \"\\n\\n\".join(evidence_parts) if evidence_parts else \"No specific trials available.\"\n",
        "\n",
        "        prompt = (\n",
        "            \"You are a diabetes health educator. Answer the user's question clearly using your medical knowledge.\\n\"\n",
        "            \"The clinical trial evidence below provides real-world context - mention it if relevant.\\n\\n\"\n",
        "            f\"USER'S QUESTION: {user_question}\\n\\n\"\n",
        "            \"CLINICAL TRIAL CONTEXT (for reference):\\n\"\n",
        "            f\"{evidence}\\n\\n\"\n",
        "            \"Instructions:\\n\"\n",
        "            \"- Answer the question directly in 3-5 sentences\\n\"\n",
        "            \"- Be specific and educational\\n\"\n",
        "            \"- If trials mention relevant findings, cite them briefly\\n\"\n",
        "            \"- End with: 'For personalized advice, please consult your healthcare provider.'\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            text = (res.text or \"\").strip()\n",
        "            if not text or len(text) < 50:\n",
        "                text = \"I don't have enough information to answer this question accurately. Please consult your healthcare provider.\"\n",
        "            return text\n",
        "        except Exception:\n",
        "            return \"Unable to generate an answer at this time. Please try rephrasing your question.\"\n",
        "\n",
        "\n",
        "    def _handle_symptom_query(self, parsed: Dict[str, Any], retrieved: Dict[str, Any], profile: Dict[str, Any]):\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        user_input = parsed.get(\"user_question\", \"\")\n",
        "\n",
        "        # Build trial listings with more details\n",
        "        trial_listings = []\n",
        "        for t in trials[:5]:\n",
        "            # Extract just the title from the text\n",
        "            title_line = t['text'].split('\\n')[0].replace('Title: ', '')\n",
        "\n",
        "            trial_listings.append(\n",
        "                f\"**{t['nct_id']}** (Confidence: {t['confidence']:.0%})\\n\"\n",
        "                f\"   {title_line}\\n\"\n",
        "                f\"   Status: {t.get('status', 'Unknown')}\"\n",
        "            )\n",
        "\n",
        "        trials_text = \"\\n\\n\".join(trial_listings)\n",
        "\n",
        "        prompt = (\n",
        "            \"You are a clinical trial research assistant.\\n\"\n",
        "            \"The user is searching for diabetes clinical trials.\\n\\n\"\n",
        "            f\"USER'S SEARCH: {user_input}\\n\\n\"\n",
        "            \"RELEVANT CLINICAL TRIALS FROM DATABASE:\\n\"\n",
        "            f\"{trials_text}\\n\\n\"\n",
        "            \"Instructions:\\n\"\n",
        "            \"1. Start with: 'I found [N] relevant diabetes clinical trials:'\\n\"\n",
        "            \"2. Briefly describe what each trial studies (1 sentence per trial)\\n\"\n",
        "            \"3. Use the NCT ID in your descriptions\\n\"\n",
        "            \"4. End with: 'To learn more about any trial, visit clinicaltrials.gov and search for the NCT ID. Discuss with your healthcare provider before participating.'\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            text = (res.text or \"\").strip()\n",
        "            if not text or len(text) < 50:\n",
        "                text = f\"I found {len(trials)} trials in our database. Here are the details:\\n\\n{trials_text}\\n\\nPlease consult your healthcare provider.\"\n",
        "            return text\n",
        "        except Exception:\n",
        "            return f\"I found {len(trials)} trials:\\n\\n{trials_text}\\n\\nPlease consult your healthcare provider.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def advise(self, parsed: Dict[str, Any], retrieved: Dict[str, Any], profile: Dict[str, Any]):\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        avg_conf = retrieved.get(\"avg_confidence\", 0.0)\n",
        "        query_type = parsed.get(\"query_type\", \"symptom_matching\")\n",
        "        is_diabetes_related = parsed.get(\"is_diabetes_related\", True)\n",
        "\n",
        "        draft = {\n",
        "            \"recommendation\": \"\",\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"query_type\": query_type,\n",
        "        }\n",
        "\n",
        "        # Handle off-topic queries\n",
        "        if not is_diabetes_related:\n",
        "            draft[\"recommendation\"] = (\n",
        "                \"I'm specialized in diabetes-related clinical trials. Your query appears to be \"\n",
        "                \"about symptoms or conditions not directly related to diabetes. \"\n",
        "                \"If you have diabetes-related questions or symptoms (like high blood sugar, \"\n",
        "                \"insulin management, complications, etc.), I'd be happy to help! \"\n",
        "                \"Otherwise, please consult your healthcare provider for your current symptoms.\"\n",
        "            )\n",
        "            draft[\"confidence_veto\"] = True\n",
        "            log = log_provenance_step(\"DiagnosisAdvisor\", parsed, draft, {\"veto\": True, \"reason\": \"off_topic\"})\n",
        "            return draft, log\n",
        "\n",
        "        # Handle low confidence\n",
        "        if not trials or avg_conf < 0.05:\n",
        "            draft[\"recommendation\"] = (\n",
        "                \"EVIDENCE IS INSUFFICIENT TO ANSWER THIS QUESTION DIRECTLY based on the \"\n",
        "                \"retrieved clinical trials. Please consult your healthcare provider.\"\n",
        "            )\n",
        "            draft[\"confidence_veto\"] = True\n",
        "            log = log_provenance_step(\"DiagnosisAdvisor\", parsed, draft, {\"veto\": True, \"reason\": \"low_confidence\"})\n",
        "            return draft, log\n",
        "\n",
        "        # Route to appropriate handler\n",
        "        if query_type == \"knowledge_seeking\":\n",
        "            draft[\"recommendation\"] = self._handle_general_question(parsed, retrieved)\n",
        "        else:\n",
        "            draft[\"recommendation\"] = self._handle_symptom_query(parsed, retrieved, profile)\n",
        "\n",
        "        draft[\"confidence_veto\"] = False\n",
        "\n",
        "        log = log_provenance_step(\"DiagnosisAdvisor\", parsed, draft)\n",
        "        return draft, log\n",
        "\n",
        "\n",
        "# --- NEW SAFETY FILTER (UNCHANGED BUT RE-DECLARED) ---\n",
        "\n",
        "class ActiveSafetyFilter:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.safety_cfg = {\n",
        "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "        }\n",
        "\n",
        "    def verify(self, advice_text: str, trials: List[Dict[str, Any]]):\n",
        "        # NEW: Skip safety check for trial listing responses\n",
        "        # Safety filter should only check MEDICAL ADVICE, not trial summaries\n",
        "\n",
        "        # Detect if this is just listing trials (safe by design)\n",
        "        if any(marker in advice_text for marker in [\"NCT\", \"clinical trial\", \"Please discuss these findings\"]):\n",
        "            # This is a trial listing, not medical advice - safe by default\n",
        "            log = log_provenance_step(\n",
        "                \"ActiveSafetyFilter\",\n",
        "                {\"advice\": advice_text},\n",
        "                {\"final_text\": advice_text, \"status\": \"Pass (Trial Listing)\"},\n",
        "            )\n",
        "            return advice_text, \"Pass (Trial Listing)\", log\n",
        "\n",
        "        # Otherwise, run full safety check for actual medical advice\n",
        "        evidence_text = \"\\n\".join(t[\"text\"][:500] for t in trials[:3])  # Limit length\n",
        "\n",
        "        audit_prompt = (\n",
        "            \"You are a Medical Safety Officer reviewing AI-generated advice.\\n\\n\"\n",
        "            \"ADVICE:\\n\"\n",
        "            f\"{advice_text}\\n\\n\"\n",
        "            \"EVIDENCE FROM CLINICAL TRIALS:\\n\"\n",
        "            f\"{evidence_text}\\n\\n\"\n",
        "            \"Check for safety issues:\\n\"\n",
        "            \"- If the advice suggests stopping or changing medication without a doctor ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it gives a diagnosis ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it makes claims not supported by the evidence ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it just lists clinical trials with disclaimers ‚Üí SAFE.\\n\\n\"\n",
        "            'If the advice is acceptable, respond with exactly: SAFE\\n'\n",
        "            'If it is not acceptable, respond starting with: CORRECTED: <safer version>\\n'\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(audit_prompt, safety_settings=self.safety_cfg)\n",
        "            txt = (res.text or \"\").strip()\n",
        "            if txt.startswith(\"SAFE\") or \"SAFE\" in txt:\n",
        "                final_text = advice_text\n",
        "                status = \"Pass\"\n",
        "            else:\n",
        "                final_text = f\"‚ö†Ô∏è SAFETY REVISION:\\n{txt}\"\n",
        "                status = \"Revised\"\n",
        "        except Exception as e:\n",
        "            # Fallback: If safety API fails, check if it's trial listing\n",
        "            if \"NCT\" in advice_text or \"clinical trial\" in advice_text.lower():\n",
        "                final_text = advice_text  # Trial listings are safe\n",
        "                status = \"Pass (API Fallback)\"\n",
        "            else:\n",
        "                final_text = \"‚ö†Ô∏è Safety filter triggered. Please consult a doctor.\"\n",
        "                status = \"Revised (API Error)\"\n",
        "\n",
        "        log = log_provenance_step(\n",
        "            \"ActiveSafetyFilter\",\n",
        "            {\"advice\": advice_text},\n",
        "            {\"final_text\": final_text, \"status\": status},\n",
        "        )\n",
        "        return final_text, status, log\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# HEALTHCARE BOT (Orchestrator)\n",
        "# ============================================================\n",
        "\n",
        "# --- NEW BOT (ORCHESTRATOR) ---\n",
        "class HealthcareBot:\n",
        "    def __init__(self, gemini_model, embed_model, faiss_index, chunk_map, initial_profile=None):\n",
        "        self.parser = SymptomParser(gemini_model)\n",
        "        self.profile_agent = ProfileAgent(initial_profile)\n",
        "        self.retriever = RetrievalAgent(embed_model, faiss_index, chunk_map, self.profile_agent)\n",
        "        self.advisor = DiagnosisAdvisor(gemini_model)\n",
        "        self.safety = ActiveSafetyFilter(gemini_model)\n",
        "\n",
        "        self.history: List[Dict[str, Any]] = []\n",
        "        self.provenance_chain: List[Dict[str, Any]] = []\n",
        "\n",
        "\n",
        "    def _handle_simple_greeting(self, user_input: str):\n",
        "        user_id = self.profile_agent.profile.get(\"user_id\", \"there\")\n",
        "        msg = (\n",
        "            f\"Hello {user_id}! I'm your **Clinical Trial Research Assistant** for diabetes. üî¨\\n\\n\"\n",
        "            \"I can help you find relevant diabetes clinical trials from a database of **22,000+ studies**.\\n\\n\"\n",
        "            \"**Try asking:**\\n\"\n",
        "            \"- 'What trials are studying insulin therapy?'\\n\"\n",
        "            \"- 'Show me trials about low-carb diets'\\n\"\n",
        "            \"- 'Are there trials testing new medications?'\\n\"\n",
        "            \"- 'I'm 55 with type 2 diabetes, what trials can I join?'\\n\\n\"\n",
        "            \"I search real trial data from ClinicalTrials.gov. How can I help you explore diabetes research today?\"\n",
        "        )\n",
        "\n",
        "        log = log_provenance_step(\"GreetingAgent\", user_input, msg, {\"type\": \"greeting\"})\n",
        "        self.provenance_chain.append(log)\n",
        "\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "        self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": msg,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Non-RAG\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _handle_off_topic(self, user_input: str, parsed: Dict[str, Any]):\n",
        "        msg = (\n",
        "            \"I'm specialized in diabetes-related clinical trials. Your query appears to be \"\n",
        "            \"about symptoms or conditions not directly related to diabetes. \"\n",
        "            \"If you have diabetes-related questions, I'd be happy to help!\"\n",
        "        )\n",
        "        log = log_provenance_step(\"OffTopicHandler\", user_input, msg, {\"type\": \"off_topic\"})\n",
        "        self.provenance_chain.append(log)\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": msg,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Off-topic\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "    def _handle_knowledge_question(self, user_input: str, parsed: Dict[str, Any]):\n",
        "        user_question = parsed.get(\"user_question\", user_input)\n",
        "        prompt = (\n",
        "            \"You are a certified diabetes educator. Answer this question clearly and accurately.\\n\"\n",
        "            f\"QUESTION: {user_question}\\n\"\n",
        "        )\n",
        "        try:\n",
        "            res = self.advisor.model.generate_content(prompt)\n",
        "            answer = (res.text or \"\").strip()\n",
        "        except:\n",
        "            answer = \"Unable to answer at this time.\"\n",
        "\n",
        "        log = log_provenance_step(\"KnowledgeAgent\", user_input, answer, {\"type\": \"general_knowledge\"})\n",
        "        self.provenance_chain.append(log)\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": answer,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Knowledge-Based\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "\n",
        "    def process_query(self, user_input: str):\n",
        "        self.provenance_chain = []\n",
        "\n",
        "        # 1. Parse\n",
        "        parsed, parse_log = self.parser.parse(user_input)\n",
        "        self.provenance_chain.append(parse_log)\n",
        "\n",
        "        intent = (parsed.get(\"intent\") or \"trial_search\").lower()\n",
        "        query_type = parsed.get(\"query_type\", \"trial_query\")\n",
        "        is_diabetes_related = parsed.get(\"is_diabetes_related\", True)\n",
        "\n",
        "        # Handle greetings\n",
        "        if intent == \"greeting\":\n",
        "            return self._handle_simple_greeting(user_input)\n",
        "\n",
        "        # Handle off-topic\n",
        "        if intent == \"off_topic\" or not is_diabetes_related:\n",
        "            return self._handle_off_topic(user_input, parsed)\n",
        "\n",
        "        # Handle profile info (store but don't search yet)\n",
        "        if intent == \"profile_info\":\n",
        "            # Extract profile\n",
        "            # TODO: Implement profile extraction\n",
        "            msg = (\n",
        "                \"Thank you for sharing your information. I've noted your details. \"\n",
        "                \"What type of clinical trials would you like to explore? \"\n",
        "                \"For example: 'Show me trials about diet management' or 'What trials test new medications?'\"\n",
        "            )\n",
        "            log = log_provenance_step(\"ProfileAgent\", user_input, msg, {\"action\": \"profile_stored\"})\n",
        "            self.provenance_chain.append(log)\n",
        "\n",
        "            session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "            return {\n",
        "                \"recommendation\": msg,\n",
        "                \"cited_trials\": [],\n",
        "                \"safety_status\": \"Profile Update\",\n",
        "                \"session_hash\": session_hash,\n",
        "                \"provenance_chain\": self.provenance_chain,\n",
        "            }\n",
        "\n",
        "        # Handle ONLY pure education questions (NO retrieval)\n",
        "        # Must be general_question AND not asking about trials\n",
        "        if intent == \"general_question\" and query_type == \"knowledge_seeking\":\n",
        "            # Double-check not asking about trials\n",
        "            if \"trial\" not in user_input.lower() and \"study\" not in user_input.lower():\n",
        "                return self._handle_knowledge_question(user_input, parsed)\n",
        "\n",
        "        # üî¥ DEFAULT: TRIAL SEARCH (WITH RETRIEVAL)\n",
        "        # This catches:\n",
        "        # - intent=\"trial_search\"\n",
        "        # - Anything diabetes-related we're unsure about\n",
        "        # - Better to search and find nothing than miss relevant trials\n",
        "\n",
        "        retrieved, retrieve_log = self.retriever.retrieve(parsed)\n",
        "\n",
        "\n",
        "        # # TEMP DEBUG - Remove after testing\n",
        "        # print(f\"\\n=== DEBUG INFO ===\")\n",
        "        # print(f\"Query: {user_input}\")\n",
        "        # print(f\"Retrieved {len(retrieved.get('trials', []))} trials\")\n",
        "        # print(f\"Avg confidence: {retrieved.get('avg_confidence', 0):.3f}\")\n",
        "        # if retrieved.get('trials'):\n",
        "        #     print(f\"Top trial: {retrieved['trials'][0]['nct_id']}\")\n",
        "        #     print(f\"Top confidence: {retrieved['trials'][0]['confidence']:.3f}\")\n",
        "        # print(f\"===================\\n\")\n",
        "\n",
        "\n",
        "        # # TEMP DEBUG\n",
        "        # if user_input.lower() == \"are there trials testing new medications?\":\n",
        "        #     print(f\"\\n=== DEBUG: New Medications Query ===\")\n",
        "        #     print(f\"Retrieved {len(retrieved.get('trials', []))} trials\")\n",
        "        #     print(f\"Avg confidence: {retrieved.get('avg_confidence', 0):.4f}\")\n",
        "        #     if retrieved.get('trials'):\n",
        "        #         for i, t in enumerate(retrieved['trials'][:3]):\n",
        "        #             print(f\"Trial {i+1}: {t['nct_id']} | Conf: {t['confidence']:.4f}\")\n",
        "        #     print(\"====================================\\n\")\n",
        "\n",
        "\n",
        "        self.provenance_chain.append(retrieve_log)\n",
        "\n",
        "        # Check if query is too generic (low confidence + generic keywords)\n",
        "        generic_terms = [\"new\", \"any\", \"some\", \"recent\", \"latest\"]\n",
        "        is_generic = any(term in user_input.lower() for term in generic_terms)\n",
        "        avg_conf = retrieved.get(\"avg_confidence\", 0.0)\n",
        "\n",
        "        if is_generic and avg_conf < 0.15:\n",
        "            return self._handle_generic_trial_query(user_input, parsed)\n",
        "\n",
        "\n",
        "        # 3. Advisor\n",
        "        draft_advice, advise_log = self.advisor.advise(parsed, retrieved, self.profile_agent.profile)\n",
        "        self.provenance_chain.append(advise_log)\n",
        "\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        if draft_advice.get(\"confidence_veto\", False) or not trials:\n",
        "            final_text = draft_advice[\"recommendation\"]\n",
        "            safety_status = \"Vetoed (Low Confidence)\"\n",
        "            evidence_list = []\n",
        "        else:\n",
        "            # 4. Safety\n",
        "            final_text, safety_status, safety_log = self.safety.verify(draft_advice[\"recommendation\"], trials)\n",
        "            self.provenance_chain.append(safety_log)\n",
        "            evidence_list = trials\n",
        "\n",
        "        nct_ids = [t[\"nct_id\"] for t in evidence_list]\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "        # 5. Update profile/history\n",
        "        turn_data = {\n",
        "            \"query\": user_input,\n",
        "            \"parsed\": parsed,\n",
        "            \"nct_ids\": nct_ids,\n",
        "            \"safety_status\": safety_status,\n",
        "            \"session_hash\": session_hash,\n",
        "        }\n",
        "        profile_log = self.profile_agent.update_profile(turn_data)\n",
        "        self.provenance_chain.append(profile_log)\n",
        "        self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": final_text,\n",
        "            \"cited_trials\": nct_ids,\n",
        "            \"safety_status\": safety_status,\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "    def _handle_generic_trial_query(self, user_input: str, parsed: Dict[str, Any]):\n",
        "        \"\"\"Handle generic queries that need more specificity\"\"\"\n",
        "\n",
        "        msg = (\n",
        "            \"I found that question a bit broad. I have 22,000+ diabetes trials in my database. \"\n",
        "            \"To help you better, could you specify:\\n\\n\"\n",
        "            \"**Drug/Medication Trials:**\\n\"\n",
        "            \"- Specific drugs: 'trials testing metformin', 'liraglutide trials'\\n\"\n",
        "            \"- Drug classes: 'GLP-1 trials', 'SGLT2 inhibitor trials'\\n\"\n",
        "            \"- Insulin: 'insulin pump trials', 'insulin therapy trials'\\n\\n\"\n",
        "            \"**Lifestyle Trials:**\\n\"\n",
        "            \"- Diet: 'low-carb diet trials', 'Mediterranean diet trials'\\n\"\n",
        "            \"- Exercise: 'physical activity trials', 'exercise trials'\\n\\n\"\n",
        "            \"**Technology Trials:**\\n\"\n",
        "            \"- Monitoring: 'CGM trials', 'glucose monitoring trials'\\n\"\n",
        "            \"- Apps: 'diabetes app trials', 'digital health trials'\\n\\n\"\n",
        "            \"**Or describe your situation:**\\n\"\n",
        "            \"- 'I'm 55 with type 2 diabetes, what trials can I join?'\\n\"\n",
        "            \"- 'Trials for managing high blood sugar'\\n\\n\"\n",
        "            \"What would you like to explore?\"\n",
        "        )\n",
        "\n",
        "        log = log_provenance_step(\"GenericQueryHandler\", user_input, msg, {\"type\": \"needs_refinement\"})\n",
        "        self.provenance_chain.append(log)\n",
        "\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "        self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": msg,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Refinement Needed\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# GLOBAL BOT INSTANCE + ENTRYPOINT\n",
        "# ============================================================\n",
        "\n",
        "default_profile = {\n",
        "    \"user_id\": \"Patient\",\n",
        "    \"conditions\": [\"diabetes\"],\n",
        "    \"extracted_conditions\": []\n",
        "}\n",
        "\n",
        "_bot = HealthcareBot(gemini_model, embed_model, faiss_index, chunk_map, initial_profile=default_profile)\n",
        "\n",
        "def run_bot(user_input: str) -> Dict[str, Any]:\n",
        "    return _bot.process_query(user_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDxpjMNrCwCA"
      },
      "source": [
        "UI frontend application simple web interface\n",
        "\n",
        "https://docs.streamlit.io/develop/tutorials/chat-and-llm-apps/build-conversational-apps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EqkmxVqOkZ-",
        "outputId": "67767ebc-1566-41de-ae00-44fcba7933bc"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "\n",
        "if \"GEMINI_API_KEY\" not in os.environ:\n",
        "    st.error(\"‚ö†Ô∏è API Key missing! Please run the 'Secure Input' cell in the notebook first.\")\n",
        "\n",
        "from run_bot import run_bot\n",
        "\n",
        "st.title(\"Clinical Trial Health Advisor ü§ñ\")\n",
        "st.caption(\"AI for Healthcare - Clinical Trials RAG\")\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "for msg in st.session_state.messages:\n",
        "    with st.chat_message(msg[\"role\"]):\n",
        "        st.markdown(msg[\"content\"])\n",
        "\n",
        "if user_input := st.chat_input(\"Describe your symptoms...\"):\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(user_input)\n",
        "\n",
        "    with st.spinner(\"Searching clinical trials...\"):\n",
        "        result = run_bot(user_input)\n",
        "        reply = result[\"recommendation\"]\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(reply)\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": reply})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5BcqHNUOklc"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 cloudflared\n",
        "!chmod +x cloudflared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZqn_TJIOkuT",
        "outputId": "71d2b3f3-e372-4a2a-d55f-5590afff7e24"
      },
      "outputs": [],
      "source": [
        "#AI LLM\n",
        "!streamlit run app.py &>/dev/null&\n",
        "!./cloudflared tunnel --url http://localhost:8501 --no-autoupdate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEI5vKa1N32W",
        "outputId": "d8919cf2-cac1-44fb-f582-f4efad647863"
      },
      "outputs": [],
      "source": [
        "# Run this and share output\n",
        "# === REAL PATH (from readlink) ===\n",
        "BASE = \"/content/drive/MyDrive/LLM_Based_GenAI_Sem1/data/\"\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(f\"{BASE}/clinical_trials_diabetes_full.csv\")\n",
        "\n",
        "print(\"=== DATASET INSPECTION ===\")\n",
        "print(f\"Total trials: {len(df)}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(f\"\\nSample titles:\")\n",
        "print(df['brief_title'].head(10))\n",
        "print(f\"\\nSample summaries:\")\n",
        "print(df['brief_summary'].iloc[0][:500])\n",
        "print(df['brief_summary'].iloc[1][:500])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTarWWCdXC-i",
        "outputId": "0b0bc118-7b73-4bd7-ad40-dad487e280f0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/LLM_Based_GenAI_Sem1/data/\"\n",
        "df = pd.read_csv(f\"{BASE}/clinical_trials_diabetes_full.csv\")\n",
        "\n",
        "# NCT IDs from your chatbot results\n",
        "test_nct_ids = [\n",
        "    \"NCT00115973\",  # Insulin pump\n",
        "    \"NCT01489644\",  # Metformin\n",
        "    \"NCT05136287\",  # GLP-1 semaglutide\n",
        "    \"NCT02478190\",  # High blood sugar management\n",
        "]\n",
        "\n",
        "print(\"=== VERIFICATION: Are these NCT IDs in your database? ===\\n\")\n",
        "\n",
        "for nct in test_nct_ids:\n",
        "    match = df[df['nct_id'] == nct]\n",
        "\n",
        "    if len(match) > 0:\n",
        "        print(f\"‚úÖ {nct} FOUND in database\")\n",
        "        print(f\"   Title: {match.iloc[0]['brief_title']}\")\n",
        "        print(f\"   Summary (first 100 chars): {match.iloc[0]['brief_summary'][:100]}...\")\n",
        "        print()\n",
        "    else:\n",
        "        print(f\"‚ùå {nct} NOT FOUND in database (HALLUCINATION!)\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDdehxkwQIK4",
        "outputId": "fc00d0c3-a980-4efb-cd4a-e98614d868fd"
      },
      "outputs": [],
      "source": [
        "nct = \"NCT00115973\"\n",
        "match = df[df['nct_id'] == nct]\n",
        "\n",
        "if len(match) > 0:\n",
        "    actual_title = match.iloc[0]['brief_title']\n",
        "    actual_summary = match.iloc[0]['brief_summary']\n",
        "\n",
        "    print(\"=== CHATBOT vs REALITY ===\")\n",
        "    print(f\"\\nChatbot said:\")\n",
        "    print(\"'studied the treatment of type 2 diabetes with an insulin infusion pump'\")\n",
        "\n",
        "    print(f\"\\nActual trial title:\")\n",
        "    print(actual_title)\n",
        "\n",
        "    print(f\"\\nActual summary:\")\n",
        "    print(actual_summary[:300])\n",
        "\n",
        "    print(f\"\\n=== IS CHATBOT DESCRIPTION ACCURATE? ===\")\n",
        "    summary_lower = actual_summary.lower()\n",
        "    print(f\"Mentions 'type 2 diabetes': {'type 2' in summary_lower or 't2d' in summary_lower}\")\n",
        "    print(f\"Mentions 'insulin': {'insulin' in summary_lower}\")\n",
        "    print(f\"Mentions 'pump' or 'infusion': {'pump' in summary_lower or 'infusion' in summary_lower}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhV1vQiEoZP0",
        "outputId": "aade7d76-3f62-4c4b-ac0a-63eeb1ff45e3"
      },
      "outputs": [],
      "source": [
        "# Quick check\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/LLM_Based_GenAI_Sem1/data/clinical_trials_diabetes_full.csv\")\n",
        "\n",
        "# Your chatbot's results\n",
        "test_ids = [\"NCT00115973\", \"NCT01489644\", \"NCT05136287\", \"NCT02478190\"]\n",
        "\n",
        "print(\"Quick Verification:\")\n",
        "for nct in test_ids:\n",
        "    exists = nct in df['nct_id'].values\n",
        "    print(f\"{nct}: {'‚úÖ FOUND' if exists else '‚ùå NOT FOUND (HALLUCINATION!)'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZVaH1MJofOF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
