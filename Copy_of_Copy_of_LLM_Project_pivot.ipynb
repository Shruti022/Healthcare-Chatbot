{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shruti022/Healthcare-Chatbot/blob/main/Copy_of_Copy_of_LLM_Project_pivot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keVc9VWJI9ZI"
      },
      "source": [
        "Project Phase 1: Stepwise API Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUmbb9KsIaRL"
      },
      "source": [
        "Step 1: Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h2IWghs9QZVy",
        "outputId": "e422ed84-da4f-4aeb-9a76-068124df4ebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m130.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m141.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q requests pandas streamlit pyngrok faiss-cpu sentence-transformers numpy\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUskaUMVEYsn",
        "outputId": "098ae100-375f-4124-cf44-48e0068953b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Secure KEY INPUT\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# Securely Capture Key\n",
        "# Input will be invisible. Paste key and press Enter.\n",
        "key_input = getpass.getpass(\"üîë Enter Gemini API Key (Invisible Input): \")\n",
        "\n",
        "if not key_input.startswith(\"AIza\"):\n",
        "    print(\"‚ö†Ô∏è Warning: Key might be invalid (usually starts with 'AIza').\")\n",
        "else:\n",
        "    print(\"‚úÖ API Key captured securely in Environment Variable.\")\n",
        "\n",
        "# 2. Set as Environment Variable for the Session\n",
        "os.environ[\"GEMINI_API_KEY\"] = key_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnfATz0x1DYc",
        "outputId": "8d8b075a-4faa-43ce-a229-6775b0e68f2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîë Enter Gemini API Key (Invisible Input): ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ API Key captured securely in Environment Variable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile build_embeddings.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "import json\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# === REAL PATH (from readlink) ===\n",
        "BASE = \"/content/drive/.shortcut-targets-by-id/1-SiVJhXHTHtDYSrPmW_0VfuP7gSTePcj/data\"\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Load Data\n",
        "# ---------------------------------------------\n",
        "df = pd.read_csv(f\"{BASE}/clinical_trials_diabetes_full.csv\")\n",
        "\n",
        "df[\"status\"] = df[\"status\"].astype(str).str.strip().str.title()\n",
        "bad_status = [\"Terminated\", \"Withdrawn\", \"Suspended\", \"No Longer Available\", \"Unknown\"]\n",
        "df_clean = df[~df[\"status\"].isin(bad_status)].copy()\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Chunking\n",
        "# ---------------------------------------------\n",
        "chunks = []\n",
        "chunk_map = []\n",
        "\n",
        "for idx, row in df_clean.iterrows():\n",
        "    title = str(row.get(\"brief_title\", \"\")).strip()\n",
        "    summary = str(row.get(\"brief_summary\", \"\")).strip()\n",
        "\n",
        "    if len(summary) < 20:\n",
        "        continue\n",
        "\n",
        "    text = f\"Title: {title}\\nSummary: {summary}\"\n",
        "    chunks.append(text)\n",
        "\n",
        "    chunk_map.append({\n",
        "        \"nct_id\": row[\"nct_id\"],\n",
        "        \"title\": title,\n",
        "        \"text\": text,\n",
        "        \"status\": row[\"status\"]\n",
        "    })\n",
        "\n",
        "print(f\"Created {len(chunks)} chunks.\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Embeddings\n",
        "# ---------------------------------------------\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = embed_model.encode(chunks, batch_size=64, show_progress_bar=True)\n",
        "\n",
        "np.save(f\"{BASE}/clinical_trials_diabetes_full_embeddings.npy\", embeddings)\n",
        "print(\"Saved clinical_trials_diabetes_full_embeddings.npy\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Save chunk map\n",
        "# ---------------------------------------------\n",
        "with open(f\"{BASE}/clinical_trials_diabetes_full_chunk_map.json\", \"w\") as f:\n",
        "    json.dump(chunk_map, f)\n",
        "\n",
        "print(\"Saved clinical_trials_diabetes_full_chunk_map.json\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Build & Save FAISS\n",
        "# ---------------------------------------------\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(embeddings).astype(\"float32\"))\n",
        "faiss.write_index(index, f\"{BASE}/clinical_trials_diabetes_full_faiss.index\")\n",
        "\n",
        "print(\"Saved clinical_trials_diabetes_full_faiss.index\")\n",
        "print(\"‚úÖ Embedding build COMPLETE.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mwEwzAoPHlB",
        "outputId": "3a222e89-4fe8-4077-b0bf-1414b1267888"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing build_embeddings.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python build_embeddings.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32A5yZO0V4VT",
        "outputId": "9516f02b-9776-4d04-a204-7565b68ca4ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-27 06:40:14.758159: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764225614.783078    1243 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764225614.802500    1243 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764225614.847084    1243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764225614.848936    1243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764225614.848959    1243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764225614.848967    1243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Created 18063 chunks.\n",
            "modules.json: 100% 349/349 [00:00<00:00, 3.10MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 1.19MB/s]\n",
            "README.md: 10.5kB [00:00, 43.8MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 571kB/s]\n",
            "config.json: 100% 612/612 [00:00<00:00, 6.32MB/s]\n",
            "model.safetensors: 100% 90.9M/90.9M [00:01<00:00, 66.5MB/s]\n",
            "tokenizer_config.json: 100% 350/350 [00:00<00:00, 3.69MB/s]\n",
            "vocab.txt: 232kB [00:00, 70.8MB/s]\n",
            "tokenizer.json: 466kB [00:00, 108MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 1.17MB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 1.94MB/s]\n",
            "Batches: 100% 283/283 [00:32<00:00,  8.65it/s]\n",
            "Saved clinical_trials_diabetes_full_embeddings.npy\n",
            "Saved clinical_trials_diabetes_full_chunk_map.json\n",
            "Saved clinical_trials_diabetes_full_faiss.index\n",
            "‚úÖ Embedding build COMPLETE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "import json\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# --- Confidence score from distance ---\n",
        "\n",
        "def calculate_confidence_score(distance: float, normalization_factor: float = 1.0) -> float:\n",
        "    \"\"\"Inverse L2 distance score in (0,1]; closer = higher confidence.\"\"\"\n",
        "    return normalization_factor / (normalization_factor + float(distance))\n",
        "\n",
        "\n",
        "# --- Load pre-built index + chunk map ---\n",
        "\n",
        "def load_data_and_index(chunk_map_path: str, faiss_path: str):\n",
        "    \"\"\"Loads pre-built chunks and FAISS index for quick startup.\"\"\"\n",
        "    print(\"‚è≥ Loading pre-built RAG index...\")\n",
        "\n",
        "    with open(chunk_map_path, \"r\") as f:\n",
        "        chunk_map = json.load(f)\n",
        "\n",
        "    index = faiss.read_index(faiss_path)\n",
        "\n",
        "    embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    print(f\"‚úÖ RAG Index Ready: {index.ntotal} vectors loaded.\")\n",
        "    return embed_model, index, chunk_map\n",
        "\n",
        "\n",
        "# --- Provenance logging ---\n",
        "\n",
        "def log_provenance_step(agent_name: str, input_data, output_data, detail=None):\n",
        "    \"\"\"\n",
        "    Creates a detailed log entry for a single agent step.\n",
        "    \"\"\"\n",
        "    log_entry = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"agent\": agent_name,\n",
        "        \"input\": input_data,\n",
        "        \"output\": output_data,\n",
        "        \"detail\": detail or {},\n",
        "        \"model_version\": \"gemini-2.0-flash\",\n",
        "    }\n",
        "    return log_entry\n",
        "\n",
        "\n",
        "# --- Reproducibility hash ---\n",
        "\n",
        "def generate_reproducibility_hash(conversation_history, corpus_version: str = \"v1.0\"):\n",
        "    \"\"\"\n",
        "    Generates a deterministic session hash based on the conversation history.\n",
        "    \"\"\"\n",
        "    queries = [turn.get(\"query\", \"\") for turn in conversation_history]\n",
        "    raw = f\"{corpus_version}|{'|'.join(queries)}\"\n",
        "    return hashlib.md5(raw.encode(\"utf-8\")).hexdigest()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PXqvXLkXaX7",
        "outputId": "0548cca2-1d7b-470f-f540-30a13b2921bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_bot.py\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "\n",
        "# --- Updated Import: Robust Cross-Encoder Initialization ---\n",
        "CrossEncoder = None\n",
        "try:\n",
        "    from sentence_transformers import CrossEncoder\n",
        "    print(\"‚úÖ sentence_transformers imported successfully.\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è sentence_transformers not found. Reranking will be disabled.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error importing CrossEncoder: {e}. Reranking disabled.\")\n",
        "\n",
        "from utils import (\n",
        "    load_data_and_index,\n",
        "    log_provenance_step,\n",
        "    generate_reproducibility_hash,\n",
        "    calculate_confidence_score,\n",
        ")\n",
        "\n",
        "\n",
        "# --- NEW CONFIG (SECURE & 2.0 MODEL) ---\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not API_KEY:\n",
        "    print(\"‚ùå ERROR: API Key not found. Please run the 'Secure Input' cell first.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "# Using the Experimental 2.0 Flash endpoint\n",
        "gemini_model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "CHUNK_PATH = \"/content/drive/.shortcut-targets-by-id/1-SiVJhXHTHtDYSrPmW_0VfuP7gSTePcj/data/clinical_trials_diabetes_full_chunk_map.json\"\n",
        "FAISS_PATH = \"/content/drive/.shortcut-targets-by-id/1-SiVJhXHTHtDYSrPmW_0VfuP7gSTePcj/data/clinical_trials_diabetes_full_faiss.index\"\n",
        "\n",
        "# Load embedding model, FAISS index, and chunk metadata\n",
        "embed_model, faiss_index, chunk_map = load_data_and_index(CHUNK_PATH, FAISS_PATH)\n",
        "\n",
        "# --- NEW: Reranker Initialization ---\n",
        "reranker = None\n",
        "if CrossEncoder:\n",
        "    try:\n",
        "        print(\"‚è≥ Loading Reranker Model (Cross-Encoder)...\")\n",
        "        # High precision reranker\n",
        "        reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "        print(\"‚úÖ Reranker Loaded.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Reranker model download failed (using pure FAISS): {e}\")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# PARSER\n",
        "# =========================\n",
        "class SymptomParser:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def parse(self, text: str):\n",
        "        \"\"\"\n",
        "        Enhanced parser for clinical trial search queries.\n",
        "        Decides if user is doing trial search vs general question, etc.\n",
        "        \"\"\"\n",
        "        prompt = (\n",
        "            \"You are a clinical trial search classifier for diabetes research.\\n\"\n",
        "            \"Your job is to determine if the user wants to SEARCH for trials or just learn about diabetes.\\n\\n\"\n",
        "            f'User Input: \"{text}\"\\n\\n'\n",
        "            \"Classification Rules:\\n\"\n",
        "            \"1. If query contains 'trial', 'study', 'research', 'clinical', or asks 'what trials', \"\n",
        "            \"'show me trials', 'are there trials' ‚Üí intent='trial_search'\\n\"\n",
        "            \"2. If user states personal info like age, conditions, medications ‚Üí intent='profile_info'\\n\"\n",
        "            \"3. If asking general education questions like 'what is X?', 'how does Y work?' \"\n",
        "            \"(WITHOUT asking about trials) ‚Üí intent='general_question'\\n\"\n",
        "            \"4. Simple greetings ‚Üí intent='greeting'\\n\"\n",
        "            \"5. Not about diabetes ‚Üí intent='off_topic'\\n\\n\"\n",
        "            \"Return ONLY valid JSON:\\n\"\n",
        "            \"{\\n\"\n",
        "            '  \"intent\": \"trial_search\" | \"profile_info\" | \"general_question\" | \"greeting\" | \"off_topic\",\\n'\n",
        "            '  \"query_type\": \"trial_query\" | \"profile_statement\" | \"knowledge_seeking\" | \"greeting\",\\n'\n",
        "            '  \"search_keywords\": [\"keyword1\", \"keyword2\"],\\n'\n",
        "            '  \"is_diabetes_related\": true/false,\\n'\n",
        "            '  \"user_question\": \"the question in plain English\",\\n'\n",
        "            '  \"trial_interest\": \"what type of trial they want (diet, medication, technology, etc.)\"\\n'\n",
        "            \"}\\n\\n\"\n",
        "            \"Examples:\\n\"\n",
        "            '- \\\"What trials study liraglutide?\\\" ‚Üí intent=\\\"trial_search\\\", search_keywords=[\\\"liraglutide\\\"]\\n'\n",
        "            \"- \\\"I'm 55 with diabetes\\\" ‚Üí intent=\\\"profile_info\\\"\\n\"\n",
        "            \"- \\\"What is HbA1c?\\\" ‚Üí intent=\\\"general_question\\\"\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            raw = (res.text or \"\").strip()\n",
        "            match = re.search(r\"\\{.*\\}\", raw, re.DOTALL)\n",
        "            if match:\n",
        "                parsed = json.loads(match.group(0))\n",
        "            else:\n",
        "                parsed = json.loads(raw)\n",
        "\n",
        "            # Force trial_search if keywords present\n",
        "            text_lower = text.lower()\n",
        "            trial_keywords = [\n",
        "                \"trial\", \"study\", \"studies\", \"research\",\n",
        "                \"clinical\", \"show me\", \"are there\", \"what trials\"\n",
        "            ]\n",
        "            if any(kw in text_lower for kw in trial_keywords):\n",
        "                parsed[\"intent\"] = \"trial_search\"\n",
        "                parsed[\"query_type\"] = \"trial_query\"\n",
        "\n",
        "        except Exception:\n",
        "            # Fallback with keyword detection\n",
        "            text_lower = text.lower()\n",
        "            if any(kw in text_lower for kw in [\"trial\", \"study\", \"research\"]):\n",
        "                parsed = {\n",
        "                    \"intent\": \"trial_search\",\n",
        "                    \"query_type\": \"trial_query\",\n",
        "                    \"search_keywords\": [text],\n",
        "                    \"is_diabetes_related\": True,\n",
        "                    \"user_question\": text,\n",
        "                    \"trial_interest\": \"general\",\n",
        "                }\n",
        "            else:\n",
        "                parsed = {\n",
        "                    \"intent\": \"general_question\",\n",
        "                    \"query_type\": \"knowledge_seeking\",\n",
        "                    \"search_keywords\": [],\n",
        "                    \"is_diabetes_related\": True,\n",
        "                    \"user_question\": text,\n",
        "                    \"trial_interest\": None,\n",
        "                }\n",
        "\n",
        "        log = log_provenance_step(\"SymptomParser\", text, parsed)\n",
        "        return parsed, log\n",
        "\n",
        "\n",
        "# =========================\n",
        "# PROFILE AGENT\n",
        "# =========================\n",
        "class ProfileAgent:\n",
        "    def __init__(self, initial_profile: Dict[str, Any] = None):\n",
        "        if initial_profile is None:\n",
        "            initial_profile = {\n",
        "                \"user_id\": \"Patient\",\n",
        "                \"conditions\": [\"diabetes\"],  # Default context\n",
        "                \"extracted_conditions\": [],  # Dynamic memory\n",
        "                \"history\": [],\n",
        "            }\n",
        "        self.profile = initial_profile\n",
        "\n",
        "    def update_profile(self, turn_data: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Updates history and extracts persistent medical entities.\n",
        "        \"\"\"\n",
        "        self.profile.setdefault(\"history\", []).append(turn_data)\n",
        "        self.profile.setdefault(\"extracted_conditions\", [])\n",
        "\n",
        "        parsed = turn_data.get(\"parsed\", {})\n",
        "        new_symptoms = parsed.get(\"symptoms\", [])\n",
        "\n",
        "        if new_symptoms:\n",
        "            current_conditions = set(self.profile[\"extracted_conditions\"])\n",
        "            for sym in new_symptoms:\n",
        "                if sym and len(sym) > 3:  # Avoid noise\n",
        "                    current_conditions.add(sym.lower())\n",
        "            self.profile[\"extracted_conditions\"] = list(current_conditions)\n",
        "\n",
        "        snapshot = {\n",
        "            \"user_id\": self.profile.get(\"user_id\", \"Patient\"),\n",
        "            \"known_conditions\": self.profile.get(\"extracted_conditions\", []),\n",
        "            \"num_turns\": len(self.profile[\"history\"]),\n",
        "        }\n",
        "        log = log_provenance_step(\"ProfileAgent\", turn_data, {\"profile_snapshot\": snapshot})\n",
        "        return log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# EVIDENCE-WEIGHTED SCORER (Novel Contribution)\n",
        "# ============================================================\n",
        "class EvidenceWeightedScorer:\n",
        "    \"\"\"\n",
        "    Implements evidence-weighted scoring for clinical trials.\n",
        "    Ranks trials based on multiple quality factors beyond semantic similarity.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Status weights (prioritize completed trials for reliable results)\n",
        "        self.status_weights = {\n",
        "            \"Completed\": 1.0,\n",
        "            \"Active, Not Recruiting\": 0.9,\n",
        "            \"Recruiting\": 0.85,\n",
        "            \"Enrolling By Invitation\": 0.8,\n",
        "            \"Not Yet Recruiting\": 0.6,\n",
        "            \"Terminated\": 0.4,\n",
        "            \"Withdrawn\": 0.3,\n",
        "            \"Suspended\": 0.3,\n",
        "            \"Unknown Status\": 0.5,\n",
        "        }\n",
        "\n",
        "        # Study design weights\n",
        "        self.design_keywords = {\n",
        "            \"randomized controlled\": 1.0,\n",
        "            \"double-blind\": 0.95,\n",
        "            \"randomized\": 0.9,\n",
        "            \"controlled\": 0.85,\n",
        "            \"interventional\": 0.8,\n",
        "            \"prospective\": 0.75,\n",
        "            \"observational\": 0.6,\n",
        "            \"retrospective\": 0.5,\n",
        "        }\n",
        "\n",
        "    def calculate_weighted_score(\n",
        "        self,\n",
        "        trial: Dict[str, Any],\n",
        "        base_confidence: float,\n",
        "        query: str\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Calculate evidence-weighted score for a trial.\n",
        "        Returns weighted_score + breakdown.\n",
        "        \"\"\"\n",
        "\n",
        "        # Factor 1: Base semantic match (35%)\n",
        "        match_score = base_confidence * 0.35\n",
        "\n",
        "        # Factor 2: Trial status quality (25%)\n",
        "        status = str(trial.get(\"status\", \"Unknown Status\")).strip().title()\n",
        "        status_score = self.status_weights.get(status, 0.5) * 0.25\n",
        "\n",
        "        # Factor 3: Study design quality (20%)\n",
        "        design_score = self._calculate_design_quality(trial) * 0.20\n",
        "\n",
        "        # Factor 4: Keyword density (10%)\n",
        "        keyword_score = self._calculate_keyword_density(trial, query) * 0.10\n",
        "\n",
        "        # Factor 5: Metadata completeness (10%)\n",
        "        completeness_score = self._calculate_completeness(trial) * 0.10\n",
        "\n",
        "        # Total weighted score\n",
        "        weighted_score = (\n",
        "            match_score +\n",
        "            status_score +\n",
        "            design_score +\n",
        "            keyword_score +\n",
        "            completeness_score\n",
        "        )\n",
        "\n",
        "        breakdown = {\n",
        "            \"base_confidence\": base_confidence,\n",
        "            \"weighted_score\": weighted_score,\n",
        "            \"factors\": {\n",
        "                \"semantic_match\": match_score,\n",
        "                \"trial_status\": status_score,\n",
        "                \"study_design\": design_score,\n",
        "                \"keyword_density\": keyword_score,\n",
        "                \"completeness\": completeness_score,\n",
        "            },\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"weighted_score\": min(weighted_score, 1.0),\n",
        "            \"breakdown\": breakdown,\n",
        "        }\n",
        "\n",
        "    def _calculate_design_quality(self, trial: Dict[str, Any]) -> float:\n",
        "        text = f\"{trial.get('brief_title', '')} {trial.get('brief_summary', '')}\".lower()\n",
        "        max_score = 0.0\n",
        "        for keyword, weight in self.design_keywords.items():\n",
        "            if keyword in text:\n",
        "                max_score = max(max_score, weight)\n",
        "        # Default moderate score if no keywords found\n",
        "        return max_score if max_score > 0 else 0.6\n",
        "\n",
        "    def _calculate_keyword_density(self, trial: Dict[str, Any], query: str) -> float:\n",
        "        text = f\"{trial.get('brief_title', '')} {trial.get('brief_summary', '')}\".lower()\n",
        "        stopwords = {\n",
        "            \"the\", \"a\", \"an\", \"and\", \"or\", \"for\", \"with\", \"in\", \"on\", \"at\", \"to\",\n",
        "            \"of\", \"is\", \"are\", \"what\", \"trials\", \"study\", \"studies\"\n",
        "        }\n",
        "        query_terms = [\n",
        "            term for term in query.lower().split()\n",
        "            if term not in stopwords and len(term) > 2\n",
        "        ]\n",
        "        if not query_terms:\n",
        "            return 0.5\n",
        "        matches = sum(1 for term in query_terms if term in text)\n",
        "        density = matches / len(query_terms)\n",
        "        return min(density, 1.0)\n",
        "\n",
        "    def _calculate_completeness(self, trial: Dict[str, Any]) -> float:\n",
        "        fields = [\n",
        "            \"brief_title\",\n",
        "            \"brief_summary\",\n",
        "            \"eligibility_criteria\",\n",
        "            \"interventions\",\n",
        "            \"primary_outcomes\",\n",
        "        ]\n",
        "        filled_fields = 0\n",
        "        for field in fields:\n",
        "            value = trial.get(field, \"\")\n",
        "            if value and isinstance(value, str) and len(value) > 20:\n",
        "                filled_fields += 1\n",
        "        completeness = filled_fields / len(fields)\n",
        "        return completeness\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PubMed Helper (NCT ‚Üí PubMed abstract)\n",
        "# ============================================================\n",
        "def fetch_pubmed_abstract_for_nct(nct_id: str):\n",
        "    \"\"\"\n",
        "    Try to find a PubMed article linked to this NCT ID and return its abstract.\n",
        "\n",
        "    Returns:\n",
        "        dict { \"pmid\": str, \"abstract\": str } or None if not found.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1) Find PubMed ID via esearch using the NCT ID as Secondary Source ID [si]\n",
        "        esearch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "        params = {\n",
        "            \"db\": \"pubmed\",\n",
        "            \"term\": f\"{nct_id}[si]\",\n",
        "            \"retmode\": \"json\",\n",
        "            \"retmax\": 1,\n",
        "        }\n",
        "        r = requests.get(esearch_url, params=params, timeout=10)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        idlist = data.get(\"esearchresult\", {}).get(\"idlist\", [])\n",
        "        if not idlist:\n",
        "            return None\n",
        "\n",
        "        pmid = idlist[0]\n",
        "\n",
        "        # 2) Fetch abstract text\n",
        "        efetch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "        params = {\n",
        "            \"db\": \"pubmed\",\n",
        "            \"id\": pmid,\n",
        "            \"rettype\": \"abstract\",\n",
        "            \"retmode\": \"text\",\n",
        "        }\n",
        "        r2 = requests.get(efetch_url, params=params, timeout=10)\n",
        "        r2.raise_for_status()\n",
        "        abstract_text = r2.text.strip()\n",
        "        if not abstract_text:\n",
        "            return None\n",
        "\n",
        "        return {\"pmid\": pmid, \"abstract\": abstract_text}\n",
        "    except Exception:\n",
        "        # Swallow errors quietly; just means \"no abstract found\"\n",
        "        return None\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# RETRIEVAL AGENT\n",
        "# ============================================================\n",
        "class RetrievalAgent:\n",
        "    def __init__(self, embed_model, faiss_index, chunk_map, profile_agent: ProfileAgent = None):\n",
        "        self.embed_model = embed_model\n",
        "        self.index = faiss_index\n",
        "        self.chunk_map = chunk_map\n",
        "        self.profile_agent = profile_agent\n",
        "        self.evidence_scorer = EvidenceWeightedScorer()\n",
        "\n",
        "    def retrieve(self, parsed: Dict[str, Any], top_k: int = 5):\n",
        "        FETCH_K = top_k * 3\n",
        "\n",
        "        symptoms = parsed.get(\"symptoms\") or []\n",
        "        context = parsed.get(\"context\") or \"\"\n",
        "        query = parsed.get(\"user_question\") or (\" \".join(symptoms) + \" \" + context).strip()\n",
        "\n",
        "        if not query:\n",
        "            retrieval = {\"query\": \"\", \"trials\": [], \"avg_confidence\": 0.0}\n",
        "            log = log_provenance_step(\n",
        "                \"RetrievalAgent\",\n",
        "                parsed,\n",
        "                retrieval,\n",
        "                {\"reason\": \"empty_query\"}\n",
        "            )\n",
        "            return retrieval, log\n",
        "\n",
        "        EXPANSIONS = {\n",
        "            \"insulin\": \"insulin OR insulin therapy OR insulin treatment OR insulin pump\",\n",
        "            \"medication\": \"medication OR drug OR pharmaceutical OR pharmacological OR treatment\",\n",
        "            \"diet\": \"diet OR dietary OR nutrition OR nutritional OR eating\",\n",
        "            \"exercise\": \"exercise OR physical activity OR fitness OR activity\",\n",
        "            \"new\": \"medication OR drug OR pharmacological OR treatment OR therapy OR intervention\",\n",
        "        }\n",
        "\n",
        "        query_lower = query.lower()\n",
        "        for term, expansion in EXPANSIONS.items():\n",
        "            if term in query_lower:\n",
        "                query = f\"{query} {expansion}\"\n",
        "                break\n",
        "\n",
        "        # 1. FAISS retrieval\n",
        "        q_emb = self.embed_model.encode([query])\n",
        "        distances, indices = self.index.search(q_emb.astype(\"float32\"), FETCH_K)\n",
        "\n",
        "        initial_candidates = []\n",
        "        for rank, idx in enumerate(indices[0]):\n",
        "            if idx == -1:\n",
        "                continue\n",
        "            item = self.chunk_map[idx]\n",
        "            dist = float(distances[0][rank])\n",
        "            initial_candidates.append({\n",
        "                \"nct_id\": item[\"nct_id\"],\n",
        "                \"text\": item[\"text\"],\n",
        "                \"status\": item[\"status\"],\n",
        "                \"faiss_dist\": dist,\n",
        "            })\n",
        "\n",
        "        final_trials = []\n",
        "        confs = []\n",
        "\n",
        "        # 2. Optional CrossEncoder reranking\n",
        "        if reranker and initial_candidates:\n",
        "            pairs = [[query, cand[\"text\"]] for cand in initial_candidates]\n",
        "            scores = reranker.predict(pairs)\n",
        "\n",
        "            for i, cand in enumerate(initial_candidates):\n",
        "                cand[\"rerank_score\"] = float(scores[i])\n",
        "\n",
        "            initial_candidates.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                logit = item[\"rerank_score\"]\n",
        "                base_conf = 1 / (1 + np.exp(-logit))\n",
        "\n",
        "                scoring_result = self.evidence_scorer.calculate_weighted_score(\n",
        "                    trial=item,\n",
        "                    base_confidence=base_conf,\n",
        "                    query=query,\n",
        "                )\n",
        "\n",
        "                weighted_score = scoring_result[\"weighted_score\"]\n",
        "\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"text\"].split(\"\\n\")[0].replace(\"Title: \", \"\"),\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": base_conf,\n",
        "                    \"weighted_score\": weighted_score,\n",
        "                    \"score_breakdown\": scoring_result[\"breakdown\"],\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"evidence_weighted\",\n",
        "                })\n",
        "\n",
        "            final_trials.sort(key=lambda x: x[\"weighted_score\"], reverse=True)\n",
        "            for i, trial in enumerate(final_trials):\n",
        "                trial[\"rank\"] = i + 1\n",
        "\n",
        "            confs = [t[\"weighted_score\"] for t in final_trials]\n",
        "\n",
        "        else:\n",
        "            # FAISS-only path\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                base_conf = calculate_confidence_score(item[\"faiss_dist\"])\n",
        "                scoring_result = self.evidence_scorer.calculate_weighted_score(\n",
        "                    trial=item,\n",
        "                    base_confidence=base_conf,\n",
        "                    query=query,\n",
        "                )\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"text\"].split(\"\\n\")[0].replace(\"Title: \", \"\"),\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": base_conf,\n",
        "                    \"weighted_score\": scoring_result[\"weighted_score\"],\n",
        "                    \"score_breakdown\": scoring_result[\"breakdown\"],\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"evidence_weighted_faiss\",\n",
        "                })\n",
        "\n",
        "            final_trials.sort(key=lambda x: x[\"weighted_score\"], reverse=True)\n",
        "            for i, trial in enumerate(final_trials):\n",
        "                trial[\"rank\"] = i + 1\n",
        "            confs = [t[\"weighted_score\"] for t in final_trials]\n",
        "\n",
        "        avg_conf = float(np.mean(confs)) if confs else 0.0\n",
        "\n",
        "        retrieval = {\n",
        "            \"query\": query,\n",
        "            \"trials\": final_trials,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "        }\n",
        "\n",
        "        detail = {\n",
        "            \"top_k\": top_k,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"num_trials\": len(final_trials),\n",
        "            \"method\": \"reranked\" if reranker else \"faiss_only\",\n",
        "        }\n",
        "\n",
        "        log = log_provenance_step(\"RetrievalAgent\", parsed, retrieval, detail)\n",
        "        return retrieval, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# DIAGNOSIS / ADVISOR\n",
        "# ============================================================\n",
        "class DiagnosisAdvisor:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def _handle_general_question(self, parsed: Dict[str, Any], retrieved: Dict[str, Any]):\n",
        "        \"\"\"Handle general knowledge questions about diabetes.\"\"\"\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        user_question = parsed.get(\"user_question\") or \" \".join(parsed.get(\"symptoms\", []))\n",
        "\n",
        "        evidence_parts = []\n",
        "        for t in trials[:3]:\n",
        "            evidence_parts.append(f\"Trial {t['nct_id']}: {t['text'][:400]}\")\n",
        "        evidence = \"\\n\\n\".join(evidence_parts) if evidence_parts else \"No specific trials available.\"\n",
        "\n",
        "        prompt = (\n",
        "            \"You are a diabetes health educator. Answer the user's question clearly using your medical knowledge.\\n\"\n",
        "            \"The clinical trial evidence below provides real-world context - mention it if relevant.\\n\\n\"\n",
        "            f\"USER'S QUESTION: {user_question}\\n\\n\"\n",
        "            \"CLINICAL TRIAL CONTEXT (for reference):\\n\"\n",
        "            f\"{evidence}\\n\\n\"\n",
        "            \"Instructions:\\n\"\n",
        "            \"- Answer the question directly in 3-5 sentences\\n\"\n",
        "            \"- Be specific and educational\\n\"\n",
        "            \"- If trials mention relevant findings, cite them briefly\\n\"\n",
        "            \"- End with: 'For personalized advice, please consult your healthcare provider.'\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            text = (res.text or \"\").strip()\n",
        "            if not text or len(text) < 50:\n",
        "                text = (\n",
        "                    \"I don't have enough information to answer this question accurately. \"\n",
        "                    \"Please consult your healthcare provider.\"\n",
        "                )\n",
        "            return text\n",
        "        except Exception:\n",
        "            return \"Unable to generate an answer at this time. Please try rephrasing your question.\"\n",
        "\n",
        "    def _handle_symptom_query(\n",
        "        self,\n",
        "        parsed: Dict[str, Any],\n",
        "        retrieved: Dict[str, Any],\n",
        "        profile: Dict[str, Any],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Generate response for diabetes clinical trial search queries with\n",
        "        readable paragraph summaries and PubMed abstracts when available.\n",
        "        \"\"\"\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        user_input = parsed.get(\"user_question\", \"\")\n",
        "\n",
        "        if not trials:\n",
        "            return \"No relevant trials found. Please try refining your query.\"\n",
        "\n",
        "        formatted_trials = []\n",
        "        for t in trials[:5]:\n",
        "            title = t[\"text\"].split(\"\\n\")[0].replace(\"Title: \", \"\")\n",
        "            status = t.get(\"status\", \"Unknown\")\n",
        "            weighted_score = t.get(\"weighted_score\", 0)\n",
        "\n",
        "            # Extract the ClinicalTrials.gov summary text\n",
        "            raw_text = t.get(\"text\", \"\")\n",
        "            brief_summary = raw_text.split(\"Summary:\", 1)[-1].strip()\n",
        "\n",
        "            if brief_summary:\n",
        "                # Ask Gemini to turn the CT.gov summary into a short paragraph\n",
        "                prompt = (\n",
        "                    \"Rewrite the following clinical trial summary as a short, clear paragraph \"\n",
        "                    \"about what the study is testing regarding diabetes:\\n\\n\"\n",
        "                    f\"{brief_summary}\\n\\n\"\n",
        "                    \"Guidelines:\\n\"\n",
        "                    \"- Use 2‚Äì4 sentences\\n\"\n",
        "                    \"- Plain English\\n\"\n",
        "                    \"- Include purpose and who it‚Äôs for\\n\"\n",
        "                    \"- Minimize jargon\\n\"\n",
        "                )\n",
        "                try:\n",
        "                    res = self.model.generate_content(prompt)\n",
        "                    brief_summary = res.text.strip() if res.text else brief_summary\n",
        "                except Exception:\n",
        "                    if len(brief_summary) > 600:\n",
        "                        brief_summary = brief_summary[:600] + \"...\"\n",
        "            else:\n",
        "                brief_summary = \"No summary available.\"\n",
        "\n",
        "            # NEW: PubMed abstract lookup (raw, not summarized)\n",
        "            pubmed_block = \"\"\n",
        "            pub = fetch_pubmed_abstract_for_nct(t[\"nct_id\"])\n",
        "            if pub:\n",
        "                abs_text = pub[\"abstract\"]\n",
        "                # Limit length so the UI doesn't explode; still show most of it\n",
        "                max_len = 2000\n",
        "                if len(abs_text) > max_len:\n",
        "                    abs_text = abs_text[:max_len] + \"...\"\n",
        "                pubmed_block = (\n",
        "                    f\"  PubMed abstract (PMID {pub['pmid']}):\\n\"\n",
        "                    f\"  {abs_text}\\n\\n\"\n",
        "                    f\"  PubMed link: https://pubmed.ncbi.nlm.nih.gov/{pub['pmid']}/\\n\\n\"\n",
        "                )\n",
        "\n",
        "            formatted_trials.append(\n",
        "                f\"**{t['nct_id']}** (Relevance: {weighted_score:.0%})\\n\"\n",
        "                f\"‚Ä¢ {title}\\n\"\n",
        "                f\"  Status: {status}\\n\\n\"\n",
        "                f\"  {brief_summary}\\n\\n\"\n",
        "                f\"{pubmed_block}\"\n",
        "            )\n",
        "\n",
        "        trials_text = \"\\n\\n\".join(formatted_trials)\n",
        "        num_trials = len(formatted_trials)\n",
        "\n",
        "        response = (\n",
        "            f\"I found {num_trials} diabetes clinical trial\"\n",
        "            f\"{'s' if num_trials != 1 else ''} relevant to your request:\\n\\n\"\n",
        "            f\"{trials_text}\\n\\n\"\n",
        "            \"Summary: These trials explore diabetes treatments and management. \"\n",
        "            \"More details are available using the listed NCT IDs.\\n\\n\"\n",
        "            \"To learn more or participate, visit clinicaltrials.gov and search by NCT ID. \"\n",
        "            \"Discuss with your healthcare provider before enrolling.\"\n",
        "        )\n",
        "\n",
        "        return response\n",
        "\n",
        "    def advise(self, parsed: Dict[str, Any], retrieved: Dict[str, Any], profile: Dict[str, Any]):\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        avg_conf = retrieved.get(\"avg_confidence\", 0.0)\n",
        "        query_type = parsed.get(\"query_type\", \"symptom_matching\")\n",
        "        is_diabetes_related = parsed.get(\"is_diabetes_related\", True)\n",
        "\n",
        "        draft = {\n",
        "            \"recommendation\": \"\",\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"query_type\": query_type,\n",
        "        }\n",
        "\n",
        "        if not is_diabetes_related:\n",
        "            draft[\"recommendation\"] = (\n",
        "                \"I'm specialized in diabetes-related clinical trials. Your query appears to be \"\n",
        "                \"about symptoms or conditions not directly related to diabetes. \"\n",
        "                \"If you have diabetes-related questions or symptoms (like high blood sugar, \"\n",
        "                \"insulin management, complications, etc.), I'd be happy to help! \"\n",
        "                \"Otherwise, please consult your healthcare provider for your current symptoms.\"\n",
        "            )\n",
        "            draft[\"confidence_veto\"] = True\n",
        "            log = log_provenance_step(\n",
        "                \"DiagnosisAdvisor\",\n",
        "                parsed,\n",
        "                draft,\n",
        "                {\"veto\": True, \"reason\": \"off_topic\"},\n",
        "            )\n",
        "            return draft, log\n",
        "\n",
        "        if not trials or avg_conf < 0.05:\n",
        "            draft[\"recommendation\"] = (\n",
        "                \"EVIDENCE IS INSUFFICIENT TO ANSWER THIS QUESTION DIRECTLY based on the \"\n",
        "                \"retrieved clinical trials. Please consult your healthcare provider.\"\n",
        "            )\n",
        "            draft[\"confidence_veto\"] = True\n",
        "            log = log_provenance_step(\n",
        "                \"DiagnosisAdvisor\",\n",
        "                parsed,\n",
        "                draft,\n",
        "                {\"veto\": True, \"reason\": \"low_confidence\"},\n",
        "            )\n",
        "            return draft, log\n",
        "\n",
        "        if query_type == \"knowledge_seeking\":\n",
        "            draft[\"recommendation\"] = self._handle_general_question(parsed, retrieved)\n",
        "        else:\n",
        "            draft[\"recommendation\"] = self._handle_symptom_query(parsed, retrieved, profile)\n",
        "\n",
        "        draft[\"confidence_veto\"] = False\n",
        "        log = log_provenance_step(\"DiagnosisAdvisor\", parsed, draft)\n",
        "        return draft, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SAFETY FILTER\n",
        "# ============================================================\n",
        "class ActiveSafetyFilter:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.safety_cfg = {\n",
        "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "        }\n",
        "\n",
        "    def verify(self, advice_text: str, trials: List[Dict[str, Any]]):\n",
        "        # Skip safety check for trial listing-style responses\n",
        "        if any(marker in advice_text for marker in [\"NCT\", \"clinical trial\", \"clinicaltrials.gov\"]):\n",
        "            log = log_provenance_step(\n",
        "                \"ActiveSafetyFilter\",\n",
        "                {\"advice\": advice_text},\n",
        "                {\"final_text\": advice_text, \"status\": \"Pass (Trial Listing)\"},\n",
        "            )\n",
        "            return advice_text, \"Pass (Trial Listing)\", log\n",
        "\n",
        "        evidence_text = \"\\n\".join(t[\"text\"][:500] for t in trials[:3])\n",
        "\n",
        "        audit_prompt = (\n",
        "            \"You are a Medical Safety Officer reviewing AI-generated advice.\\n\\n\"\n",
        "            \"ADVICE:\\n\"\n",
        "            f\"{advice_text}\\n\\n\"\n",
        "            \"EVIDENCE FROM CLINICAL TRIALS:\\n\"\n",
        "            f\"{evidence_text}\\n\\n\"\n",
        "            \"Check for safety issues:\\n\"\n",
        "            \"- If the advice suggests stopping or changing medication without a doctor ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it gives a diagnosis ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it makes claims not supported by the evidence ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it just lists clinical trials with disclaimers ‚Üí SAFE.\\n\\n\"\n",
        "            \"If the advice is acceptable, respond with exactly: SAFE\\n\"\n",
        "            \"If it is not acceptable, respond starting with: CORRECTED: <safer version>\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(audit_prompt, safety_settings=self.safety_cfg)\n",
        "            txt = (res.text or \"\").strip()\n",
        "            if txt.startswith(\"SAFE\") or \"SAFE\" in txt:\n",
        "                final_text = advice_text\n",
        "                status = \"Pass\"\n",
        "            else:\n",
        "                final_text = f\"‚ö†Ô∏è SAFETY REVISION:\\n{txt}\"\n",
        "                status = \"Revised\"\n",
        "        except Exception:\n",
        "            if \"NCT\" in advice_text or \"clinical trial\" in advice_text.lower():\n",
        "                final_text = advice_text\n",
        "                status = \"Pass (API Fallback)\"\n",
        "            else:\n",
        "                final_text = \"‚ö†Ô∏è Safety filter triggered. Please consult a doctor.\"\n",
        "                status = \"Revised (API Error)\"\n",
        "\n",
        "        log = log_provenance_step(\n",
        "            \"ActiveSafetyFilter\",\n",
        "            {\"advice\": advice_text},\n",
        "            {\"final_text\": final_text, \"status\": status},\n",
        "        )\n",
        "        return final_text, status, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# HEALTHCARE BOT (Orchestrator)\n",
        "# ============================================================\n",
        "class HealthcareBot:\n",
        "    def __init__(self, gemini_model, embed_model, faiss_index, chunk_map, initial_profile=None):\n",
        "        self.parser = SymptomParser(gemini_model)\n",
        "        self.profile_agent = ProfileAgent(initial_profile)\n",
        "        self.retriever = RetrievalAgent(embed_model, faiss_index, chunk_map, self.profile_agent)\n",
        "        self.advisor = DiagnosisAdvisor(gemini_model)\n",
        "        self.safety = ActiveSafetyFilter(gemini_model)\n",
        "\n",
        "        self.history: List[Dict[str, Any]] = []\n",
        "        self.provenance_chain: List[Dict[str, Any]] = []\n",
        "\n",
        "    def _handle_simple_greeting(self, user_input: str):\n",
        "        user_id = self.profile_agent.profile.get(\"user_id\", \"there\")\n",
        "        msg = (\n",
        "            f\"Hello {user_id}! I'm your **Clinical Trial Research Assistant** for diabetes. üî¨\\n\\n\"\n",
        "            \"I can help you find relevant diabetes clinical trials from a database of **22,000+ studies**.\\n\\n\"\n",
        "            \"**Try asking:**\\n\"\n",
        "            \"- 'What trials are studying insulin therapy?'\\n\"\n",
        "            \"- 'Show me trials about low-carb diets'\\n\"\n",
        "            \"- 'Are there trials testing new medications?'\\n\"\n",
        "            \"- 'I'm 55 with type 2 diabetes, what trials can I join?'\\n\\n\"\n",
        "            \"I search real trial data from ClinicalTrials.gov. How can I help you explore diabetes research today?\"\n",
        "        )\n",
        "\n",
        "        log = log_provenance_step(\"GreetingAgent\", user_input, msg, {\"type\": \"greeting\"})\n",
        "        self.provenance_chain.append(log)\n",
        "\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "        self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": msg,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Non-RAG\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "    def _handle_off_topic(self, user_input: str, parsed: Dict[str, Any]):\n",
        "        msg = (\n",
        "            \"I'm specialized in diabetes-related clinical trials. Your query appears to be \"\n",
        "            \"about symptoms or conditions not directly related to diabetes. \"\n",
        "            \"If you have diabetes-related questions, I'd be happy to help!\"\n",
        "        )\n",
        "        log = log_provenance_step(\"OffTopicHandler\", user_input, msg, {\"type\": \"off_topic\"})\n",
        "        self.provenance_chain.append(log)\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": msg,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Off-topic\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "    def _handle_knowledge_question(self, user_input: str, parsed: Dict[str, Any]):\n",
        "        user_question = parsed.get(\"user_question\", user_input)\n",
        "        prompt = (\n",
        "            \"You are a certified diabetes educator. Answer this question clearly and accurately.\\n\"\n",
        "            f\"QUESTION: {user_question}\\n\"\n",
        "        )\n",
        "        try:\n",
        "            res = self.advisor.model.generate_content(prompt)\n",
        "            answer = (res.text or \"\").strip()\n",
        "        except Exception:\n",
        "            answer = \"Unable to answer at this time.\"\n",
        "\n",
        "        log = log_provenance_step(\"KnowledgeAgent\", user_input, answer, {\"type\": \"general_knowledge\"})\n",
        "        self.provenance_chain.append(log)\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": answer,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Knowledge-Based\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "    def _handle_generic_trial_query(self, user_input: str, parsed: Dict[str, Any]):\n",
        "        \"\"\"Handle generic queries that need more specificity.\"\"\"\n",
        "        msg = (\n",
        "            \"I found that question a bit broad. I have 22,000+ diabetes trials in my database. \"\n",
        "            \"To help you better, could you specify:\\n\\n\"\n",
        "            \"**Drug/Medication Trials:**\\n\"\n",
        "            \"- Specific drugs: 'trials testing metformin', 'liraglutide trials'\\n\"\n",
        "            \"- Drug classes: 'GLP-1 trials', 'SGLT2 inhibitor trials'\\n\"\n",
        "            \"- Insulin: 'insulin pump trials', 'insulin therapy trials'\\n\\n\"\n",
        "            \"**Lifestyle Trials:**\\n\"\n",
        "            \"- Diet: 'low-carb diet trials', 'Mediterranean diet trials'\\n\"\n",
        "            \"- Exercise: 'physical activity trials', 'exercise trials'\\n\\n\"\n",
        "            \"**Technology Trials:**\\n\"\n",
        "            \"- Monitoring: 'CGM trials', 'glucose monitoring trials'\\n\"\n",
        "            \"- Apps: 'diabetes app trials', 'digital health trials'\\n\\n\"\n",
        "            \"**Or describe your situation:**\\n\"\n",
        "            \"- 'I'm 55 with type 2 diabetes, what trials can I join?'\\n\"\n",
        "            \"- 'Trials for managing high blood sugar'\\n\\n\"\n",
        "            \"What would you like to explore?\"\n",
        "        )\n",
        "\n",
        "        log = log_provenance_step(\"GenericQueryHandler\", user_input, msg, {\"type\": \"needs_refinement\"})\n",
        "        self.provenance_chain.append(log)\n",
        "\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "        self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": msg,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Refinement Needed\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "    def process_query(self, user_input: str):\n",
        "        self.provenance_chain = []\n",
        "\n",
        "        # 1. Parse\n",
        "        parsed, parse_log = self.parser.parse(user_input)\n",
        "        self.provenance_chain.append(parse_log)\n",
        "\n",
        "        intent = (parsed.get(\"intent\") or \"trial_search\").lower()\n",
        "        query_type = parsed.get(\"query_type\", \"trial_query\")\n",
        "        is_diabetes_related = parsed.get(\"is_diabetes_related\", True)\n",
        "\n",
        "        # Greetings\n",
        "        if intent == \"greeting\":\n",
        "            return self._handle_simple_greeting(user_input)\n",
        "\n",
        "        # Off-topic\n",
        "        if intent == \"off_topic\" or not is_diabetes_related:\n",
        "            return self._handle_off_topic(user_input, parsed)\n",
        "\n",
        "        # Profile info\n",
        "        if intent == \"profile_info\":\n",
        "            msg = (\n",
        "                \"Thank you for sharing your information. I've noted your details. \"\n",
        "                \"What type of clinical trials would you like to explore? \"\n",
        "                \"For example: 'Show me trials about diet management' or 'What trials test new medications?'\"\n",
        "            )\n",
        "            log = log_provenance_step(\"ProfileAgent\", user_input, msg, {\"action\": \"profile_stored\"})\n",
        "            self.provenance_chain.append(log)\n",
        "\n",
        "            session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "            return {\n",
        "                \"recommendation\": msg,\n",
        "                \"cited_trials\": [],\n",
        "                \"safety_status\": \"Profile Update\",\n",
        "                \"session_hash\": session_hash,\n",
        "                \"provenance_chain\": self.provenance_chain,\n",
        "            }\n",
        "\n",
        "        # Pure education (no trial search)\n",
        "        if intent == \"general_question\" and query_type == \"knowledge_seeking\":\n",
        "            if \"trial\" not in user_input.lower() and \"study\" not in user_input.lower():\n",
        "                return self._handle_knowledge_question(user_input, parsed)\n",
        "\n",
        "        # DEFAULT: trial search\n",
        "        retrieved, retrieve_log = self.retriever.retrieve(parsed)\n",
        "        self.provenance_chain.append(retrieve_log)\n",
        "\n",
        "        # Generic query detection\n",
        "        generic_terms = [\"new\", \"any\", \"some\", \"recent\", \"latest\", \"medications\", \"trials\", \"studies\"]\n",
        "        is_generic = sum(1 for term in generic_terms if term in user_input.lower()) >= 2\n",
        "\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        avg_conf = retrieved.get(\"avg_confidence\", 0.0)\n",
        "        top_score = trials[0][\"weighted_score\"] if trials else 0.0\n",
        "\n",
        "        if is_generic and (avg_conf < 0.50 or top_score < 0.55):\n",
        "            return self._handle_generic_trial_query(user_input, parsed)\n",
        "\n",
        "        # 3. Advisor\n",
        "        draft_advice, advise_log = self.advisor.advise(parsed, retrieved, self.profile_agent.profile)\n",
        "        self.provenance_chain.append(advise_log)\n",
        "\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        if draft_advice.get(\"confidence_veto\", False) or not trials:\n",
        "            final_text = draft_advice[\"recommendation\"]\n",
        "            safety_status = \"Vetoed (Low Confidence)\"\n",
        "            evidence_list = []\n",
        "        else:\n",
        "            final_text, safety_status, safety_log = self.safety.verify(draft_advice[\"recommendation\"], trials)\n",
        "            self.provenance_chain.append(safety_log)\n",
        "            evidence_list = trials\n",
        "\n",
        "        nct_ids = [t[\"nct_id\"] for t in evidence_list]\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "        # Update profile/history\n",
        "        turn_data = {\n",
        "            \"query\": user_input,\n",
        "            \"parsed\": parsed,\n",
        "            \"nct_ids\": nct_ids,\n",
        "            \"safety_status\": safety_status,\n",
        "            \"session_hash\": session_hash,\n",
        "        }\n",
        "        profile_log = self.profile_agent.update_profile(turn_data)\n",
        "        self.provenance_chain.append(profile_log)\n",
        "        self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": final_text,\n",
        "            \"cited_trials\": nct_ids,\n",
        "            \"safety_status\": safety_status,\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# GLOBAL BOT INSTANCE + ENTRYPOINT\n",
        "# ============================================================\n",
        "default_profile = {\n",
        "    \"user_id\": \"Patient\",\n",
        "    \"conditions\": [\"diabetes\"],\n",
        "    \"extracted_conditions\": [],\n",
        "}\n",
        "\n",
        "_bot = HealthcareBot(gemini_model, embed_model, faiss_index, chunk_map, initial_profile=default_profile)\n",
        "\n",
        "def run_bot(user_input: str) -> Dict[str, Any]:\n",
        "    return _bot.process_query(user_input)\n"
      ],
      "metadata": {
        "id": "adDqKGc-piM1",
        "outputId": "02a48b19-a115-4a10-ee22-fd015a565033",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run_bot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UI frontend application simple web interface\n",
        "\n",
        "https://docs.streamlit.io/develop/tutorials/chat-and-llm-apps/build-conversational-apps"
      ],
      "metadata": {
        "id": "mDxpjMNrCwCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "\n",
        "if \"GEMINI_API_KEY\" not in os.environ:\n",
        "    st.error(\"‚ö†Ô∏è API Key missing! Please run the 'Secure Input' cell in the notebook first.\")\n",
        "\n",
        "from run_bot import run_bot\n",
        "\n",
        "st.title(\"Clinical Trial Health Advisor ü§ñ\")\n",
        "st.caption(\"AI for Healthcare - Clinical Trials RAG\")\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "for msg in st.session_state.messages:\n",
        "    with st.chat_message(msg[\"role\"]):\n",
        "        st.markdown(msg[\"content\"])\n",
        "\n",
        "if user_input := st.chat_input(\"Describe your symptoms...\"):\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(user_input)\n",
        "\n",
        "    with st.spinner(\"Searching clinical trials...\"):\n",
        "        result = run_bot(user_input)\n",
        "        reply = result[\"recommendation\"]\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(reply)\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": reply})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EqkmxVqOkZ-",
        "outputId": "6ab97dfd-782d-48e9-b8cf-a4f291d2a94a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 cloudflared\n",
        "!chmod +x cloudflared"
      ],
      "metadata": {
        "id": "u5BcqHNUOklc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AI LLM\n",
        "!streamlit run app.py &>/dev/null&\n",
        "!./cloudflared tunnel --url http://localhost:8501 --no-autoupdate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZqn_TJIOkuT",
        "outputId": "42588b0e-aae5-453a-97ad-7f4fbb75d16b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-11-27T07:07:11Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-11-27T07:07:11Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m |  https://colored-cooler-chicago-admitted.trycloudflare.com                                 |\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 991dffd8889ee9f0147b6b48933da9e4407e68ea8c6d984f55fa2d3db4bb431d)\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 8215536a-9eb4-465b-91b9-7d934bb274cb\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "2025/11/27 07:07:17 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-11-27T07:07:17Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m5eb885ef-fdde-4fa6-9267-3372193ed383 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113 \u001b[36mlocation=\u001b[0msin07 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-11-27T07:09:38Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2025-11-27T07:09:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to run the datagram handler \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "\u001b[90m2025-11-27T07:09:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "\u001b[90m2025-11-27T07:09:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Serve tunnel error \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "\u001b[90m2025-11-27T07:09:38Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "\u001b[90m2025-11-27T07:09:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Connection terminated \u001b[36mconnIndex=\u001b[0m0\n",
            "\u001b[90m2025-11-27T07:09:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2025-11-27T07:09:38Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2025-11-27T07:09:38Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from run_bot import run_bot\n",
        "\n",
        "print(run_bot(\"What trials are studying insulin therapy?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "KxW5Cm8QFFC1",
        "outputId": "66a20f53-b123-40f2-eab3-96f904be937c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 905.80ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 378.33ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 302.26ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 303.42ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 302.74ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 277.42ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'recommendation': 'I found 5 diabetes clinical trials relevant to your request:\\n\\n**NCT00115973** (Relevance: 71%)\\n‚Ä¢ A Study of the Treatment of Type 2 Diabetes With an Insulin Infusion Pump\\n  Status: Completed\\n\\n  This trial is conducted in the United States of America (USA). This is an in-patient trial investigating stepwise dose increase in a period of up to 3-weeks followed by a 10-week out-patient maintenance period. A telephone contact visit is scheduled as a follow-up for the final clinic visit. A subject\\'s participation in this trial would be expected to be up to 16 weeks.\\n\\n**NCT04981808** (Relevance: 71%)\\n‚Ä¢ Diabetes teleMonitoring of Patients in Insulin Therapy\\n  Status: Completed\\n\\n  The trial is an open-label randomized controlled trial. Patients with T2D on insulin therapy will be randomized to a telemonitoring group (intervention) and a usual care group (control). The telemonitoring group will use various devices at home. Hospital staff will monitor their data for a period of three months.\\n\\n**NCT00922649** (Relevance: 70%)\\n‚Ä¢ Pilot Study Assessing Insulin Pump Therapy in Type 2 Diabetes\\n  Status: Completed\\n\\n  16-week, open-label, multi-center pilot study. Insulin pump na√Øve subjects with type 2 diabetes who are not achieving glycemic targets (screening A1C ‚â• 7.0%) on an established regimen of either: 1) ‚â• 2 OAs (Cohort A), 2) basal insulin ¬± OAs (Cohort B), or 3) basal-bolus insulin ¬± OAs (Cohort C) will initiate basal-bolus therapy with an insulin pump using a rapid-acting insulin analog.\\n\\n**NCT00841919** (Relevance: 68%)\\n‚Ä¢ Insulin Therapy in the Hospital Comparing Two Protocols\\n  Status: Completed\\n\\n  The purpose of this study is to determine if by using insulin analog (Glargine and lispro insulin) with an insulin pen the investigators are able to obtain a higher rate of correct timing of insulin and food administration as when compared to the usual therapy (insulin NPH and regular) with syringes.\\n\\n**NCT00537303** (Relevance: 67%)\\n‚Ä¢ Comparison of the Blood Sugar Lowering Effect and Safety of Two Insulin Treatments in Type 2 Diabetes\\n  Status: Completed\\n\\n  This trial is conducted in Europe, Africa and the United States of America (USA).\\n\\nThe aim of this trial is to compare the safety and efficacy of two different insulin treatments, the \"basic\" and the \"advanced\" treatment in type 2 diabetes.\\n\\nTo learn more or participate, visit clinicaltrials.gov and search by NCT ID. Discuss with your healthcare provider before enrolling.', 'cited_trials': ['NCT00115973', 'NCT04981808', 'NCT00922649', 'NCT00841919', 'NCT00537303'], 'safety_status': 'Pass (Trial Listing)', 'session_hash': '6e3aa2ba6e5cc74f7f4c5b4b4f7e0e29', 'provenance_chain': [{'timestamp': '2025-11-27T07:06:49.470666', 'agent': 'SymptomParser', 'input': 'What trials are studying insulin therapy?', 'output': {'intent': 'trial_search', 'query_type': 'trial_query', 'search_keywords': ['What trials are studying insulin therapy?'], 'is_diabetes_related': True, 'user_question': 'What trials are studying insulin therapy?', 'trial_interest': 'general'}, 'detail': {}, 'model_version': 'gemini-2.0-flash'}, {'timestamp': '2025-11-27T07:06:49.566899', 'agent': 'RetrievalAgent', 'input': {'intent': 'trial_search', 'query_type': 'trial_query', 'search_keywords': ['What trials are studying insulin therapy?'], 'is_diabetes_related': True, 'user_question': 'What trials are studying insulin therapy?', 'trial_interest': 'general'}, 'output': {'query': 'What trials are studying insulin therapy? insulin OR insulin therapy OR insulin treatment OR insulin pump', 'trials': [{'nct_id': 'NCT00115973', 'title': 'A Study of the Treatment of Type 2 Diabetes With an Insulin Infusion Pump', 'text': \"Title: A Study of the Treatment of Type 2 Diabetes With an Insulin Infusion Pump\\nSummary: This trial is conducted in the United States of America (USA). This is an in-patient trial investigating stepwise dose increase in a period of up to 3-weeks followed by a 10-week out-patient maintenance period. A telephone contact visit is scheduled as a follow-up for the final clinic visit. A subject's participation in this trial would be expected to be up to 16 weeks.\", 'status': 'Completed', 'confidence': np.float64(0.9822955644614827), 'weighted_score': np.float64(0.7138034475615189), 'score_breakdown': {'base_confidence': np.float64(0.9822955644614827), 'weighted_score': np.float64(0.7138034475615189), 'factors': {'semantic_match': np.float64(0.3438034475615189), 'trial_status': 0.25, 'study_design': 0.12, 'keyword_density': 0.0, 'completeness': 0.0}}, 'rank': 1, 'method': 'evidence_weighted'}, {'nct_id': 'NCT04981808', 'title': 'Diabetes teleMonitoring of Patients in Insulin Therapy', 'text': 'Title: Diabetes teleMonitoring of Patients in Insulin Therapy\\nSummary: The trial is an open-label randomized controlled trial. Patients with T2D on insulin therapy will be randomized to a telemonitoring group (intervention) and a usual care group (control). The telemonitoring group will use various devices at home. Hospital staff will monitor their data for a period of three months.', 'status': 'Completed', 'confidence': np.float64(0.9589146717722865), 'weighted_score': np.float64(0.7056201351203003), 'score_breakdown': {'base_confidence': np.float64(0.9589146717722865), 'weighted_score': np.float64(0.7056201351203003), 'factors': {'semantic_match': np.float64(0.33562013512030026), 'trial_status': 0.25, 'study_design': 0.12, 'keyword_density': 0.0, 'completeness': 0.0}}, 'rank': 2, 'method': 'evidence_weighted'}, {'nct_id': 'NCT00922649', 'title': 'Pilot Study Assessing Insulin Pump Therapy in Type 2 Diabetes', 'text': 'Title: Pilot Study Assessing Insulin Pump Therapy in Type 2 Diabetes\\nSummary: 16-week, open-label, multi-center pilot study. Insulin pump na√Øve subjects with type 2 diabetes who are not achieving glycemic targets (screening A1C ‚â• 7.0%) on an established regimen of either: 1) ‚â• 2 OAs (Cohort A), 2) basal insulin ¬± OAs (Cohort B), or 3) basal-bolus insulin ¬± OAs (Cohort C) will initiate basal-bolus therapy with an insulin pump using a rapid-acting insulin analog.', 'status': 'Completed', 'confidence': np.float64(0.9332271745652748), 'weighted_score': np.float64(0.6966295110978461), 'score_breakdown': {'base_confidence': np.float64(0.9332271745652748), 'weighted_score': np.float64(0.6966295110978461), 'factors': {'semantic_match': np.float64(0.32662951109784616), 'trial_status': 0.25, 'study_design': 0.12, 'keyword_density': 0.0, 'completeness': 0.0}}, 'rank': 3, 'method': 'evidence_weighted'}, {'nct_id': 'NCT00841919', 'title': 'Insulin Therapy in the Hospital Comparing Two Protocols', 'text': 'Title: Insulin Therapy in the Hospital Comparing Two Protocols\\nSummary: The purpose of this study is to determine if by using insulin analog (Glargine and lispro insulin) with an insulin pen the investigators are able to obtain a higher rate of correct timing of insulin and food administration as when compared to the usual therapy (insulin NPH and regular) with syringes.', 'status': 'Completed', 'confidence': np.float64(0.8892666641237863), 'weighted_score': np.float64(0.6812433324433252), 'score_breakdown': {'base_confidence': np.float64(0.8892666641237863), 'weighted_score': np.float64(0.6812433324433252), 'factors': {'semantic_match': np.float64(0.3112433324433252), 'trial_status': 0.25, 'study_design': 0.12, 'keyword_density': 0.0, 'completeness': 0.0}}, 'rank': 4, 'method': 'evidence_weighted'}, {'nct_id': 'NCT00537303', 'title': 'Comparison of the Blood Sugar Lowering Effect and Safety of Two Insulin Treatments in Type 2 Diabetes', 'text': 'Title: Comparison of the Blood Sugar Lowering Effect and Safety of Two Insulin Treatments in Type 2 Diabetes\\nSummary: This trial is conducted in Europe, Africa and the United States of America (USA).\\n\\nThe aim of this trial is to compare the safety and efficacy of two different insulin treatments, the \"basic\" and the \"advanced\" treatment in type 2 diabetes.', 'status': 'Completed', 'confidence': np.float64(0.8454603202487386), 'weighted_score': np.float64(0.6659111120870586), 'score_breakdown': {'base_confidence': np.float64(0.8454603202487386), 'weighted_score': np.float64(0.6659111120870586), 'factors': {'semantic_match': np.float64(0.2959111120870585), 'trial_status': 0.25, 'study_design': 0.12, 'keyword_density': 0.0, 'completeness': 0.0}}, 'rank': 5, 'method': 'evidence_weighted'}], 'avg_confidence': 0.6926415076620098}, 'detail': {'top_k': 5, 'avg_confidence': 0.6926415076620098, 'num_trials': 5, 'method': 'reranked'}, 'model_version': 'gemini-2.0-flash'}, {'timestamp': '2025-11-27T07:06:51.149961', 'agent': 'DiagnosisAdvisor', 'input': {'intent': 'trial_search', 'query_type': 'trial_query', 'search_keywords': ['What trials are studying insulin therapy?'], 'is_diabetes_related': True, 'user_question': 'What trials are studying insulin therapy?', 'trial_interest': 'general'}, 'output': {'recommendation': 'I found 5 diabetes clinical trials relevant to your request:\\n\\n**NCT00115973** (Relevance: 71%)\\n‚Ä¢ A Study of the Treatment of Type 2 Diabetes With an Insulin Infusion Pump\\n  Status: Completed\\n\\n  This trial is conducted in the United States of America (USA). This is an in-patient trial investigating stepwise dose increase in a period of up to 3-weeks followed by a 10-week out-patient maintenance period. A telephone contact visit is scheduled as a follow-up for the final clinic visit. A subject\\'s participation in this trial would be expected to be up to 16 weeks.\\n\\n**NCT04981808** (Relevance: 71%)\\n‚Ä¢ Diabetes teleMonitoring of Patients in Insulin Therapy\\n  Status: Completed\\n\\n  The trial is an open-label randomized controlled trial. Patients with T2D on insulin therapy will be randomized to a telemonitoring group (intervention) and a usual care group (control). The telemonitoring group will use various devices at home. Hospital staff will monitor their data for a period of three months.\\n\\n**NCT00922649** (Relevance: 70%)\\n‚Ä¢ Pilot Study Assessing Insulin Pump Therapy in Type 2 Diabetes\\n  Status: Completed\\n\\n  16-week, open-label, multi-center pilot study. Insulin pump na√Øve subjects with type 2 diabetes who are not achieving glycemic targets (screening A1C ‚â• 7.0%) on an established regimen of either: 1) ‚â• 2 OAs (Cohort A), 2) basal insulin ¬± OAs (Cohort B), or 3) basal-bolus insulin ¬± OAs (Cohort C) will initiate basal-bolus therapy with an insulin pump using a rapid-acting insulin analog.\\n\\n**NCT00841919** (Relevance: 68%)\\n‚Ä¢ Insulin Therapy in the Hospital Comparing Two Protocols\\n  Status: Completed\\n\\n  The purpose of this study is to determine if by using insulin analog (Glargine and lispro insulin) with an insulin pen the investigators are able to obtain a higher rate of correct timing of insulin and food administration as when compared to the usual therapy (insulin NPH and regular) with syringes.\\n\\n**NCT00537303** (Relevance: 67%)\\n‚Ä¢ Comparison of the Blood Sugar Lowering Effect and Safety of Two Insulin Treatments in Type 2 Diabetes\\n  Status: Completed\\n\\n  This trial is conducted in Europe, Africa and the United States of America (USA).\\n\\nThe aim of this trial is to compare the safety and efficacy of two different insulin treatments, the \"basic\" and the \"advanced\" treatment in type 2 diabetes.\\n\\nTo learn more or participate, visit clinicaltrials.gov and search by NCT ID. Discuss with your healthcare provider before enrolling.', 'avg_confidence': 0.6926415076620098, 'query_type': 'trial_query', 'confidence_veto': False}, 'detail': {}, 'model_version': 'gemini-2.0-flash'}, {'timestamp': '2025-11-27T07:06:51.149995', 'agent': 'ActiveSafetyFilter', 'input': {'advice': 'I found 5 diabetes clinical trials relevant to your request:\\n\\n**NCT00115973** (Relevance: 71%)\\n‚Ä¢ A Study of the Treatment of Type 2 Diabetes With an Insulin Infusion Pump\\n  Status: Completed\\n\\n  This trial is conducted in the United States of America (USA). This is an in-patient trial investigating stepwise dose increase in a period of up to 3-weeks followed by a 10-week out-patient maintenance period. A telephone contact visit is scheduled as a follow-up for the final clinic visit. A subject\\'s participation in this trial would be expected to be up to 16 weeks.\\n\\n**NCT04981808** (Relevance: 71%)\\n‚Ä¢ Diabetes teleMonitoring of Patients in Insulin Therapy\\n  Status: Completed\\n\\n  The trial is an open-label randomized controlled trial. Patients with T2D on insulin therapy will be randomized to a telemonitoring group (intervention) and a usual care group (control). The telemonitoring group will use various devices at home. Hospital staff will monitor their data for a period of three months.\\n\\n**NCT00922649** (Relevance: 70%)\\n‚Ä¢ Pilot Study Assessing Insulin Pump Therapy in Type 2 Diabetes\\n  Status: Completed\\n\\n  16-week, open-label, multi-center pilot study. Insulin pump na√Øve subjects with type 2 diabetes who are not achieving glycemic targets (screening A1C ‚â• 7.0%) on an established regimen of either: 1) ‚â• 2 OAs (Cohort A), 2) basal insulin ¬± OAs (Cohort B), or 3) basal-bolus insulin ¬± OAs (Cohort C) will initiate basal-bolus therapy with an insulin pump using a rapid-acting insulin analog.\\n\\n**NCT00841919** (Relevance: 68%)\\n‚Ä¢ Insulin Therapy in the Hospital Comparing Two Protocols\\n  Status: Completed\\n\\n  The purpose of this study is to determine if by using insulin analog (Glargine and lispro insulin) with an insulin pen the investigators are able to obtain a higher rate of correct timing of insulin and food administration as when compared to the usual therapy (insulin NPH and regular) with syringes.\\n\\n**NCT00537303** (Relevance: 67%)\\n‚Ä¢ Comparison of the Blood Sugar Lowering Effect and Safety of Two Insulin Treatments in Type 2 Diabetes\\n  Status: Completed\\n\\n  This trial is conducted in Europe, Africa and the United States of America (USA).\\n\\nThe aim of this trial is to compare the safety and efficacy of two different insulin treatments, the \"basic\" and the \"advanced\" treatment in type 2 diabetes.\\n\\nTo learn more or participate, visit clinicaltrials.gov and search by NCT ID. Discuss with your healthcare provider before enrolling.'}, 'output': {'final_text': 'I found 5 diabetes clinical trials relevant to your request:\\n\\n**NCT00115973** (Relevance: 71%)\\n‚Ä¢ A Study of the Treatment of Type 2 Diabetes With an Insulin Infusion Pump\\n  Status: Completed\\n\\n  This trial is conducted in the United States of America (USA). This is an in-patient trial investigating stepwise dose increase in a period of up to 3-weeks followed by a 10-week out-patient maintenance period. A telephone contact visit is scheduled as a follow-up for the final clinic visit. A subject\\'s participation in this trial would be expected to be up to 16 weeks.\\n\\n**NCT04981808** (Relevance: 71%)\\n‚Ä¢ Diabetes teleMonitoring of Patients in Insulin Therapy\\n  Status: Completed\\n\\n  The trial is an open-label randomized controlled trial. Patients with T2D on insulin therapy will be randomized to a telemonitoring group (intervention) and a usual care group (control). The telemonitoring group will use various devices at home. Hospital staff will monitor their data for a period of three months.\\n\\n**NCT00922649** (Relevance: 70%)\\n‚Ä¢ Pilot Study Assessing Insulin Pump Therapy in Type 2 Diabetes\\n  Status: Completed\\n\\n  16-week, open-label, multi-center pilot study. Insulin pump na√Øve subjects with type 2 diabetes who are not achieving glycemic targets (screening A1C ‚â• 7.0%) on an established regimen of either: 1) ‚â• 2 OAs (Cohort A), 2) basal insulin ¬± OAs (Cohort B), or 3) basal-bolus insulin ¬± OAs (Cohort C) will initiate basal-bolus therapy with an insulin pump using a rapid-acting insulin analog.\\n\\n**NCT00841919** (Relevance: 68%)\\n‚Ä¢ Insulin Therapy in the Hospital Comparing Two Protocols\\n  Status: Completed\\n\\n  The purpose of this study is to determine if by using insulin analog (Glargine and lispro insulin) with an insulin pen the investigators are able to obtain a higher rate of correct timing of insulin and food administration as when compared to the usual therapy (insulin NPH and regular) with syringes.\\n\\n**NCT00537303** (Relevance: 67%)\\n‚Ä¢ Comparison of the Blood Sugar Lowering Effect and Safety of Two Insulin Treatments in Type 2 Diabetes\\n  Status: Completed\\n\\n  This trial is conducted in Europe, Africa and the United States of America (USA).\\n\\nThe aim of this trial is to compare the safety and efficacy of two different insulin treatments, the \"basic\" and the \"advanced\" treatment in type 2 diabetes.\\n\\nTo learn more or participate, visit clinicaltrials.gov and search by NCT ID. Discuss with your healthcare provider before enrolling.', 'status': 'Pass (Trial Listing)'}, 'detail': {}, 'model_version': 'gemini-2.0-flash'}, {'timestamp': '2025-11-27T07:06:51.150040', 'agent': 'ProfileAgent', 'input': {'query': 'What trials are studying insulin therapy?', 'parsed': {'intent': 'trial_search', 'query_type': 'trial_query', 'search_keywords': ['What trials are studying insulin therapy?'], 'is_diabetes_related': True, 'user_question': 'What trials are studying insulin therapy?', 'trial_interest': 'general'}, 'nct_ids': ['NCT00115973', 'NCT04981808', 'NCT00922649', 'NCT00841919', 'NCT00537303'], 'safety_status': 'Pass (Trial Listing)', 'session_hash': '6e3aa2ba6e5cc74f7f4c5b4b4f7e0e29'}, 'output': {'profile_snapshot': {'user_id': 'Patient', 'known_conditions': [], 'num_turns': 2}}, 'detail': {}, 'model_version': 'gemini-2.0-flash'}]}\n"
          ]
        }
      ]
    }
  ]
}