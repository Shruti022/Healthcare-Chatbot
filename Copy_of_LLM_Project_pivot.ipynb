{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shruti022/Healthcare-Chatbot/blob/main/Copy_of_LLM_Project_pivot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keVc9VWJI9ZI"
      },
      "source": [
        "Project Phase 1: Stepwise API Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUmbb9KsIaRL"
      },
      "source": [
        "Step 1: Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "h2IWghs9QZVy"
      },
      "outputs": [],
      "source": [
        "!pip install -q requests pandas streamlit pyngrok faiss-cpu sentence-transformers numpy\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUskaUMVEYsn",
        "outputId": "c602c039-005f-46eb-8047-8065d931f58f"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Secure KEY INPUT\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# Securely Capture Key\n",
        "# Input will be invisible. Paste key and press Enter.\n",
        "key_input = getpass.getpass(\"üîë Enter Gemini API Key (Invisible Input): \")\n",
        "\n",
        "if not key_input.startswith(\"AIza\"):\n",
        "    print(\"‚ö†Ô∏è Warning: Key might be invalid (usually starts with 'AIza').\")\n",
        "else:\n",
        "    print(\"‚úÖ API Key captured securely in Environment Variable.\")\n",
        "\n",
        "# 2. Set as Environment Variable for the Session\n",
        "os.environ[\"GEMINI_API_KEY\"] = key_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnfATz0x1DYc",
        "outputId": "fabe585f-0319-42a6-8ae6-259d6cdb65e5"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîë Enter Gemini API Key (Invisible Input): ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ API Key captured securely in Environment Variable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile build_embeddings.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "import json\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# === REAL PATH (from readlink) ===\n",
        "BASE = \"/content/drive/.shortcut-targets-by-id/1-SiVJhXHTHtDYSrPmW_0VfuP7gSTePcj/data\"\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Load Data\n",
        "# ---------------------------------------------\n",
        "df = pd.read_csv(f\"{BASE}/clinical_trials_diabetes_full.csv\")\n",
        "\n",
        "df[\"status\"] = df[\"status\"].astype(str).str.strip().str.title()\n",
        "bad_status = [\"Terminated\", \"Withdrawn\", \"Suspended\", \"No Longer Available\", \"Unknown\"]\n",
        "df_clean = df[~df[\"status\"].isin(bad_status)].copy()\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Chunking\n",
        "# ---------------------------------------------\n",
        "chunks = []\n",
        "chunk_map = []\n",
        "\n",
        "for idx, row in df_clean.iterrows():\n",
        "    title = str(row.get(\"brief_title\", \"\")).strip()\n",
        "    summary = str(row.get(\"brief_summary\", \"\")).strip()\n",
        "\n",
        "    if len(summary) < 20:\n",
        "        continue\n",
        "\n",
        "    text = f\"Title: {title}\\nSummary: {summary}\"\n",
        "    chunks.append(text)\n",
        "\n",
        "    chunk_map.append({\n",
        "        \"nct_id\": row[\"nct_id\"],\n",
        "        \"title\": title,\n",
        "        \"text\": text,\n",
        "        \"status\": row[\"status\"]\n",
        "    })\n",
        "\n",
        "print(f\"Created {len(chunks)} chunks.\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Embeddings\n",
        "# ---------------------------------------------\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = embed_model.encode(chunks, batch_size=64, show_progress_bar=True)\n",
        "\n",
        "np.save(f\"{BASE}/clinical_trials_diabetes_full_embeddings.npy\", embeddings)\n",
        "print(\"Saved clinical_trials_diabetes_full_embeddings.npy\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Save chunk map\n",
        "# ---------------------------------------------\n",
        "with open(f\"{BASE}/clinical_trials_diabetes_full_chunk_map.json\", \"w\") as f:\n",
        "    json.dump(chunk_map, f)\n",
        "\n",
        "print(\"Saved clinical_trials_diabetes_full_chunk_map.json\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Build & Save FAISS\n",
        "# ---------------------------------------------\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(embeddings).astype(\"float32\"))\n",
        "faiss.write_index(index, f\"{BASE}/clinical_trials_diabetes_full_faiss.index\")\n",
        "\n",
        "print(\"Saved clinical_trials_diabetes_full_faiss.index\")\n",
        "print(\"‚úÖ Embedding build COMPLETE.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mwEwzAoPHlB",
        "outputId": "2ac4b44a-dc3d-4507-fc36-c54679ab3e0a"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting build_embeddings.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python build_embeddings.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32A5yZO0V4VT",
        "outputId": "9feb0c5d-30e6-4041-ddf4-e8f497b58c5e"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-27 04:03:00.945976: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764216180.977338   58701 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764216180.989850   58701 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764216181.006639   58701 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764216181.006665   58701 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764216181.006669   58701 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764216181.006673   58701 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Created 18063 chunks.\n",
            "Batches: 100% 283/283 [00:34<00:00,  8.26it/s]\n",
            "Saved clinical_trials_diabetes_full_embeddings.npy\n",
            "Saved clinical_trials_diabetes_full_chunk_map.json\n",
            "Saved clinical_trials_diabetes_full_faiss.index\n",
            "‚úÖ Embedding build COMPLETE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "import json\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# --- Confidence score from distance ---\n",
        "\n",
        "def calculate_confidence_score(distance: float, normalization_factor: float = 1.0) -> float:\n",
        "    \"\"\"Inverse L2 distance score in (0,1]; closer = higher confidence.\"\"\"\n",
        "    return normalization_factor / (normalization_factor + float(distance))\n",
        "\n",
        "\n",
        "# --- Load pre-built index + chunk map ---\n",
        "\n",
        "def load_data_and_index(chunk_map_path: str, faiss_path: str):\n",
        "    \"\"\"Loads pre-built chunks and FAISS index for quick startup.\"\"\"\n",
        "    print(\"‚è≥ Loading pre-built RAG index...\")\n",
        "\n",
        "    with open(chunk_map_path, \"r\") as f:\n",
        "        chunk_map = json.load(f)\n",
        "\n",
        "    index = faiss.read_index(faiss_path)\n",
        "\n",
        "    embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    print(f\"‚úÖ RAG Index Ready: {index.ntotal} vectors loaded.\")\n",
        "    return embed_model, index, chunk_map\n",
        "\n",
        "\n",
        "# --- Provenance logging ---\n",
        "\n",
        "def log_provenance_step(agent_name: str, input_data, output_data, detail=None):\n",
        "    \"\"\"\n",
        "    Creates a detailed log entry for a single agent step.\n",
        "    \"\"\"\n",
        "    log_entry = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"agent\": agent_name,\n",
        "        \"input\": input_data,\n",
        "        \"output\": output_data,\n",
        "        \"detail\": detail or {},\n",
        "        \"model_version\": \"gemini-2.0-flash\",\n",
        "    }\n",
        "    return log_entry\n",
        "\n",
        "\n",
        "# --- Reproducibility hash ---\n",
        "\n",
        "def generate_reproducibility_hash(conversation_history, corpus_version: str = \"v1.0\"):\n",
        "    \"\"\"\n",
        "    Generates a deterministic session hash based on the conversation history.\n",
        "    \"\"\"\n",
        "    queries = [turn.get(\"query\", \"\") for turn in conversation_history]\n",
        "    raw = f\"{corpus_version}|{'|'.join(queries)}\"\n",
        "    return hashlib.md5(raw.encode(\"utf-8\")).hexdigest()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PXqvXLkXaX7",
        "outputId": "64bb8b89-4fc8-4cfb-b53d-2e310f7212c6"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_bot.py\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "from typing import List, Dict, Any\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "\n",
        "from utils import (\n",
        "    load_data_and_index,\n",
        "    calculate_confidence_score,\n",
        ")\n",
        "\n",
        "# =============================\n",
        "# Gemini API Config\n",
        "# =============================\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "if not API_KEY:\n",
        "    raise ValueError(\"‚ùå Missing GEMINI_API_KEY environment variable.\")\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n",
        "gemini_model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Paths to FAISS + chunk data\n",
        "# =============================\n",
        "CHUNK_PATH = \"/content/drive/.shortcut-targets-by-id/1-SiVJhXHTHtDYSrPmW_0VfuP7gSTePcj/data/clinical_trials_diabetes_full_chunk_map.json\"\n",
        "FAISS_PATH = \"/content/drive/.shortcut-targets-by-id/1-SiVJhXHTHtDYSrPmW_0VfuP7gSTePcj/data/clinical_trials_diabetes_full_faiss.index\"\n",
        "\n",
        "embed_model, faiss_index, chunk_map = load_data_and_index(CHUNK_PATH, FAISS_PATH)\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Tone Manager\n",
        "# =============================\n",
        "class ToneManager:\n",
        "    tone = \"professional\"\n",
        "\n",
        "    @classmethod\n",
        "    def set_tone(cls, tone):\n",
        "        cls.tone = tone\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Query Parser\n",
        "# =============================\n",
        "class QueryParser:\n",
        "    def parse(self, text):\n",
        "        return {\n",
        "            \"intent\": \"trial_search\",\n",
        "            \"query\": text,\n",
        "            \"is_diabetes_related\": True\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Retriever (FAISS)\n",
        "# =============================\n",
        "class RetrievalAgent:\n",
        "    def __init__(self, embed_model, index, chunk_map):\n",
        "        self.embed_model = embed_model\n",
        "        self.index = index\n",
        "        self.chunk_map = chunk_map\n",
        "\n",
        "    def retrieve(self, parsed, top_k=5):\n",
        "        q = parsed[\"query\"]\n",
        "        q_emb = self.embed_model.encode([q])\n",
        "        D, I = self.index.search(q_emb.astype(\"float32\"), top_k)\n",
        "\n",
        "        trials = []\n",
        "        for r, idx in enumerate(I[0]):\n",
        "            item = self.chunk_map[idx]\n",
        "            conf = calculate_confidence_score(D[0][r])\n",
        "\n",
        "            trials.append({\n",
        "                \"nct_id\": item[\"nct_id\"],\n",
        "                \"title\": item[\"title\"],\n",
        "                \"text\": item[\"text\"],\n",
        "                \"status\": item[\"status\"],\n",
        "                \"confidence\": conf\n",
        "            })\n",
        "        return {\"trials\": trials}\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Trial Summarizer (Improved Structure)\n",
        "# =============================\n",
        "class TrialSummarizer:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def summarize_trial(self, t):\n",
        "        confidence_pct = round(t[\"confidence\"] * 100)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are summarizing a diabetes clinical trial for {ToneManager.tone} audience.\n",
        "\n",
        "NCT ID: {t['nct_id']}\n",
        "Title: {t['title']}\n",
        "Status: {t['status']}\n",
        "Relevance Score: {confidence_pct}%\n",
        "\n",
        "ClinicalTrials.gov Summary:\n",
        "{t['text']}\n",
        "\n",
        "Write exactly this structure:\n",
        "\n",
        "üìå {t['nct_id']} ‚Äî {t['title']}\n",
        "Status: {t['status']} | Relevance: {confidence_pct}%\n",
        "\n",
        "Abstract:\n",
        "‚Ä¢ Rewrite purpose, population, and intervention (2‚Äì3 sentences)\n",
        "\n",
        "Key Findings:\n",
        "‚Ä¢ If results publicly posted ‚Üí summarize outcomes\n",
        "‚Ä¢ If not posted ‚Üí infer likely findings based on study goal\n",
        "(No invented numbers)\n",
        "\n",
        "Takeaway:\n",
        "‚Ä¢ Single sentence ‚Äî evidence insight but NO medical orders\n",
        "\n",
        "Keep it short. No disclaimers.\n",
        "\"\"\"\n",
        "\n",
        "        res = self.model.generate_content(prompt)\n",
        "        return res.text.strip()\n",
        "\n",
        "    def summarize(self, trials):\n",
        "        return \"\\n\\n---\\n\\n\".join(self.summarize_trial(t) for t in trials)\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Safety Filter\n",
        "# =============================\n",
        "class SafetyFilter:\n",
        "    def verify(self, text):\n",
        "        banned = [\"stop taking\", \"diagnose\", \"prescribe\"]\n",
        "        if any(b in text.lower() for b in banned):\n",
        "            return \"‚ö†Ô∏è Safety revision applied. Information only.\", \"Revised\"\n",
        "        return text, \"Pass\"\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Bot\n",
        "# =============================\n",
        "class HealthcareBot:\n",
        "    def __init__(self):\n",
        "        self.parser = QueryParser()\n",
        "        self.retriever = RetrievalAgent(embed_model, faiss_index, chunk_map)\n",
        "        self.summarizer = TrialSummarizer(gemini_model)\n",
        "        self.safety = SafetyFilter()\n",
        "\n",
        "    def process_query(self, user_input):\n",
        "        # Greetings\n",
        "        if user_input.lower().strip() in [\"hi\", \"hello\", \"hey\"]:\n",
        "            return {\n",
        "                \"recommendation\": (\n",
        "                    \"üëã Hi! I summarize real diabetes clinical trials.\\n\\n\"\n",
        "                    \"Ask me things like:\\n\"\n",
        "                    \"‚Ä¢ GLP-1 trials for type 2 diabetes\\n\"\n",
        "                    \"‚Ä¢ Diet studies for weight loss\\n\"\n",
        "                    \"‚Ä¢ Insulin pump trials in adults\\n\"\n",
        "                ),\n",
        "                \"cited_trials\": []\n",
        "            }\n",
        "\n",
        "        parsed = self.parser.parse(user_input)\n",
        "        retrieved = self.retriever.retrieve(parsed)\n",
        "\n",
        "        if not retrieved[\"trials\"]:\n",
        "            return {\"recommendation\": \"No relevant trials found.\", \"cited_trials\": []}\n",
        "\n",
        "        summaries = self.summarizer.summarize(retrieved[\"trials\"])\n",
        "        final, status = self.safety.verify(summaries)\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": final,\n",
        "            \"cited_trials\": [t[\"nct_id\"] for t in retrieved[\"trials\"]],\n",
        "            \"safety_status\": status\n",
        "        }\n",
        "\n",
        "\n",
        "# Instance + entrypoint\n",
        "_bot = HealthcareBot()\n",
        "\n",
        "def run_bot(user_input: str):\n",
        "    return _bot.process_query(user_input)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnj3ftY75QgE",
        "outputId": "e0623c09-8285-4b39-e878-a426d0c254c4"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run_bot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UI frontend application simple web interface\n",
        "\n",
        "https://docs.streamlit.io/develop/tutorials/chat-and-llm-apps/build-conversational-apps"
      ],
      "metadata": {
        "id": "mDxpjMNrCwCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from run_bot import run_bot, ToneManager\n",
        "\n",
        "st.title(\"Diabetes Clinical Trial Assistant üî¨\")\n",
        "\n",
        "# Tone selector\n",
        "mode = st.radio(\"Audience:\", [\"Professional\", \"Patient\"], index=0)\n",
        "ToneManager.set_tone(mode.lower())\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Chat history\n",
        "for m in st.session_state.messages:\n",
        "    with st.chat_message(m[\"role\"]):\n",
        "        st.markdown(m[\"content\"])\n",
        "\n",
        "user_input = st.chat_input(\"Ask about diabetes clinical trials...\")\n",
        "if user_input:\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(user_input)\n",
        "\n",
        "    result = run_bot(user_input)\n",
        "    reply = result[\"recommendation\"]\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(reply)\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": reply})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EqkmxVqOkZ-",
        "outputId": "5ba4dd8b-8436-4ddd-f0e4-b828e4d60185"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 cloudflared\n",
        "!chmod +x cloudflared"
      ],
      "metadata": {
        "id": "u5BcqHNUOklc"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AI LLM\n",
        "!streamlit run app.py &>/dev/null&\n",
        "!./cloudflared tunnel --url http://localhost:8501 --no-autoupdate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZqn_TJIOkuT",
        "outputId": "32ad2b62-3f52-47bd-d7ca-c8a2e8ec272f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-11-27T04:14:59Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-11-27T04:14:59Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m |  https://admissions-rehabilitation-contains-property.trycloudflare.com                     |\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 991dffd8889ee9f0147b6b48933da9e4407e68ea8c6d984f55fa2d3db4bb431d)\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: a5261695-dea6-43c4-aa37-87b43e880dc0\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63\n",
            "2025/11/27 04:15:07 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-11-27T04:15:07Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m70a6d442-04a2-4038-a53f-460be52ef7a3 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63 \u001b[36mlocation=\u001b[0msea09 \u001b[36mprotocol=\u001b[0mquic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import run_bot\n",
        "importlib.reload(run_bot)\n",
        "\n",
        "print(run_bot.run_bot(\"trials with weight and diabetes?\")[\"recommendation\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "52QUFjvRXe3_",
        "outputId": "0f9418d4-e474-47fc-b873-09694c6b1c73"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Loading pre-built RAG index...\n",
            "‚úÖ RAG Index Ready: 18063 vectors loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-27 04:14:14.467 200 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 1737.36ms\n",
            "2025-11-27 04:14:16.183 200 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 1712.13ms\n",
            "2025-11-27 04:14:18.252 200 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 2065.85ms\n",
            "2025-11-27 04:14:20.044 200 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 1787.03ms\n",
            "2025-11-27 04:14:21.811 200 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 1762.35ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìå NCT01522157 ‚Äî A Randomized Cross-over Trial of the Postprandial Effects of Three Different Diets in Patients With Type 2 Diabetes\n",
            "Status: Completed | Relevance: 65%\n",
            "\n",
            "Abstract:\n",
            "This randomized crossover trial investigated the acute metabolic effects of three diets‚Äîlow-fat, low-carbohydrate, and Mediterranean‚Äîin approximately 20 patients with type 2 diabetes. Participants received each diet on separate days with standardized energy content but varying macronutrient ratios for breakfast and lunch, and blood samples were collected six times daily. The dietary intervention order was randomized.\n",
            "\n",
            "Key Findings:\n",
            "Likely findings involve differences in postprandial glucose and lipid responses based on the macronutrient composition of each diet.\n",
            "\n",
            "Takeaway:\n",
            "Different dietary macronutrient ratios influence postprandial glucose and lipid metabolism in individuals with type 2 diabetes.\n",
            "\n",
            "---\n",
            "\n",
            "üìå NCT00729196 ‚Äî A Trial of Two Diets for Weight and Diabetes Management\n",
            "Status: Completed | Relevance: 64%\n",
            "\n",
            "Abstract:\n",
            "‚Ä¢ This study compared the effectiveness of a low-fat diet versus a low-glycemic load diet for managing weight and blood glucose. The trial enrolled individuals with type 2 diabetes. The primary intervention was dietary modification following either a low-fat or low-glycemic load approach.\n",
            "\n",
            "Key Findings:\n",
            "‚Ä¢ Given the study's purpose, it is likely that the trial investigated and reported on differences in weight loss and glycemic control between the two diet groups. Likely outcomes included a comparison of HbA1c levels, fasting glucose, and changes in body weight.\n",
            "\n",
            "Takeaway:\n",
            "‚Ä¢ This trial provides evidence regarding the comparative effectiveness of low-fat versus low-glycemic load diets on weight and glucose control in type 2 diabetes.\n",
            "\n",
            "---\n",
            "\n",
            "üìå NCT00151697 ‚Äî LANN-study: Lantus, Amaryl, Novorapid, Novomix Study\n",
            "Status: Completed | Relevance: 64%\n",
            "\n",
            "Abstract:\n",
            "The LANN-study investigated the efficacy of combination glimepiride and short-acting insulin on weight and glucose control in 150 diabetics with inadequate glycemic control despite maximal oral therapy. Participants were randomized to either combination therapy, twice-daily premixed insulin, or once-daily basal insulin analog and followed for one year. The study compared glucose control and weight gain across the three treatment arms.\n",
            "\n",
            "Key Findings:\n",
            "Since results are not publicly posted, likely findings include a comparison of the three treatment arms regarding glucose control (e.g., HbA1c) and changes in body weight over the one-year study period. The study likely explored whether the combination therapy offered advantages in weight management compared to traditional insulin regimens, while maintaining comparable glycemic control.\n",
            "\n",
            "Takeaway:\n",
            "This study provides insights into the comparative effectiveness of different insulin strategies and oral agent combinations on glycemic control and weight management in patients with type 2 diabetes.\n",
            "\n",
            "---\n",
            "\n",
            "üìå NCT04745572 ‚Äî Development of an Adaptive Treatment for Weight Loss in People With Prediabetes\n",
            "Status: Completed | Relevance: 63%\n",
            "\n",
            "Abstract:\n",
            "This study employed a Sequential Multiple Assignment Randomized Trial (SMART) design to optimize weight loss strategies for individuals with prediabetes. Participants were initially randomized to a high or reduced carbohydrate diet and, based on weight loss response at 4 weeks, were either continued on their initial diet or re-randomized to exercise counseling/training or time-restricted eating.\n",
            "\n",
            "Key Findings:\n",
            "Since results are not yet posted, the study likely aimed to identify effective adaptive treatment pathways. A key inferred finding is the identification of second-stage interventions (exercise or time-restricted eating) that are effective for initial non-responders to dietary interventions.\n",
            "\n",
            "Takeaway:\n",
            "Adaptive treatment strategies may improve weight loss outcomes in prediabetic individuals by tailoring interventions based on initial response.\n",
            "\n",
            "---\n",
            "\n",
            "üìå NCT06976307 ‚Äî Development of an Inclusive Adaptive Treatment Strategy for Weight Loss in People With Prediabetes Using a Sequential Multiple Assignment Randomized Trial\n",
            "Status: Recruiting | Relevance: 62%\n",
            "\n",
            "Abstract:\n",
            "This study aims to identify effective weight loss strategies for individuals with prediabetes, including those with disabilities. Participants will be initially randomized to either a high or reduced carbohydrate diet. Non-responders after four weeks will be re-randomized to either exercise counseling/training or a time-restricted eating protocol.\n",
            "\n",
            "Key Findings:\n",
            "Given the study's focus on identifying optimal treatment sequences, likely findings will reveal which initial dietary approach, followed by which secondary intervention (exercise or time-restricted eating), yields the most significant weight loss in non-responders.\n",
            "\n",
            "Takeaway:\n",
            "Adaptive treatment strategies may improve weight loss outcomes in individuals with prediabetes who do not initially respond to a single dietary intervention.\n"
          ]
        }
      ]
    }
  ]
}