{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keVc9VWJI9ZI"
      },
      "source": [
        "Project Phase 1: Stepwise API Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUmbb9KsIaRL"
      },
      "source": [
        "Step 1: Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h2IWghs9QZVy"
      },
      "outputs": [],
      "source": [
        "!pip install -q requests pandas streamlit pyngrok faiss-cpu sentence-transformers numpy\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUskaUMVEYsn",
        "outputId": "b2018b5d-3829-4717-a886-f55f263aa4bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Secure KEY INPUT\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# Securely Capture Key\n",
        "# Input will be invisible. Paste key and press Enter.\n",
        "key_input = getpass.getpass(\"üîë Enter Gemini API Key (Invisible Input): \")\n",
        "\n",
        "if not key_input.startswith(\"AIza\"):\n",
        "    print(\"‚ö†Ô∏è Warning: Key might be invalid (usually starts with 'AIza').\")\n",
        "else:\n",
        "    print(\"‚úÖ API Key captured securely in Environment Variable.\")\n",
        "\n",
        "# 2. Set as Environment Variable for the Session\n",
        "os.environ[\"GEMINI_API_KEY\"] = key_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnfATz0x1DYc",
        "outputId": "dca00912-23f7-4b00-cabc-13e1f49f4725"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîë Enter Gemini API Key (Invisible Input): ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ API Key captured securely in Environment Variable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile build_embeddings.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "import json\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# === REAL PATH (from readlink) ===\n",
        "BASE = \"/content/drive/MyDrive/LLM_Based_GenAI_Sem1/data/\"\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Load Data\n",
        "# ---------------------------------------------\n",
        "df = pd.read_csv(f\"{BASE}/clinical_trials_diabetes_full.csv\")\n",
        "\n",
        "df[\"status\"] = df[\"status\"].astype(str).str.strip().str.title()\n",
        "bad_status = [\"Terminated\", \"Withdrawn\", \"Suspended\", \"No Longer Available\", \"Unknown\"]\n",
        "df_clean = df[~df[\"status\"].isin(bad_status)].copy()\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Chunking\n",
        "# ---------------------------------------------\n",
        "chunks = []\n",
        "chunk_map = []\n",
        "\n",
        "for idx, row in df_clean.iterrows():\n",
        "    title = str(row.get(\"brief_title\", \"\")).strip()\n",
        "    summary = str(row.get(\"brief_summary\", \"\")).strip()\n",
        "\n",
        "    if len(summary) < 20:\n",
        "        continue\n",
        "\n",
        "    text = f\"Title: {title}\\nSummary: {summary}\"\n",
        "    chunks.append(text)\n",
        "\n",
        "    chunk_map.append({\n",
        "        \"nct_id\": row[\"nct_id\"],\n",
        "        \"title\": title,\n",
        "        \"text\": text,\n",
        "        \"status\": row[\"status\"]\n",
        "    })\n",
        "\n",
        "print(f\"Created {len(chunks)} chunks.\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Embeddings\n",
        "# ---------------------------------------------\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = embed_model.encode(chunks, batch_size=64, show_progress_bar=True)\n",
        "\n",
        "np.save(f\"{BASE}/clinical_trials_diabetes_full_embeddings.npy\", embeddings)\n",
        "print(\"Saved clinical_trials_diabetes_full_embeddings.npy\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Save chunk map\n",
        "# ---------------------------------------------\n",
        "with open(f\"{BASE}/clinical_trials_diabetes_full_chunk_map.json\", \"w\") as f:\n",
        "    json.dump(chunk_map, f)\n",
        "\n",
        "print(\"Saved clinical_trials_diabetes_full_chunk_map.json\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Build & Save FAISS\n",
        "# ---------------------------------------------\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(embeddings).astype(\"float32\"))\n",
        "faiss.write_index(index, f\"{BASE}/clinical_trials_diabetes_full_faiss.index\")\n",
        "\n",
        "print(\"Saved clinical_trials_diabetes_full_faiss.index\")\n",
        "print(\"‚úÖ Embedding build COMPLETE.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mwEwzAoPHlB",
        "outputId": "fa81d9c2-c0ab-47d1-da57-e6887e2b5a45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting build_embeddings.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python build_embeddings.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32A5yZO0V4VT",
        "outputId": "dec12fd0-f270-4861-d4a7-c4ffd6a7c80e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-24 22:48:52.241430: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764024532.268865    2767 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764024532.274883    2767 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764024532.289538    2767 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764024532.289564    2767 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764024532.289568    2767 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764024532.289572    2767 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Created 18063 chunks.\n",
            "Batches: 100% 283/283 [00:33<00:00,  8.50it/s]\n",
            "Saved clinical_trials_diabetes_full_embeddings.npy\n",
            "Saved clinical_trials_diabetes_full_chunk_map.json\n",
            "Saved clinical_trials_diabetes_full_faiss.index\n",
            "‚úÖ Embedding build COMPLETE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "import json\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# --- Confidence score from distance ---\n",
        "\n",
        "def calculate_confidence_score(distance: float, normalization_factor: float = 1.0) -> float:\n",
        "    \"\"\"Inverse L2 distance score in (0,1]; closer = higher confidence.\"\"\"\n",
        "    return normalization_factor / (normalization_factor + float(distance))\n",
        "\n",
        "\n",
        "# --- Load pre-built index + chunk map ---\n",
        "\n",
        "def load_data_and_index(chunk_map_path: str, faiss_path: str):\n",
        "    \"\"\"Loads pre-built chunks and FAISS index for quick startup.\"\"\"\n",
        "    print(\"‚è≥ Loading pre-built RAG index...\")\n",
        "\n",
        "    with open(chunk_map_path, \"r\") as f:\n",
        "        chunk_map = json.load(f)\n",
        "\n",
        "    index = faiss.read_index(faiss_path)\n",
        "\n",
        "    embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    print(f\"‚úÖ RAG Index Ready: {index.ntotal} vectors loaded.\")\n",
        "    return embed_model, index, chunk_map\n",
        "\n",
        "\n",
        "# --- Provenance logging ---\n",
        "\n",
        "def log_provenance_step(agent_name: str, input_data, output_data, detail=None):\n",
        "    \"\"\"\n",
        "    Creates a detailed log entry for a single agent step.\n",
        "    \"\"\"\n",
        "    log_entry = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"agent\": agent_name,\n",
        "        \"input\": input_data,\n",
        "        \"output\": output_data,\n",
        "        \"detail\": detail or {},\n",
        "        \"model_version\": \"gemini-2.0-flash\",\n",
        "    }\n",
        "    return log_entry\n",
        "\n",
        "\n",
        "# --- Reproducibility hash ---\n",
        "\n",
        "def generate_reproducibility_hash(conversation_history, corpus_version: str = \"v1.0\"):\n",
        "    \"\"\"\n",
        "    Generates a deterministic session hash based on the conversation history.\n",
        "    \"\"\"\n",
        "    queries = [turn.get(\"query\", \"\") for turn in conversation_history]\n",
        "    raw = f\"{corpus_version}|{'|'.join(queries)}\"\n",
        "    return hashlib.md5(raw.encode(\"utf-8\")).hexdigest()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PXqvXLkXaX7",
        "outputId": "8a65b865-56bc-464d-ba0a-d0075f1aa2c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_bot.py\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "\n",
        "# --- Updated Import: Robust Cross-Encoder Initialization ---\n",
        "CrossEncoder = None\n",
        "try:\n",
        "    from sentence_transformers import CrossEncoder\n",
        "    print(\"‚úÖ sentence_transformers imported successfully.\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è sentence_transformers not found. Reranking will be disabled.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error importing CrossEncoder: {e}. Reranking disabled.\")\n",
        "\n",
        "from utils import (\n",
        "    load_data_and_index,\n",
        "    log_provenance_step,\n",
        "    generate_reproducibility_hash,\n",
        "    calculate_confidence_score,\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# CONFIG / PATHS\n",
        "# ============================================================\n",
        "\n",
        "# ‚ö†Ô∏è OLD CONFIG (COMMENTED OUT)\n",
        "# ‚ö†Ô∏è FOR GITHUB: keep this as \"***\" and DO NOT commit your real key.\n",
        "# API_KEY = \"******\"  # <-- replace in Colab with your real key before running\n",
        "# if API_KEY == \"***\":\n",
        "#     print(\"‚ö†Ô∏è WARNING: You must set API_KEY in run_bot.py before running.\")\n",
        "# genai.configure(api_key=API_KEY)\n",
        "# gemini_model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "# --- NEW CONFIG (SECURE & 2.0 MODEL) ---\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not API_KEY:\n",
        "    print(\"‚ùå ERROR: API Key not found. Please run the 'Secure Input' cell first.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "# Using the Experimental 2.0 Flash endpoint\n",
        "gemini_model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "CHUNK_PATH = \"/content/drive/MyDrive/LLM_Based_GenAI_Sem1/data/clinical_trials_diabetes_full_chunk_map.json\"\n",
        "FAISS_PATH = \"/content/drive/MyDrive/LLM_Based_GenAI_Sem1/data/clinical_trials_diabetes_full_faiss.index\"\n",
        "\n",
        "# Load embedding model, FAISS index, and chunk metadata\n",
        "embed_model, faiss_index, chunk_map = load_data_and_index(CHUNK_PATH, FAISS_PATH)\n",
        "\n",
        "# --- NEW: Reranker Initialization ---\n",
        "reranker = None\n",
        "if CrossEncoder:\n",
        "    try:\n",
        "        print(\"‚è≥ Loading Reranker Model (Cross-Encoder)...\")\n",
        "        # High precision reranker\n",
        "        reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "        print(\"‚úÖ Reranker Loaded.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Reranker model download failed (using pure FAISS): {e}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# AGENT 1 ‚Äî Symptom Parser\n",
        "# ============================================================\n",
        "\n",
        "# --- OLD PARSER (COMMENTED OUT) ---\n",
        "# # class SymptomParser:\n",
        "# #     def __init__(self, model):\n",
        "# #         self.model = model\n",
        "\n",
        "# #     def parse(self, text: str):\n",
        "# #         \"\"\"\n",
        "# #         Returns:\n",
        "# #           parsed: dict with symptoms, duration, context, intent\n",
        "# #           log: provenance entry\n",
        "# #         \"\"\"\n",
        "# #         prompt = (\n",
        "# #             \"You are a medical NLP parser.\\n\"\n",
        "# #             \"Extract structured info and detect whether this is a greeting or a symptom query.\\n\\n\"\n",
        "# #             f'Input: \"{text}\"\\n\\n'\n",
        "# #             \"Return ONLY valid JSON with this format:\\n\"\n",
        "# #             \"{\\n\"\n",
        "# #             '  \"symptoms\": [\"list\", \"of\", \"symptoms\"],\\n'\n",
        "# #             '  \"duration\": \"text or null\",\\n'\n",
        "# #             '  \"context\": \"extra free-text context\",\\n'\n",
        "# #             '  \"intent\": \"greeting\" or \"symptom_query\" or \"other\"\\n'\n",
        "# #             \"}\\n\"\n",
        "# #         )\n",
        "\n",
        "# #         try:\n",
        "# #             res = self.model.generate_content(prompt)\n",
        "# #             raw = (res.text or \"\").strip()\n",
        "# #             match = re.search(r\"\\{.*\\}\", raw, re.DOTALL)\n",
        "# #             if match:\n",
        "# #                 parsed = json.loads(match.group(0))\n",
        "# #             else:\n",
        "# #                 parsed = json.loads(raw)\n",
        "# #         except Exception:\n",
        "# #             # Fallback\n",
        "# #             parsed = {\n",
        "# #                 \"symptoms\": [text],\n",
        "# #                 \"duration\": None,\n",
        "# #                 \"context\": \"\",\n",
        "# #                 \"intent\": \"symptom_query\",\n",
        "# #             }\n",
        "\n",
        "# #         log = log_provenance_step(\"SymptomParser\", text, parsed)\n",
        "# #         return parsed, log\n",
        "\n",
        "\n",
        "\n",
        "# # class SymptomParser:\n",
        "# #     def __init__(self, model):\n",
        "# #         self.model = model\n",
        "\n",
        "# #     def parse(self, text: str):\n",
        "# #         \"\"\"\n",
        "# #         Returns:\n",
        "# #           parsed: dict with symptoms, duration, context, intent, relevance_to_diabetes\n",
        "# #           log: provenance entry\n",
        "# #         \"\"\"\n",
        "# #         prompt = (\n",
        "# #             \"You are a medical NLP parser for a diabetes clinical trial chatbot.\\n\"\n",
        "# #             \"Extract structured info and classify the query type.\\n\\n\"\n",
        "# #             f'Input: \"{text}\"\\n\\n'\n",
        "# #             \"Return ONLY valid JSON with this format:\\n\"\n",
        "# #             \"{\\n\"\n",
        "# #             '  \"symptoms\": [\"list\", \"of\", \"symptoms\"],\\n'\n",
        "# #             '  \"duration\": \"text or null\",\\n'\n",
        "# #             '  \"context\": \"extra free-text context\",\\n'\n",
        "# #             '  \"intent\": \"greeting\" or \"symptom_query\" or \"general_question\" or \"off_topic\",\\n'\n",
        "# #             '  \"is_diabetes_related\": true or false,\\n'\n",
        "# #             '  \"query_type\": \"knowledge_seeking\" or \"symptom_matching\" or \"greeting\"\\n'\n",
        "# #             \"}\\n\\n\"\n",
        "# #             \"Intent rules:\\n\"\n",
        "# #             \"- 'greeting': hi, hello, hey, etc.\\n\"\n",
        "# #             \"- 'general_question': asking about diabetes info (symptoms, treatment, etc.)\\n\"\n",
        "# #             \"- 'symptom_query': describing personal symptoms\\n\"\n",
        "# #             \"- 'off_topic': not related to diabetes at all\\n\\n\"\n",
        "# #             \"is_diabetes_related:\\n\"\n",
        "# #             \"- true if query mentions diabetes, blood sugar, insulin, HbA1c, or diabetes complications\\n\"\n",
        "# #             \"- false if symptoms/conditions are unrelated (e.g., headache, stomach upset alone)\\n\"\n",
        "# #         )\n",
        "\n",
        "# #         try:\n",
        "# #             res = self.model.generate_content(prompt)\n",
        "# #             raw = (res.text or \"\").strip()\n",
        "# #             match = re.search(r\"\\{.*\\}\", raw, re.DOTALL)\n",
        "# #             if match:\n",
        "# #                 parsed = json.loads(match.group(0))\n",
        "# #             else:\n",
        "# #                 parsed = json.loads(raw)\n",
        "# #         except Exception:\n",
        "# #             # Fallback\n",
        "# #             parsed = {\n",
        "# #                 \"symptoms\": [text],\n",
        "# #                 \"duration\": None,\n",
        "# #                 \"context\": \"\",\n",
        "# #                 \"intent\": \"symptom_query\",\n",
        "# #                 \"is_diabetes_related\": True,\n",
        "# #                 \"query_type\": \"symptom_matching\",\n",
        "# #             }\n",
        "\n",
        "# #         log = log_provenance_step(\"SymptomParser\", text, parsed)\n",
        "# #         return parsed, log\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# class SymptomParser:\n",
        "#     def __init__(self, model):\n",
        "#         self.model = model\n",
        "\n",
        "#     def parse(self, text: str):\n",
        "#         \"\"\"\n",
        "#         Returns:\n",
        "#           parsed: dict with symptoms, duration, context, intent, relevance_to_diabetes\n",
        "#           log: provenance entry\n",
        "#         \"\"\"\n",
        "#         prompt = (\n",
        "#             \"You are a medical NLP parser for a diabetes clinical trial chatbot.\\n\"\n",
        "#             \"Extract structured info and classify the query type.\\n\\n\"\n",
        "#             f'Input: \"{text}\"\\n\\n'\n",
        "#             \"Return ONLY valid JSON with this format:\\n\"\n",
        "#             \"{\\n\"\n",
        "#             '  \"symptoms\": [\"list\", \"of\", \"symptoms\"],\\n'\n",
        "#             '  \"duration\": \"text or null\",\\n'\n",
        "#             '  \"context\": \"extra free-text context\",\\n'\n",
        "#             '  \"intent\": \"greeting\" or \"symptom_query\" or \"general_question\" or \"off_topic\",\\n'\n",
        "#             '  \"is_diabetes_related\": true or false,\\n'\n",
        "#             '  \"query_type\": \"knowledge_seeking\" or \"symptom_matching\" or \"greeting\",\\n'\n",
        "#             '  \"user_question\": \"the actual question being asked in plain English\"\\n'\n",
        "#             \"}\\n\\n\"\n",
        "#             \"Classification rules:\\n\"\n",
        "#             \"- intent='greeting' ‚Üí query_type='greeting' (hi, hello, hey)\\n\"\n",
        "#             \"- intent='general_question' ‚Üí query_type='knowledge_seeking' (asking ABOUT diabetes, not describing symptoms)\\n\"\n",
        "#             \"  Examples: 'What are symptoms of diabetes?', 'How is diabetes treated?', 'What is HbA1c?'\\n\"\n",
        "#             \"- intent='symptom_query' ‚Üí query_type='symptom_matching' (user describing THEIR symptoms)\\n\"\n",
        "#             \"  Examples: 'I have high blood sugar', 'I feel tired and thirsty'\\n\"\n",
        "#             \"- intent='off_topic' ‚Üí not diabetes-related at all\\n\\n\"\n",
        "#             \"is_diabetes_related:\\n\"\n",
        "#             \"- true if about diabetes, blood sugar, insulin, HbA1c, or diabetes complications\\n\"\n",
        "#             \"- false if unrelated (headache alone, cold, flu, etc.)\\n\"\n",
        "#         )\n",
        "\n",
        "#         try:\n",
        "#             res = self.model.generate_content(prompt)\n",
        "#             raw = (res.text or \"\").strip()\n",
        "#             match = re.search(r\"\\{.*\\}\", raw, re.DOTALL)\n",
        "#             if match:\n",
        "#                 parsed = json.loads(match.group(0))\n",
        "#             else:\n",
        "#                 parsed = json.loads(raw)\n",
        "\n",
        "#             # Validation: ensure query_type matches intent\n",
        "#             intent = parsed.get(\"intent\", \"symptom_query\")\n",
        "#             if intent == \"general_question\":\n",
        "#                 parsed[\"query_type\"] = \"knowledge_seeking\"\n",
        "#             elif intent == \"greeting\":\n",
        "#                 parsed[\"query_type\"] = \"greeting\"\n",
        "#             elif intent == \"symptom_query\":\n",
        "#                 parsed[\"query_type\"] = \"symptom_matching\"\n",
        "\n",
        "#         except Exception:\n",
        "#             # Fallback\n",
        "#             parsed = {\n",
        "#                 \"symptoms\": [text],\n",
        "#                 \"duration\": None,\n",
        "#                 \"context\": \"\",\n",
        "#                 \"intent\": \"symptom_query\",\n",
        "#                 \"is_diabetes_related\": True,\n",
        "#                 \"query_type\": \"symptom_matching\",\n",
        "#                 \"user_question\": text,\n",
        "#             }\n",
        "\n",
        "#         log = log_provenance_step(\"SymptomParser\", text, parsed)\n",
        "#         return parsed, log\n",
        "\n",
        "# --- NEW PARSER (UPDATED) ---\n",
        "class SymptomParser:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def parse(self, text: str):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "          parsed: dict with symptoms, duration, context, intent, relevance_to_diabetes\n",
        "          log: provenance entry\n",
        "        \"\"\"\n",
        "        prompt = (\n",
        "            \"You are a medical NLP parser for a diabetes clinical trial chatbot.\\n\"\n",
        "            \"Extract structured info and classify the query type.\\n\\n\"\n",
        "            f'Input: \"{text}\"\\n\\n'\n",
        "            \"Return ONLY valid JSON with this format:\\n\"\n",
        "            \"{\\n\"\n",
        "            '  \"symptoms\": [\"list\", \"of\", \"symptoms\"],\\n'\n",
        "            '  \"duration\": \"text or null\",\\n'\n",
        "            '  \"context\": \"extra free-text context\",\\n'\n",
        "            '  \"intent\": \"greeting\" or \"symptom_query\" or \"general_question\" or \"off_topic\",\\n'\n",
        "            '  \"is_diabetes_related\": true or false,\\n'\n",
        "            '  \"query_type\": \"knowledge_seeking\" or \"symptom_matching\" or \"greeting\",\\n'\n",
        "            '  \"user_question\": \"the actual question being asked in plain English\"\\n'\n",
        "            \"}\\n\\n\"\n",
        "            \"Classification rules:\\n\"\n",
        "            \"- intent='greeting' ‚Üí query_type='greeting' (hi, hello, hey)\\n\"\n",
        "            \"- intent='general_question' ‚Üí query_type='knowledge_seeking' (asking ABOUT diabetes, not describing symptoms)\\n\"\n",
        "            \"  Examples: 'What are symptoms of diabetes?', 'How is diabetes treated?', 'What is HbA1c?'\\n\"\n",
        "            \"- intent='symptom_query' ‚Üí query_type='symptom_matching' (user describing THEIR symptoms)\\n\"\n",
        "            \"  Examples: 'I have high blood sugar', 'I feel tired and thirsty'\\n\"\n",
        "            \"- intent='off_topic' ‚Üí not diabetes-related at all\\n\\n\"\n",
        "            \"is_diabetes_related:\\n\"\n",
        "            \"- true if about diabetes, blood sugar, insulin, HbA1c, or diabetes complications\\n\"\n",
        "            \"- false if unrelated (headache alone, cold, flu, etc.)\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            raw = (res.text or \"\").strip()\n",
        "            match = re.search(r\"\\{.*\\}\", raw, re.DOTALL)\n",
        "            if match:\n",
        "                parsed = json.loads(match.group(0))\n",
        "            else:\n",
        "                parsed = json.loads(raw)\n",
        "\n",
        "            # Validation: ensure query_type matches intent\n",
        "            intent = parsed.get(\"intent\", \"symptom_query\")\n",
        "            if intent == \"general_question\":\n",
        "                parsed[\"query_type\"] = \"knowledge_seeking\"\n",
        "            elif intent == \"greeting\":\n",
        "                parsed[\"query_type\"] = \"greeting\"\n",
        "            elif intent == \"symptom_query\":\n",
        "                parsed[\"query_type\"] = \"symptom_matching\"\n",
        "\n",
        "        except Exception:\n",
        "            # Fallback\n",
        "            parsed = {\n",
        "                \"symptoms\": [text],\n",
        "                \"duration\": None,\n",
        "                \"context\": \"\",\n",
        "                \"intent\": \"symptom_query\",\n",
        "                \"is_diabetes_related\": True,\n",
        "                \"query_type\": \"symptom_matching\",\n",
        "                \"user_question\": text,\n",
        "            }\n",
        "\n",
        "        log = log_provenance_step(\"SymptomParser\", text, parsed)\n",
        "        return parsed, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# AGENT 2 ‚Äî ProfileAgent\n",
        "# ============================================================\n",
        "\n",
        "# --- OLD PROFILE AGENT (COMMENTED OUT) ---\n",
        "# class ProfileAgent:\n",
        "#     def __init__(self, initial_profile: Dict[str, Any] = None):\n",
        "#         if initial_profile is None:\n",
        "#             initial_profile = {\n",
        "#                 \"user_id\": \"Patient\",\n",
        "#                 \"conditions\": [\"diabetes\"],\n",
        "#                 \"history\": [],\n",
        "#             }\n",
        "#         self.profile = initial_profile\n",
        "\n",
        "#     def update_profile(self, turn_data: Dict[str, Any]):\n",
        "#         self.profile.setdefault(\"history\", []).append(turn_data)\n",
        "#         snapshot = {\n",
        "#             \"user_id\": self.profile.get(\"user_id\", \"Patient\"),\n",
        "#             \"conditions\": self.profile.get(\"conditions\", []),\n",
        "#             \"num_turns\": len(self.profile[\"history\"]),\n",
        "#         }\n",
        "#         log = log_provenance_step(\"ProfileAgent\", turn_data, {\"profile_snapshot\": snapshot})\n",
        "#         return log\n",
        "\n",
        "# --- NEW PROFILE AGENT (STATEFUL) ---\n",
        "class ProfileAgent:\n",
        "    def __init__(self, initial_profile: Dict[str, Any] = None):\n",
        "        if initial_profile is None:\n",
        "            initial_profile = {\n",
        "                \"user_id\": \"Patient\",\n",
        "                \"conditions\": [\"diabetes\"], # Default context\n",
        "                \"extracted_conditions\": [], # Dynamic memory\n",
        "                \"history\": [],\n",
        "            }\n",
        "        self.profile = initial_profile\n",
        "\n",
        "    def update_profile(self, turn_data: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Updates history and extracts persistent medical entities.\n",
        "        \"\"\"\n",
        "        self.profile.setdefault(\"history\", []).append(turn_data)\n",
        "        self.profile.setdefault(\"extracted_conditions\", [])\n",
        "\n",
        "        # Heuristic: Add new symptoms found in this turn to the persistent profile\n",
        "        parsed = turn_data.get(\"parsed\", {})\n",
        "        new_symptoms = parsed.get(\"symptoms\", [])\n",
        "\n",
        "        if new_symptoms:\n",
        "            current_conditions = set(self.profile[\"extracted_conditions\"])\n",
        "            for sym in new_symptoms:\n",
        "                if sym and len(sym) > 3: # Avoid noise\n",
        "                    current_conditions.add(sym.lower())\n",
        "            self.profile[\"extracted_conditions\"] = list(current_conditions)\n",
        "\n",
        "        snapshot = {\n",
        "            \"user_id\": self.profile.get(\"user_id\", \"Patient\"),\n",
        "            \"known_conditions\": self.profile.get(\"extracted_conditions\", []),\n",
        "            \"num_turns\": len(self.profile[\"history\"]),\n",
        "        }\n",
        "        log = log_provenance_step(\"ProfileAgent\", turn_data, {\"profile_snapshot\": snapshot})\n",
        "        return log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# AGENT 3 ‚Äî RetrievalAgent\n",
        "# ============================================================\n",
        "\n",
        "# # --- OLD RETRIEVAL AGENT (COMMENTED OUT) ---\n",
        "# class RetrievalAgent:\n",
        "#     def __init__(self, embed_model, faiss_index, chunk_map, profile_agent: ProfileAgent = None):\n",
        "#         self.embed_model = embed_model\n",
        "#         self.index = faiss_index\n",
        "#         self.chunk_map = chunk_map\n",
        "#         self.profile_agent = profile_agent\n",
        "\n",
        "#     def retrieve(self, parsed: Dict[str, Any], top_k: int = 5):\n",
        "#         symptoms = parsed.get(\"symptoms\") or []\n",
        "#         context = parsed.get(\"context\") or \"\"\n",
        "#         query = (\" \".join(symptoms) + \" \" + context).strip()\n",
        "\n",
        "#         if not query:\n",
        "#             retrieval = {\"query\": \"\", \"trials\": [], \"avg_confidence\": 0.0}\n",
        "#             log = log_provenance_step(\"RetrievalAgent\", parsed, retrieval, {\"reason\": \"empty_query\"})\n",
        "#             return retrieval, log\n",
        "\n",
        "#         q_emb = self.embed_model.encode([query])\n",
        "#         distances, indices = self.index.search(q_emb.astype(\"float32\"), top_k)\n",
        "\n",
        "#         trials = []\n",
        "#         confs = []\n",
        "\n",
        "#         for rank, idx in enumerate(indices[0]):\n",
        "#             item = self.chunk_map[idx]\n",
        "#             dist = float(distances[0][rank])\n",
        "#             conf = calculate_confidence_score(dist)\n",
        "#             confs.append(conf)\n",
        "\n",
        "#             trials.append({\n",
        "#                 \"nct_id\": item[\"nct_id\"],\n",
        "#                 \"title\": item[\"title\"],\n",
        "#                 \"text\": item[\"text\"],\n",
        "#                 \"status\": item[\"status\"],\n",
        "#                 \"distance\": dist,\n",
        "#                 \"confidence\": conf,\n",
        "#                 \"rank\": rank + 1,\n",
        "#             })\n",
        "\n",
        "#         avg_conf = float(np.mean(confs)) if confs else 0.0\n",
        "\n",
        "#         retrieval = {\n",
        "#             \"query\": query,\n",
        "#             \"trials\": trials,\n",
        "#             \"avg_confidence\": avg_conf,\n",
        "#         }\n",
        "\n",
        "#         detail = {\n",
        "#             \"top_k\": top_k,\n",
        "#             \"avg_confidence\": avg_conf,\n",
        "#             \"num_trials\": len(trials),\n",
        "#         }\n",
        "\n",
        "#         log = log_provenance_step(\"RetrievalAgent\", parsed, retrieval, detail)\n",
        "#         return retrieval, log\n",
        "\n",
        "# --- NEW RETRIEVAL AGENT (RERANKING) ---\n",
        "class RetrievalAgent:\n",
        "    def __init__(self, embed_model, faiss_index, chunk_map, profile_agent: ProfileAgent = None):\n",
        "        self.embed_model = embed_model\n",
        "        self.index = faiss_index\n",
        "        self.chunk_map = chunk_map\n",
        "        self.profile_agent = profile_agent\n",
        "\n",
        "    def retrieve(self, parsed: Dict[str, Any], top_k: int = 5):\n",
        "        # Fetch 3x candidates for reranking\n",
        "        FETCH_K = top_k * 3\n",
        "\n",
        "        symptoms = parsed.get(\"symptoms\") or []\n",
        "        context = parsed.get(\"context\") or \"\"\n",
        "        # user_question usually captures the intent best\n",
        "        query = parsed.get(\"user_question\") or (\" \".join(symptoms) + \" \" + context).strip()\n",
        "\n",
        "        if not query:\n",
        "            retrieval = {\"query\": \"\", \"trials\": [], \"avg_confidence\": 0.0}\n",
        "            log = log_provenance_step(\"RetrievalAgent\", parsed, retrieval, {\"reason\": \"empty_query\"})\n",
        "            return retrieval, log\n",
        "\n",
        "        # 1. FAISS Retrieval (Fast/Dense)\n",
        "        q_emb = self.embed_model.encode([query])\n",
        "        distances, indices = self.index.search(q_emb.astype(\"float32\"), FETCH_K)\n",
        "\n",
        "        initial_candidates = []\n",
        "        for rank, idx in enumerate(indices[0]):\n",
        "            if idx == -1: continue\n",
        "            item = self.chunk_map[idx]\n",
        "            dist = float(distances[0][rank])\n",
        "            initial_candidates.append({\n",
        "                \"nct_id\": item[\"nct_id\"],\n",
        "                \"text\": item[\"text\"],\n",
        "                \"status\": item[\"status\"],\n",
        "                \"faiss_dist\": dist,\n",
        "            })\n",
        "\n",
        "        # 2. Reranking (Cross-Encoder)\n",
        "        final_trials = []\n",
        "        confs = []\n",
        "\n",
        "        if reranker and initial_candidates:\n",
        "            # Score (Query, Doc) pairs\n",
        "            pairs = [[query, cand[\"text\"]] for cand in initial_candidates]\n",
        "            scores = reranker.predict(pairs)\n",
        "\n",
        "            # Attach scores\n",
        "            for i, cand in enumerate(initial_candidates):\n",
        "                cand[\"rerank_score\"] = float(scores[i])\n",
        "\n",
        "            # Sort by rerank score (descending)\n",
        "            initial_candidates.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
        "\n",
        "            # Take top_k\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                # Sigmoid normalization for confidence\n",
        "                logit = item[\"rerank_score\"]\n",
        "                conf = 1 / (1 + np.exp(-logit))\n",
        "                confs.append(conf)\n",
        "\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"text\"].split(\"\\n\")[0].replace(\"Title: \", \"\"),\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": conf,\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"reranked\"\n",
        "                })\n",
        "        else:\n",
        "            # Fallback if reranker is not loaded\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                conf = calculate_confidence_score(item[\"faiss_dist\"])\n",
        "                confs.append(conf)\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"text\"].split(\"\\n\")[0].replace(\"Title: \", \"\"),\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": conf,\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"faiss_only\"\n",
        "                })\n",
        "\n",
        "        avg_conf = float(np.mean(confs)) if confs else 0.0\n",
        "\n",
        "        retrieval = {\n",
        "            \"query\": query,\n",
        "            \"trials\": final_trials,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "        }\n",
        "\n",
        "        detail = {\n",
        "            \"top_k\": top_k,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"num_trials\": len(final_trials),\n",
        "            \"method\": \"reranked\" if reranker else \"faiss_only\"\n",
        "        }\n",
        "\n",
        "        log = log_provenance_step(\"RetrievalAgent\", parsed, retrieval, detail)\n",
        "        return retrieval, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# AGENT 4 ‚Äî DiagnosisAdvisor\n",
        "# ============================================================\n",
        "\n",
        "# --- OLD DIAGNOSIS ADVISOR (COMMENTED OUT) ---\n",
        "\n",
        "# # class DiagnosisAdvisor:\n",
        "# #     def __init__(self, model):\n",
        "# #         self.model = model\n",
        "\n",
        "# #     def advise(self, parsed: Dict[str, Any], retrieved: Dict[str, Any]):\n",
        "# #         trials = retrieved.get(\"trials\", [])\n",
        "# #         avg_conf = retrieved.get(\"avg_confidence\", 0.0)\n",
        "\n",
        "# #         # If retrieval is very low confidence, veto early\n",
        "# #         draft = {\n",
        "# #             \"recommendation\": \"\",\n",
        "# #             \"avg_confidence\": avg_conf,\n",
        "# #         }\n",
        "\n",
        "# #         if not trials or avg_conf < 0.15:\n",
        "# #             draft[\"recommendation\"] = (\n",
        "# #                 \"EVIDENCE IS INSUFFICIENT TO ANSWER THIS QUESTION DIRECTLY based on the \"\n",
        "# #                 \"retrieved clinical trials. Please consult your healthcare provider.\"\n",
        "# #             )\n",
        "# #             draft[\"confidence_veto\"] = True\n",
        "# #             log = log_provenance_step(\n",
        "# #                 \"DiagnosisAdvisor\",\n",
        "# #                 {\"parsed\": parsed, \"retrieval_meta\": {\"avg_confidence\": avg_conf, \"num_trials\": len(trials)}},\n",
        "# #                 draft,\n",
        "# #                 {\"veto\": True},\n",
        "# #             )\n",
        "# #             return draft, log\n",
        "\n",
        "# #         evidence_parts = []\n",
        "# #         for t in trials:\n",
        "# #             evidence_parts.append(\n",
        "# #                 f\"Trial {t['nct_id']} (rank {t['rank']}, confidence {t['confidence']:.2f}):\\n{t['text']}\\n\"\n",
        "# #             )\n",
        "# #         evidence = \"\\n\".join(evidence_parts)\n",
        "\n",
        "# #         prompt = (\n",
        "# #             \"You are an evidence-based medical assistant summarizing clinical trials.\\n\"\n",
        "# #             \"You MUST answer based ONLY on the evidence below.\\n\"\n",
        "# #             \"If the evidence does not clearly answer the question, explicitly say:\\n\"\n",
        "# #             '\"EVIDENCE IS INSUFFICIENT TO ANSWER THIS QUESTION DIRECTLY.\"\\n\\n'\n",
        "# #             \"Rules:\\n\"\n",
        "# #             \"- Do NOT diagnose.\\n\"\n",
        "# #             \"- Do NOT tell the user to start/stop/change any medication.\\n\"\n",
        "# #             \"- Summarize what the trials studied (population, interventions, outcomes).\\n\"\n",
        "# #             \"- End with: 'Please discuss these findings with your healthcare provider before making any changes.'\\n\\n\"\n",
        "# #             \"PATIENT QUERY (parsed JSON):\\n\"\n",
        "# #             f\"{json.dumps(parsed, indent=2)}\\n\\n\"\n",
        "# #             \"RETRIEVED CLINICAL TRIAL EVIDENCE:\\n\"\n",
        "# #             f\"{evidence}\\n\"\n",
        "# #         )\n",
        "\n",
        "# #         try:\n",
        "# #             res = self.model.generate_content(prompt)\n",
        "# #             text = (res.text or \"\").strip()\n",
        "# #             if not text:\n",
        "# #                 text = \"EVIDENCE IS INSUFFICIENT TO ANSWER THIS QUESTION DIRECTLY.\"\n",
        "# #             draft[\"recommendation\"] = text\n",
        "# #             draft[\"confidence_veto\"] = False\n",
        "# #         except Exception:\n",
        "# #             draft[\"recommendation\"] = \"Unable to generate advice at this time.\"\n",
        "# #             draft[\"confidence_veto\"] = True\n",
        "\n",
        "# #         log = log_provenance_step(\n",
        "# #             \"DiagnosisAdvisor\",\n",
        "# #             {\"parsed\": parsed, \"retrieval_meta\": {\"avg_confidence\": avg_conf, \"num_trials\": len(trials)}},\n",
        "# #             draft,\n",
        "# #         )\n",
        "# #         return draft, log\n",
        "\n",
        "\n",
        "\n",
        "# class DiagnosisAdvisor:\n",
        "#     def __init__(self, model):\n",
        "#         self.model = model\n",
        "\n",
        "#     # def _handle_general_question(self, parsed: Dict[str, Any], retrieved: Dict[str, Any]):\n",
        "#     #     \"\"\"Handle general knowledge questions about diabetes\"\"\"\n",
        "#     #     trials = retrieved.get(\"trials\", [])\n",
        "#     #     user_query = \" \".join(parsed.get(\"symptoms\", []))\n",
        "\n",
        "#     #     evidence_parts = []\n",
        "#     #     for t in trials[:3]:  # Use top 3 for context\n",
        "#     #         evidence_parts.append(\n",
        "#     #             f\"Trial {t['nct_id']}: {t['text'][:300]}...\\n\"\n",
        "#     #         )\n",
        "#     #     evidence = \"\\n\".join(evidence_parts) if evidence_parts else \"No specific trials found.\"\n",
        "\n",
        "#     #     prompt = (\n",
        "#     #         \"You are a diabetes health educator. Answer the user's question clearly and accurately.\\n\"\n",
        "#     #         \"Use your medical knowledge AND the clinical trial evidence provided as validation.\\n\\n\"\n",
        "#     #         f\"USER QUESTION: {user_query}\\n\\n\"\n",
        "#     #         \"SUPPORTING EVIDENCE FROM CLINICAL TRIALS:\\n\"\n",
        "#     #         f\"{evidence}\\n\\n\"\n",
        "#     #         \"Instructions:\\n\"\n",
        "#     #         \"- Answer the question directly and clearly\\n\"\n",
        "#     #         \"- If trials provide relevant context, mention them\\n\"\n",
        "#     #         \"- Keep answer concise (3-4 sentences)\\n\"\n",
        "#     #         \"- End with: 'For personalized advice, please consult your healthcare provider.'\\n\"\n",
        "#     #     )\n",
        "\n",
        "#     #     try:\n",
        "#     #         res = self.model.generate_content(prompt)\n",
        "#     #         text = (res.text or \"\").strip()\n",
        "#     #         if not text:\n",
        "#     #             text = \"I don't have enough information to answer this question accurately.\"\n",
        "#     #         return text\n",
        "#     #     except Exception:\n",
        "#     #         return \"Unable to generate an answer at this time.\"\n",
        "\n",
        "\n",
        "#     def _handle_general_question(self, parsed: Dict[str, Any], retrieved: Dict[str, Any]):\n",
        "#         \"\"\"Handle general knowledge questions about diabetes\"\"\"\n",
        "#         trials = retrieved.get(\"trials\", [])\n",
        "#         user_question = parsed.get(\"user_question\") or \" \".join(parsed.get(\"symptoms\", []))\n",
        "\n",
        "#         # Build evidence context (top 3 trials)\n",
        "#         evidence_parts = []\n",
        "#         for t in trials[:3]:\n",
        "#             evidence_parts.append(\n",
        "#                 f\"Trial {t['nct_id']}: {t['text'][:400]}\"\n",
        "#             )\n",
        "#         evidence = \"\\n\\n\".join(evidence_parts) if evidence_parts else \"No specific trials available.\"\n",
        "\n",
        "#         prompt = (\n",
        "#             \"You are a diabetes health educator. Answer the user's question clearly using your medical knowledge.\\n\"\n",
        "#             \"The clinical trial evidence below provides real-world context - mention it if relevant.\\n\\n\"\n",
        "#             f\"USER'S QUESTION: {user_question}\\n\\n\"\n",
        "#             \"CLINICAL TRIAL CONTEXT (for reference):\\n\"\n",
        "#             f\"{evidence}\\n\\n\"\n",
        "#             \"Instructions:\\n\"\n",
        "#             \"- Answer the question directly in 3-5 sentences\\n\"\n",
        "#             \"- Be specific and educational\\n\"\n",
        "#             \"- If trials mention relevant findings, cite them briefly\\n\"\n",
        "#             \"- End with: 'For personalized advice, please consult your healthcare provider.'\\n\\n\"\n",
        "#             \"Example for 'What are symptoms of diabetes?':\\n\"\n",
        "#             \"Common symptoms of diabetes include increased thirst, frequent urination, unexplained weight loss, \"\n",
        "#             \"fatigue, blurred vision, and slow-healing wounds. Type 1 diabetes symptoms often appear suddenly, \"\n",
        "#             \"while type 2 symptoms develop gradually. Some clinical trials (like NCT...) study complications \"\n",
        "#             \"such as neuropathy and retinopathy. For personalized advice, please consult your healthcare provider.\\n\"\n",
        "#         )\n",
        "\n",
        "#         try:\n",
        "#             res = self.model.generate_content(prompt)\n",
        "#             text = (res.text or \"\").strip()\n",
        "#             if not text or len(text) < 50:\n",
        "#                 text = \"I don't have enough information to answer this question accurately. Please consult your healthcare provider.\"\n",
        "#             return text\n",
        "#         except Exception as e:\n",
        "#             return f\"Unable to generate an answer at this time. Please try rephrasing your question.\"\n",
        "\n",
        "\n",
        "\n",
        "#     # def _handle_symptom_query(self, parsed: Dict[str, Any], retrieved: Dict[str, Any]):\n",
        "#     #     \"\"\"Handle symptom-based queries with evidence\"\"\"\n",
        "#     #     trials = retrieved.get(\"trials\", [])\n",
        "#     #     avg_conf = retrieved.get(\"avg_confidence\", 0.0)\n",
        "#     #     symptoms = parsed.get(\"symptoms\", [])\n",
        "#     #     user_input = parsed.get(\"user_question\") or \", \".join(symptoms)\n",
        "\n",
        "#     #     evidence_parts = []\n",
        "#     #     for t in trials:\n",
        "#     #         evidence_parts.append(\n",
        "#     #             f\"Trial {t['nct_id']} (confidence {t['confidence']:.2f}):\\n{t['text']}\"\n",
        "#     #         )\n",
        "#     #     evidence = \"\\n\\n\".join(evidence_parts)\n",
        "\n",
        "#     #     prompt = (\n",
        "#     #         \"You are an evidence-based diabetes health assistant.\\n\"\n",
        "#     #         \"The user has described symptoms. Provide a helpful response based ONLY on the clinical trial evidence.\\n\\n\"\n",
        "#     #         f\"USER'S SYMPTOMS/CONCERN: {user_input}\\n\\n\"\n",
        "#     #         \"RETRIEVED CLINICAL TRIAL EVIDENCE:\\n\"\n",
        "#     #         f\"{evidence}\\n\\n\"\n",
        "#     #         \"Instructions:\\n\"\n",
        "#     #         \"- Start with 1-2 sentences acknowledging their symptoms\\n\"\n",
        "#     #         \"- Summarize what the trials found about these symptoms/conditions\\n\"\n",
        "#     #         \"- List 2-3 specific trials with their focus\\n\"\n",
        "#     #         \"- Do NOT diagnose or recommend medication changes\\n\"\n",
        "#     #         \"- End with: 'Please discuss these findings with your healthcare provider before making any changes.'\\n\\n\"\n",
        "#     #         \"Example format:\\n\"\n",
        "#     #         \"Based on your symptoms of high blood sugar and fatigue, several diabetes trials have investigated these concerns. \"\n",
        "#     #         \"Research shows that fatigue is commonly studied alongside glycemic control and quality of life measures. \"\n",
        "#     #         \"Here are relevant trials:\\n\"\n",
        "#     #         \"‚Ä¢ NCT... examines fatigue in type 2 diabetes patients\\n\"\n",
        "#     #         \"‚Ä¢ NCT... studies the relationship between blood sugar levels and energy\\n\"\n",
        "#     #         \"Please discuss these findings with your healthcare provider before making any changes.\\n\"\n",
        "#     #     )\n",
        "\n",
        "#     #     try:\n",
        "#     #         res = self.model.generate_content(prompt)\n",
        "#     #         text = (res.text or \"\").strip()\n",
        "#     #         if not text or len(text) < 50:\n",
        "#     #             text = \"The retrieved trials may not directly address your specific symptoms. Please consult your healthcare provider.\"\n",
        "#     #         return text\n",
        "#     #     except Exception:\n",
        "#     #         return \"Unable to generate advice at this time. Please consult your healthcare provider.\"\n",
        "\n",
        "\n",
        "#     def _handle_symptom_query(self, parsed: Dict[str, Any], retrieved: Dict[str, Any]):\n",
        "#         \"\"\"Handle symptom-based queries with evidence\"\"\"\n",
        "#         trials = retrieved.get(\"trials\", [])\n",
        "#         avg_conf = retrieved.get(\"avg_confidence\", 0.0)\n",
        "#         symptoms = parsed.get(\"symptoms\", [])\n",
        "#         user_input = parsed.get(\"user_question\", \", \".join(symptoms))\n",
        "\n",
        "#         evidence_parts = []\n",
        "#         for t in trials[:5]:  # Top 5 trials\n",
        "#             evidence_parts.append(\n",
        "#                 f\"‚Ä¢ {t['nct_id']}: {t['text'][:350]}\"\n",
        "#             )\n",
        "#         evidence = \"\\n\\n\".join(evidence_parts)\n",
        "\n",
        "#         prompt = (\n",
        "#             \"You are an evidence-based diabetes health assistant.\\n\"\n",
        "#             \"The user has described diabetes-related symptoms or concerns. Provide a helpful, empathetic response.\\n\\n\"\n",
        "#             f\"USER'S SYMPTOMS/CONCERN: {user_input}\\n\\n\"\n",
        "#             \"RETRIEVED CLINICAL TRIAL EVIDENCE:\\n\"\n",
        "#             f\"{evidence}\\n\\n\"\n",
        "#             \"Instructions:\\n\"\n",
        "#             \"1. Start with 1-2 sentences acknowledging their concern (brief medical context)\\n\"\n",
        "#             \"2. Say 'Several clinical trials have investigated this' or similar transition\\n\"\n",
        "#             \"3. List 3-4 specific trials with brief descriptions:\\n\"\n",
        "#             \"   ‚Ä¢ NCT... examines [brief focus]\\n\"\n",
        "#             \"   ‚Ä¢ NCT... investigates [brief focus]\\n\"\n",
        "#             \"4. Do NOT diagnose or recommend medication changes\\n\"\n",
        "#             \"5. End with: 'Please discuss these findings with your healthcare provider before making any changes.'\\n\\n\"\n",
        "#             \"Keep response concise (5-7 sentences total).\\n\"\n",
        "#         )\n",
        "\n",
        "#         try:\n",
        "#             res = self.model.generate_content(prompt)\n",
        "#             text = (res.text or \"\").strip()\n",
        "#             if not text or len(text) < 50:\n",
        "#                 text = \"The retrieved trials may not directly address your specific symptoms. Please consult your healthcare provider.\"\n",
        "#             return text\n",
        "#         except Exception:\n",
        "#             return \"Unable to generate advice at this time. Please consult your healthcare provider.\"\n",
        "\n",
        "\n",
        "\n",
        "#     def advise(self, parsed: Dict[str, Any], retrieved: Dict[str, Any]):\n",
        "#         trials = retrieved.get(\"trials\", [])\n",
        "#         avg_conf = retrieved.get(\"avg_confidence\", 0.0)\n",
        "#         query_type = parsed.get(\"query_type\", \"symptom_matching\")\n",
        "#         is_diabetes_related = parsed.get(\"is_diabetes_related\", True)\n",
        "\n",
        "#         draft = {\n",
        "#             \"recommendation\": \"\",\n",
        "#             \"avg_confidence\": avg_conf,\n",
        "#             \"query_type\": query_type,\n",
        "#         }\n",
        "\n",
        "#         # Handle off-topic queries\n",
        "#         if not is_diabetes_related:\n",
        "#             draft[\"recommendation\"] = (\n",
        "#                 \"I'm specialized in diabetes-related clinical trials. Your query appears to be \"\n",
        "#                 \"about symptoms or conditions not directly related to diabetes. \"\n",
        "#                 \"If you have diabetes-related questions or symptoms (like high blood sugar, \"\n",
        "#                 \"insulin management, complications, etc.), I'd be happy to help! \"\n",
        "#                 \"Otherwise, please consult your healthcare provider for your current symptoms.\"\n",
        "#             )\n",
        "#             draft[\"confidence_veto\"] = True\n",
        "#             log = log_provenance_step(\n",
        "#                 \"DiagnosisAdvisor\",\n",
        "#                 {\"parsed\": parsed, \"retrieval_meta\": {\"avg_confidence\": avg_conf}},\n",
        "#                 draft,\n",
        "#                 {\"veto\": True, \"reason\": \"off_topic\"},\n",
        "#             )\n",
        "#             return draft, log\n",
        "\n",
        "#         # Handle low confidence\n",
        "#         if not trials or avg_conf < 0.15:\n",
        "#             draft[\"recommendation\"] = (\n",
        "#                 \"EVIDENCE IS INSUFFICIENT TO ANSWER THIS QUESTION DIRECTLY based on the \"\n",
        "#                 \"retrieved clinical trials. Please consult your healthcare provider.\"\n",
        "#             )\n",
        "#             draft[\"confidence_veto\"] = True\n",
        "#             log = log_provenance_step(\n",
        "#                 \"DiagnosisAdvisor\",\n",
        "#                 {\"parsed\": parsed, \"retrieval_meta\": {\"avg_confidence\": avg_conf, \"num_trials\": len(trials)}},\n",
        "#                 draft,\n",
        "#                 {\"veto\": True, \"reason\": \"low_confidence\"},\n",
        "#             )\n",
        "#             return draft, log\n",
        "\n",
        "#         # Route to appropriate handler\n",
        "#         if query_type == \"knowledge_seeking\":\n",
        "#             draft[\"recommendation\"] = self._handle_general_question(parsed, retrieved)\n",
        "#         else:\n",
        "#             draft[\"recommendation\"] = self._handle_symptom_query(parsed, retrieved)\n",
        "\n",
        "#         draft[\"confidence_veto\"] = False\n",
        "\n",
        "#         log = log_provenance_step(\n",
        "#             \"DiagnosisAdvisor\",\n",
        "#             {\"parsed\": parsed, \"retrieval_meta\": {\"avg_confidence\": avg_conf, \"num_trials\": len(trials)}},\n",
        "#             draft,\n",
        "#         )\n",
        "#         return draft, log\n",
        "\n",
        "# --- NEW DIAGNOSIS ADVISOR (CONTEXT AWARE) ---\n",
        "class DiagnosisAdvisor:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def _handle_general_question(self, parsed: Dict[str, Any], retrieved: Dict[str, Any]):\n",
        "        \"\"\"Handle general knowledge questions about diabetes\"\"\"\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        user_question = parsed.get(\"user_question\") or \" \".join(parsed.get(\"symptoms\", []))\n",
        "\n",
        "        # Build evidence context (top 3 trials)\n",
        "        evidence_parts = []\n",
        "        for t in trials[:3]:\n",
        "            evidence_parts.append(f\"Trial {t['nct_id']}: {t['text'][:400]}\")\n",
        "        evidence = \"\\n\\n\".join(evidence_parts) if evidence_parts else \"No specific trials available.\"\n",
        "\n",
        "        prompt = (\n",
        "            \"You are a diabetes health educator. Answer the user's question clearly using your medical knowledge.\\n\"\n",
        "            \"The clinical trial evidence below provides real-world context - mention it if relevant.\\n\\n\"\n",
        "            f\"USER'S QUESTION: {user_question}\\n\\n\"\n",
        "            \"CLINICAL TRIAL CONTEXT (for reference):\\n\"\n",
        "            f\"{evidence}\\n\\n\"\n",
        "            \"Instructions:\\n\"\n",
        "            \"- Answer the question directly in 3-5 sentences\\n\"\n",
        "            \"- Be specific and educational\\n\"\n",
        "            \"- If trials mention relevant findings, cite them briefly\\n\"\n",
        "            \"- End with: 'For personalized advice, please consult your healthcare provider.'\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            text = (res.text or \"\").strip()\n",
        "            if not text or len(text) < 50:\n",
        "                text = \"I don't have enough information to answer this question accurately. Please consult your healthcare provider.\"\n",
        "            return text\n",
        "        except Exception:\n",
        "            return \"Unable to generate an answer at this time. Please try rephrasing your question.\"\n",
        "\n",
        "    def _handle_symptom_query(self, parsed: Dict[str, Any], retrieved: Dict[str, Any], profile: Dict[str, Any]):\n",
        "        \"\"\"Handle symptom-based queries with evidence AND profile context\"\"\"\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        symptoms = parsed.get(\"symptoms\", [])\n",
        "        user_input = parsed.get(\"user_question\", \", \".join(symptoms))\n",
        "\n",
        "        # Inject Profile Context\n",
        "        known_conditions = \", \".join(profile.get(\"extracted_conditions\", []))\n",
        "        patient_context = f\"Patient Profile: Known conditions include {known_conditions}.\" if known_conditions else \"Patient Profile: New patient.\"\n",
        "\n",
        "        evidence_parts = []\n",
        "        for t in trials[:5]:  # Top 5 trials\n",
        "            evidence_parts.append(f\"‚Ä¢ {t['nct_id']}: {t['text'][:350]}\")\n",
        "        evidence = \"\\n\\n\".join(evidence_parts)\n",
        "\n",
        "        prompt = (\n",
        "            \"You are an evidence-based diabetes health assistant.\\n\"\n",
        "            \"The user has described diabetes-related symptoms or concerns. Provide a helpful, empathetic response.\\n\\n\"\n",
        "            f\"{patient_context}\\n\"\n",
        "            f\"USER'S SYMPTOMS/CONCERN: {user_input}\\n\\n\"\n",
        "            \"RETRIEVED CLINICAL TRIAL EVIDENCE:\\n\"\n",
        "            f\"{evidence}\\n\\n\"\n",
        "            \"Instructions:\\n\"\n",
        "            \"1. Start with 1-2 sentences acknowledging their concern (brief medical context)\\n\"\n",
        "            \"2. Say 'Several clinical trials have investigated this' or similar transition\\n\"\n",
        "            \"3. List 3-4 specific trials with brief descriptions:\\n\"\n",
        "            \"   ‚Ä¢ NCT... examines [brief focus]\\n\"\n",
        "            \"   ‚Ä¢ NCT... investigates [brief focus]\\n\"\n",
        "            \"4. Do NOT diagnose or recommend medication changes\\n\"\n",
        "            \"5. End with: 'Please discuss these findings with your healthcare provider before making any changes.'\\n\\n\"\n",
        "            \"Keep response concise (5-7 sentences total).\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            text = (res.text or \"\").strip()\n",
        "            if not text or len(text) < 50:\n",
        "                text = \"The retrieved trials may not directly address your specific symptoms. Please consult your healthcare provider.\"\n",
        "            return text\n",
        "        except Exception:\n",
        "            return \"Unable to generate advice at this time. Please consult your healthcare provider.\"\n",
        "\n",
        "    def advise(self, parsed: Dict[str, Any], retrieved: Dict[str, Any], profile: Dict[str, Any]):\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        avg_conf = retrieved.get(\"avg_confidence\", 0.0)\n",
        "        query_type = parsed.get(\"query_type\", \"symptom_matching\")\n",
        "        is_diabetes_related = parsed.get(\"is_diabetes_related\", True)\n",
        "\n",
        "        draft = {\n",
        "            \"recommendation\": \"\",\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"query_type\": query_type,\n",
        "        }\n",
        "\n",
        "        # Handle off-topic queries\n",
        "        if not is_diabetes_related:\n",
        "            draft[\"recommendation\"] = (\n",
        "                \"I'm specialized in diabetes-related clinical trials. Your query appears to be \"\n",
        "                \"about symptoms or conditions not directly related to diabetes. \"\n",
        "                \"If you have diabetes-related questions or symptoms (like high blood sugar, \"\n",
        "                \"insulin management, complications, etc.), I'd be happy to help! \"\n",
        "                \"Otherwise, please consult your healthcare provider for your current symptoms.\"\n",
        "            )\n",
        "            draft[\"confidence_veto\"] = True\n",
        "            log = log_provenance_step(\"DiagnosisAdvisor\", parsed, draft, {\"veto\": True, \"reason\": \"off_topic\"})\n",
        "            return draft, log\n",
        "\n",
        "        # Handle low confidence\n",
        "        if not trials or avg_conf < 0.15:\n",
        "            draft[\"recommendation\"] = (\n",
        "                \"EVIDENCE IS INSUFFICIENT TO ANSWER THIS QUESTION DIRECTLY based on the \"\n",
        "                \"retrieved clinical trials. Please consult your healthcare provider.\"\n",
        "            )\n",
        "            draft[\"confidence_veto\"] = True\n",
        "            log = log_provenance_step(\"DiagnosisAdvisor\", parsed, draft, {\"veto\": True, \"reason\": \"low_confidence\"})\n",
        "            return draft, log\n",
        "\n",
        "        # Route to appropriate handler\n",
        "        if query_type == \"knowledge_seeking\":\n",
        "            draft[\"recommendation\"] = self._handle_general_question(parsed, retrieved)\n",
        "        else:\n",
        "            draft[\"recommendation\"] = self._handle_symptom_query(parsed, retrieved, profile)\n",
        "\n",
        "        draft[\"confidence_veto\"] = False\n",
        "\n",
        "        log = log_provenance_step(\"DiagnosisAdvisor\", parsed, draft)\n",
        "        return draft, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# AGENT 5 ‚Äî ActiveSafetyFilter\n",
        "# ============================================================\n",
        "\n",
        "# --- OLD SAFETY FILTER (COMMENTED OUT) ---\n",
        "\n",
        "# class ActiveSafetyFilter:\n",
        "#     def __init__(self, model):\n",
        "#         self.model = model\n",
        "#         self.safety_cfg = {\n",
        "#             HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "#         }\n",
        "\n",
        "#     def verify(self, advice_text: str, trials: List[Dict[str, Any]]):\n",
        "#         evidence_text = \"\\n\".join(t[\"text\"] for t in trials)\n",
        "\n",
        "#         audit_prompt = (\n",
        "#             \"You are a Medical Safety Officer reviewing AI-generated advice.\\n\\n\"\n",
        "#             \"ADVICE:\\n\"\n",
        "#             f\"{advice_text}\\n\\n\"\n",
        "#             \"EVIDENCE FROM CLINICAL TRIALS:\\n\"\n",
        "#             f\"{evidence_text[:4000]}\\n\\n\"\n",
        "#             \"Check for safety issues:\\n\"\n",
        "#             \"- If the advice suggests stopping or changing medication without a doctor ‚Üí UNSAFE.\\n\"\n",
        "#             \"- If it gives a diagnosis ‚Üí UNSAFE.\\n\"\n",
        "#             \"- If it makes claims not supported by the evidence ‚Üí UNSAFE.\\n\\n\"\n",
        "#             'If the advice is acceptable, respond with exactly: SAFE\\n'\n",
        "#             'If it is not acceptable, respond starting with: CORRECTED: \\n'\n",
        "#         )\n",
        "\n",
        "#         try:\n",
        "#             res = self.model.generate_content(audit_prompt, safety_settings=self.safety_cfg)\n",
        "#             txt = (res.text or \"\").strip()\n",
        "#             if txt.startswith(\"SAFE\"):\n",
        "#                 final_text = advice_text\n",
        "#                 status = \"Pass\"\n",
        "#             else:\n",
        "#                 final_text = f\"‚ö†Ô∏è SAFETY REVISION:\\n{txt}\"\n",
        "#                 status = \"Revised\"\n",
        "#         except Exception:\n",
        "#             final_text = \"‚ö†Ô∏è Safety filter triggered. Please consult a doctor.\"\n",
        "#             status = \"Revised (API)\"\n",
        "\n",
        "#         log = log_provenance_step(\n",
        "#             \"ActiveSafetyFilter\",\n",
        "#             {\"advice\": advice_text},\n",
        "#             {\"final_text\": final_text, \"status\": status},\n",
        "#         )\n",
        "#         return final_text, status, log\n",
        "\n",
        "# --- NEW SAFETY FILTER (UNCHANGED BUT RE-DECLARED) ---\n",
        "class ActiveSafetyFilter:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.safety_cfg = {\n",
        "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "        }\n",
        "\n",
        "    def verify(self, advice_text: str, trials: List[Dict[str, Any]]):\n",
        "        evidence_text = \"\\n\".join(t[\"text\"] for t in trials)\n",
        "\n",
        "        audit_prompt = (\n",
        "            \"You are a Medical Safety Officer reviewing AI-generated advice.\\n\\n\"\n",
        "            \"ADVICE:\\n\"\n",
        "            f\"{advice_text}\\n\\n\"\n",
        "            \"EVIDENCE FROM CLINICAL TRIALS:\\n\"\n",
        "            f\"{evidence_text[:4000]}\\n\\n\"\n",
        "            \"Check for safety issues:\\n\"\n",
        "            \"- If the advice suggests stopping or changing medication without a doctor ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it gives a diagnosis ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it makes claims not supported by the evidence ‚Üí UNSAFE.\\n\\n\"\n",
        "            'If the advice is acceptable, respond with exactly: SAFE\\n'\n",
        "            'If it is not acceptable, respond starting with: CORRECTED: <safer version>\\n'\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(audit_prompt, safety_settings=self.safety_cfg)\n",
        "            txt = (res.text or \"\").strip()\n",
        "            if txt.startswith(\"SAFE\"):\n",
        "                final_text = advice_text\n",
        "                status = \"Pass\"\n",
        "            else:\n",
        "                final_text = f\"‚ö†Ô∏è SAFETY REVISION:\\n{txt}\"\n",
        "                status = \"Revised\"\n",
        "        except Exception:\n",
        "            final_text = \"‚ö†Ô∏è Safety filter triggered. Please consult a doctor.\"\n",
        "            status = \"Revised (API)\"\n",
        "\n",
        "        log = log_provenance_step(\n",
        "            \"ActiveSafetyFilter\",\n",
        "            {\"advice\": advice_text},\n",
        "            {\"final_text\": final_text, \"status\": status},\n",
        "        )\n",
        "        return final_text, status, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# HEALTHCARE BOT (Orchestrator)\n",
        "# ============================================================\n",
        "\n",
        "# --- OLD BOT (COMMENTED OUT) ---\n",
        "# ============================================================\n",
        "# HEALTHCARE BOT (Orchestrator)\n",
        "# ============================================================\n",
        "\n",
        "# class HealthcareBot:\n",
        "#     def __init__(self, gemini_model, embed_model, faiss_index, chunk_map, initial_profile=None):\n",
        "#         self.parser = SymptomParser(gemini_model)\n",
        "#         self.profile_agent = ProfileAgent(initial_profile)\n",
        "#         self.retriever = RetrievalAgent(embed_model, faiss_index, chunk_map, self.profile_agent)\n",
        "#         self.advisor = DiagnosisAdvisor(gemini_model)\n",
        "#         self.safety = ActiveSafetyFilter(gemini_model)\n",
        "\n",
        "#         self.history: List[Dict[str, Any]] = []\n",
        "#         self.provenance_chain: List[Dict[str, Any]] = []\n",
        "\n",
        "#     def _handle_simple_greeting(self, user_input: str):\n",
        "#         user_id = self.profile_agent.profile.get(\"user_id\", \"there\")\n",
        "#         msg = (\n",
        "#             f\"Hello {user_id}! I'm your clinical trial health assistant. \"\n",
        "#             \"Tell me your symptoms or a question about diabetes-related trials, \"\n",
        "#             \"and I‚Äôll summarize relevant evidence. I cannot diagnose or give direct medical orders.\"\n",
        "#         )\n",
        "\n",
        "#         log = log_provenance_step(\n",
        "#             \"GreetingAgent\",\n",
        "#             user_input,\n",
        "#             msg,\n",
        "#             {\"type\": \"greeting\"},\n",
        "#         )\n",
        "#         self.provenance_chain.append(log)\n",
        "\n",
        "#         session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "#         self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "#         return {\n",
        "#             \"recommendation\": msg,\n",
        "#             \"cited_trials\": [],\n",
        "#             \"safety_status\": \"Non-RAG\",\n",
        "#             \"session_hash\": session_hash,\n",
        "#             \"provenance_chain\": self.provenance_chain,\n",
        "#         }\n",
        "\n",
        "\n",
        "\n",
        "#     def _handle_off_topic(self, user_input: str, parsed: Dict[str, Any]):\n",
        "#         \"\"\"Handle off-topic queries\"\"\"\n",
        "#         msg = (\n",
        "#             \"I'm specialized in diabetes-related clinical trials and information. \"\n",
        "#             \"Your query appears to be about symptoms or conditions not directly related to diabetes. \"\n",
        "#             \"If you have diabetes-related questions (blood sugar, insulin, complications, medications, etc.), \"\n",
        "#             \"I'd be happy to help! Otherwise, please consult your healthcare provider.\"\n",
        "#         )\n",
        "\n",
        "#         log = log_provenance_step(\"OffTopicHandler\", user_input, msg, {\"type\": \"off_topic\"})\n",
        "#         self.provenance_chain.append(log)\n",
        "\n",
        "#         session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "#         turn_data = {\n",
        "#             \"query\": user_input,\n",
        "#             \"parsed\": parsed,\n",
        "#             \"nct_ids\": [],\n",
        "#             \"safety_status\": \"Off-topic\",\n",
        "#             \"session_hash\": session_hash,\n",
        "#         }\n",
        "#         profile_log = self.profile_agent.update_profile(turn_data)\n",
        "#         self.provenance_chain.append(profile_log)\n",
        "#         self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "#         return {\n",
        "#             \"recommendation\": msg,\n",
        "#             \"cited_trials\": [],\n",
        "#             \"safety_status\": \"Off-topic\",\n",
        "#             \"session_hash\": session_hash,\n",
        "#             \"provenance_chain\": self.provenance_chain,\n",
        "#         }\n",
        "\n",
        "\n",
        "\n",
        "#     def _handle_knowledge_question(self, user_input: str, parsed: Dict[str, Any]):\n",
        "#         \"\"\"Handle general diabetes knowledge questions using LLM's built-in knowledge\"\"\"\n",
        "\n",
        "#         user_question = parsed.get(\"user_question\", user_input)\n",
        "\n",
        "#         prompt = (\n",
        "#             \"You are a certified diabetes educator. Answer this question clearly and accurately \"\n",
        "#             \"using evidence-based medical knowledge.\\n\\n\"\n",
        "#             f\"QUESTION: {user_question}\\n\\n\"\n",
        "#             \"Instructions:\\n\"\n",
        "#             \"- Provide a clear, educational answer (4-6 sentences)\\n\"\n",
        "#             \"- Use medical accuracy\\n\"\n",
        "#             \"- Be specific with examples when relevant\\n\"\n",
        "#             \"- Mention that clinical trials are available if they want personalized info\\n\"\n",
        "#             \"- End with: 'For personalized guidance based on your specific situation, \"\n",
        "#             \"please ask about your symptoms or consult your healthcare provider.'\\n\"\n",
        "#         )\n",
        "\n",
        "#         try:\n",
        "#             res = self.advisor.model.generate_content(prompt)\n",
        "#             answer = (res.text or \"\").strip()\n",
        "\n",
        "#             if not answer or len(answer) < 50:\n",
        "#                 answer = (\n",
        "#                     \"I can help you find relevant clinical trials for your specific symptoms. \"\n",
        "#                     \"For general diabetes information, please consult your healthcare provider \"\n",
        "#                     \"or ask me about specific symptoms you're experiencing.\"\n",
        "#                 )\n",
        "#         except Exception:\n",
        "#             answer = \"Unable to answer at this time. Please try rephrasing your question.\"\n",
        "\n",
        "#         # Log as knowledge-based response\n",
        "#         log = log_provenance_step(\n",
        "#             \"KnowledgeAgent\",\n",
        "#             user_input,\n",
        "#             answer,\n",
        "#             {\"type\": \"general_knowledge\", \"no_retrieval\": True}\n",
        "#         )\n",
        "#         self.provenance_chain.append(log)\n",
        "\n",
        "#         session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "#         # Update profile\n",
        "#         turn_data = {\n",
        "#             \"query\": user_input,\n",
        "#             \"parsed\": parsed,\n",
        "#             \"nct_ids\": [],\n",
        "#             \"safety_status\": \"Knowledge-Based (No Retrieval)\",\n",
        "#             \"session_hash\": session_hash,\n",
        "#         }\n",
        "#         profile_log = self.profile_agent.update_profile(turn_data)\n",
        "#         self.provenance_chain.append(profile_log)\n",
        "#         self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "#         return {\n",
        "#             \"recommendation\": answer,\n",
        "#             \"cited_trials\": [],\n",
        "#             \"safety_status\": \"Knowledge-Based (No Retrieval)\",\n",
        "#             \"session_hash\": session_hash,\n",
        "#             \"provenance_chain\": self.provenance_chain,\n",
        "#         }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     def process_query(self, user_input: str):\n",
        "#         self.provenance_chain = []\n",
        "\n",
        "#         # 1. Parse\n",
        "#         parsed, parse_log = self.parser.parse(user_input)\n",
        "#         self.provenance_chain.append(parse_log)\n",
        "\n",
        "#         intent = (parsed.get(\"intent\") or \"symptom_query\").lower()\n",
        "#         is_diabetes_related = parsed.get(\"is_diabetes_related\", True)\n",
        "#         query_type = parsed.get(\"query_type\", \"symptom_matching\")\n",
        "\n",
        "#         # Handle greetings\n",
        "#         if intent == \"greeting\":\n",
        "#             return self._handle_simple_greeting(user_input)\n",
        "\n",
        "#         # Handle off-topic queries (skip retrieval)\n",
        "#         if intent == \"off_topic\" or not is_diabetes_related:\n",
        "#             msg = (\n",
        "#                 \"I'm specialized in diabetes-related clinical trials. Your query appears to be \"\n",
        "#                 \"about symptoms or conditions not directly related to diabetes. \"\n",
        "#                 \"If you have diabetes-related questions or symptoms (like high blood sugar, \"\n",
        "#                 \"insulin management, complications, etc.), I'd be happy to help!\"\n",
        "#             )\n",
        "\n",
        "#             session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "#             turn_data = {\n",
        "#                 \"query\": user_input,\n",
        "#                 \"parsed\": parsed,\n",
        "#                 \"nct_ids\": [],\n",
        "#                 \"safety_status\": \"Off-topic (No Retrieval)\",\n",
        "#                 \"session_hash\": session_hash,\n",
        "#             }\n",
        "#             profile_log = self.profile_agent.update_profile(turn_data)\n",
        "#             self.provenance_chain.append(profile_log)\n",
        "#             self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "#             return {\n",
        "#                 \"recommendation\": msg,\n",
        "#                 \"cited_trials\": [],\n",
        "#                 \"safety_status\": \"Off-topic (No Retrieval)\",\n",
        "#                 \"session_hash\": session_hash,\n",
        "#                 \"provenance_chain\": self.provenance_chain,\n",
        "#             }\n",
        "\n",
        "#         # NEW: Handle general knowledge questions (no retrieval needed)\n",
        "#         if query_type == \"knowledge_seeking\":\n",
        "#             user_question = parsed.get(\"user_question\", user_input)\n",
        "\n",
        "#             prompt = (\n",
        "#                 \"You are a certified diabetes educator. Answer this question clearly and accurately \"\n",
        "#                 \"using evidence-based medical knowledge.\\n\\n\"\n",
        "#                 f\"QUESTION: {user_question}\\n\\n\"\n",
        "#                 \"Instructions:\\n\"\n",
        "#                 \"- Provide a clear, educational answer (4-6 sentences)\\n\"\n",
        "#                 \"- Use medical accuracy and be specific\\n\"\n",
        "#                 \"- Mention common examples when relevant\\n\"\n",
        "#                 \"- End with: 'For personalized guidance based on your specific situation, \"\n",
        "#                 \"please describe your symptoms or consult your healthcare provider.'\\n\"\n",
        "#             )\n",
        "\n",
        "#             try:\n",
        "#                 res = self.advisor.model.generate_content(prompt)\n",
        "#                 answer = (res.text or \"\").strip()\n",
        "\n",
        "#                 if not answer or len(answer) < 50:\n",
        "#                     answer = (\n",
        "#                         \"I can help you find relevant clinical trials for your specific symptoms. \"\n",
        "#                         \"For general diabetes information, please consult your healthcare provider \"\n",
        "#                         \"or ask me about specific symptoms you're experiencing.\"\n",
        "#                     )\n",
        "#             except Exception:\n",
        "#                 answer = \"Unable to answer at this time. Please try rephrasing your question.\"\n",
        "\n",
        "#             # Log as knowledge-based response\n",
        "#             log = log_provenance_step(\n",
        "#                 \"KnowledgeAgent\",\n",
        "#                 user_input,\n",
        "#                 answer,\n",
        "#                 {\"type\": \"general_knowledge\", \"no_retrieval\": True}\n",
        "#             )\n",
        "#             self.provenance_chain.append(log)\n",
        "\n",
        "#             session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "#             turn_data = {\n",
        "#                 \"query\": user_input,\n",
        "#                 \"parsed\": parsed,\n",
        "#                 \"nct_ids\": [],\n",
        "#                 \"safety_status\": \"Knowledge-Based (No Retrieval)\",\n",
        "#                 \"session_hash\": session_hash,\n",
        "#             }\n",
        "#             profile_log = self.profile_agent.update_profile(turn_data)\n",
        "#             self.provenance_chain.append(profile_log)\n",
        "#             self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "#             return {\n",
        "#                 \"recommendation\": answer,\n",
        "#                 \"cited_trials\": [],\n",
        "#                 \"safety_status\": \"Knowledge-Based (No Retrieval)\",\n",
        "#                 \"session_hash\": session_hash,\n",
        "#                 \"provenance_chain\": self.provenance_chain,\n",
        "#             }\n",
        "\n",
        "#         # 2. Retrieve (for symptom queries)\n",
        "#         retrieved, retrieve_log = self.retriever.retrieve(parsed)\n",
        "#         self.provenance_chain.append(retrieve_log)\n",
        "\n",
        "#         # 3. Advisor\n",
        "#         draft_advice, advise_log = self.advisor.advise(parsed, retrieved)\n",
        "#         self.provenance_chain.append(advise_log)\n",
        "\n",
        "#         trials = retrieved.get(\"trials\", [])\n",
        "#         if draft_advice.get(\"confidence_veto\", False) or not trials:\n",
        "#             final_text = draft_advice[\"recommendation\"]\n",
        "#             safety_status = \"Vetoed (Low Confidence)\"\n",
        "#             evidence_list = []\n",
        "#         else:\n",
        "#             # 4. Safety\n",
        "#             final_text, safety_status, safety_log = self.safety.verify(\n",
        "#                 draft_advice[\"recommendation\"],\n",
        "#                 trials,\n",
        "#             )\n",
        "#             self.provenance_chain.append(safety_log)\n",
        "#             evidence_list = trials\n",
        "\n",
        "#         nct_ids = [t[\"nct_id\"] for t in evidence_list]\n",
        "\n",
        "#         session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "#         # 5. Update profile/history\n",
        "#         turn_data = {\n",
        "#             \"query\": user_input,\n",
        "#             \"parsed\": parsed,\n",
        "#             \"nct_ids\": nct_ids,\n",
        "#             \"safety_status\": safety_status,\n",
        "#             \"session_hash\": session_hash,\n",
        "#         }\n",
        "#         profile_log = self.profile_agent.update_profile(turn_data)\n",
        "#         self.provenance_chain.append(profile_log)\n",
        "#         self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "#         return {\n",
        "#             \"recommendation\": final_text,\n",
        "#             \"cited_trials\": nct_ids,\n",
        "#             \"safety_status\": safety_status,\n",
        "#             \"session_hash\": session_hash,\n",
        "#             \"provenance_chain\": self.provenance_chain,\n",
        "#         }\n",
        "\n",
        "\n",
        "\n",
        "# --- NEW BOT (ORCHESTRATOR) ---\n",
        "class HealthcareBot:\n",
        "    def __init__(self, gemini_model, embed_model, faiss_index, chunk_map, initial_profile=None):\n",
        "        self.parser = SymptomParser(gemini_model)\n",
        "        self.profile_agent = ProfileAgent(initial_profile)\n",
        "        self.retriever = RetrievalAgent(embed_model, faiss_index, chunk_map, self.profile_agent)\n",
        "        self.advisor = DiagnosisAdvisor(gemini_model)\n",
        "        self.safety = ActiveSafetyFilter(gemini_model)\n",
        "\n",
        "        self.history: List[Dict[str, Any]] = []\n",
        "        self.provenance_chain: List[Dict[str, Any]] = []\n",
        "\n",
        "    def _handle_simple_greeting(self, user_input: str):\n",
        "        user_id = self.profile_agent.profile.get(\"user_id\", \"there\")\n",
        "        msg = (\n",
        "            f\"Hello {user_id}! I'm your clinical trial health assistant. \"\n",
        "            \"Tell me your symptoms or a question about diabetes-related trials, \"\n",
        "            \"and I‚Äôll summarize relevant evidence. I cannot diagnose or give direct medical orders.\"\n",
        "        )\n",
        "\n",
        "        log = log_provenance_step(\"GreetingAgent\", user_input, msg, {\"type\": \"greeting\"})\n",
        "        self.provenance_chain.append(log)\n",
        "\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "        self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": msg,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Non-RAG\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "    def _handle_off_topic(self, user_input: str, parsed: Dict[str, Any]):\n",
        "        msg = (\n",
        "            \"I'm specialized in diabetes-related clinical trials. Your query appears to be \"\n",
        "            \"about symptoms or conditions not directly related to diabetes. \"\n",
        "            \"If you have diabetes-related questions, I'd be happy to help!\"\n",
        "        )\n",
        "        log = log_provenance_step(\"OffTopicHandler\", user_input, msg, {\"type\": \"off_topic\"})\n",
        "        self.provenance_chain.append(log)\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": msg,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Off-topic\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "    def _handle_knowledge_question(self, user_input: str, parsed: Dict[str, Any]):\n",
        "        user_question = parsed.get(\"user_question\", user_input)\n",
        "        prompt = (\n",
        "            \"You are a certified diabetes educator. Answer this question clearly and accurately.\\n\"\n",
        "            f\"QUESTION: {user_question}\\n\"\n",
        "        )\n",
        "        try:\n",
        "            res = self.advisor.model.generate_content(prompt)\n",
        "            answer = (res.text or \"\").strip()\n",
        "        except:\n",
        "            answer = \"Unable to answer at this time.\"\n",
        "\n",
        "        log = log_provenance_step(\"KnowledgeAgent\", user_input, answer, {\"type\": \"general_knowledge\"})\n",
        "        self.provenance_chain.append(log)\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": answer,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Knowledge-Based\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "    def process_query(self, user_input: str):\n",
        "        self.provenance_chain = []\n",
        "\n",
        "        # 1. Parse\n",
        "        parsed, parse_log = self.parser.parse(user_input)\n",
        "        self.provenance_chain.append(parse_log)\n",
        "\n",
        "        intent = (parsed.get(\"intent\") or \"symptom_query\").lower()\n",
        "        is_diabetes_related = parsed.get(\"is_diabetes_related\", True)\n",
        "        query_type = parsed.get(\"query_type\", \"symptom_matching\")\n",
        "\n",
        "        if intent == \"greeting\":\n",
        "            return self._handle_simple_greeting(user_input)\n",
        "        if intent == \"off_topic\" or not is_diabetes_related:\n",
        "            return self._handle_off_topic(user_input, parsed)\n",
        "        if query_type == \"knowledge_seeking\":\n",
        "            return self._handle_knowledge_question(user_input, parsed)\n",
        "\n",
        "        # 2. Retrieve (now with Reranker)\n",
        "        retrieved, retrieve_log = self.retriever.retrieve(parsed)\n",
        "        self.provenance_chain.append(retrieve_log)\n",
        "\n",
        "        # 3. Advisor (now with Profile Context)\n",
        "        draft_advice, advise_log = self.advisor.advise(parsed, retrieved, self.profile_agent.profile)\n",
        "        self.provenance_chain.append(advise_log)\n",
        "\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        if draft_advice.get(\"confidence_veto\", False) or not trials:\n",
        "            final_text = draft_advice[\"recommendation\"]\n",
        "            safety_status = \"Vetoed (Low Confidence)\"\n",
        "            evidence_list = []\n",
        "        else:\n",
        "            # 4. Safety\n",
        "            final_text, safety_status, safety_log = self.safety.verify(draft_advice[\"recommendation\"], trials)\n",
        "            self.provenance_chain.append(safety_log)\n",
        "            evidence_list = trials\n",
        "\n",
        "        nct_ids = [t[\"nct_id\"] for t in evidence_list]\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "        # 5. Update profile/history\n",
        "        turn_data = {\n",
        "            \"query\": user_input,\n",
        "            \"parsed\": parsed,\n",
        "            \"nct_ids\": nct_ids,\n",
        "            \"safety_status\": safety_status,\n",
        "            \"session_hash\": session_hash,\n",
        "        }\n",
        "        profile_log = self.profile_agent.update_profile(turn_data)\n",
        "        self.provenance_chain.append(profile_log)\n",
        "        self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": final_text,\n",
        "            \"cited_trials\": nct_ids,\n",
        "            \"safety_status\": safety_status,\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "# ============================================================\n",
        "# GLOBAL BOT INSTANCE + ENTRYPOINT\n",
        "# ============================================================\n",
        "\n",
        "default_profile = {\n",
        "    \"user_id\": \"Patient\",\n",
        "    \"conditions\": [\"diabetes\"],\n",
        "    \"extracted_conditions\": []\n",
        "}\n",
        "\n",
        "_bot = HealthcareBot(gemini_model, embed_model, faiss_index, chunk_map, initial_profile=default_profile)\n",
        "\n",
        "def run_bot(user_input: str) -> Dict[str, Any]:\n",
        "    return _bot.process_query(user_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLn6JKXmMFog",
        "outputId": "19ab5532-c4a6-4f6f-b9d4-1570805d28b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run_bot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UI frontend application simple web interface\n",
        "\n",
        "https://docs.streamlit.io/develop/tutorials/chat-and-llm-apps/build-conversational-apps"
      ],
      "metadata": {
        "id": "mDxpjMNrCwCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "\n",
        "if \"GEMINI_API_KEY\" not in os.environ:\n",
        "    st.error(\"‚ö†Ô∏è API Key missing! Please run the 'Secure Input' cell in the notebook first.\")\n",
        "\n",
        "from run_bot import run_bot\n",
        "\n",
        "st.title(\"Clinical Trial Health Advisor ü§ñ\")\n",
        "st.caption(\"AI for Healthcare - Clinical Trials RAG\")\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "for msg in st.session_state.messages:\n",
        "    with st.chat_message(msg[\"role\"]):\n",
        "        st.markdown(msg[\"content\"])\n",
        "\n",
        "if user_input := st.chat_input(\"Describe your symptoms...\"):\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(user_input)\n",
        "\n",
        "    with st.spinner(\"Searching clinical trials...\"):\n",
        "        result = run_bot(user_input)\n",
        "        reply = result[\"recommendation\"]\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(reply)\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": reply})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EqkmxVqOkZ-",
        "outputId": "bee45924-9ddd-4e95-fee6-f68af09eabda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 cloudflared\n",
        "!chmod +x cloudflared"
      ],
      "metadata": {
        "id": "u5BcqHNUOklc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AI LLM\n",
        "!streamlit run app.py &>/dev/null&\n",
        "!./cloudflared tunnel --url http://localhost:8501 --no-autoupdate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZqn_TJIOkuT",
        "outputId": "4a73d25e-e3f2-4727-93ea-bffa37175670"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-11-24T22:49:36Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-11-24T22:49:36Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m |  https://dennis-tree-spas-limitation.trycloudflare.com                                     |\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 991dffd8889ee9f0147b6b48933da9e4407e68ea8c6d984f55fa2d3db4bb431d)\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 624c79de-832f-4c3d-9c80-ff56a5665ab0\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-11-24T22:49:39Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.73\n",
            "2025/11/24 22:49:39 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-11-24T22:49:40Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m27a409da-1ed0-4ba4-811e-62d97d471306 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.73 \u001b[36mlocation=\u001b[0msea07 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-11-24T22:51:40Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2025-11-24T22:51:40Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to run the datagram handler \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.73\n",
            "\u001b[90m2025-11-24T22:51:40Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.73\n",
            "\u001b[90m2025-11-24T22:51:40Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Serve tunnel error \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.73\n",
            "\u001b[90m2025-11-24T22:51:40Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.73\n",
            "\u001b[90m2025-11-24T22:51:40Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Connection terminated \u001b[36mconnIndex=\u001b[0m0\n",
            "\u001b[90m2025-11-24T22:51:40Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2025-11-24T22:51:40Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2025-11-24T22:51:40Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ]
    }
  ]
}