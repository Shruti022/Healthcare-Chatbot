{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keVc9VWJI9ZI"
      },
      "source": [
        "Qdrant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "vk3hdJJ4Bpg8",
        "outputId": "b185ab94-a6e0-40ab-c65c-37c08115e56e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîë Enter your Qdrant API Key (input will be hidden):\n",
            "Qdrant API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ API Key captured securely\n"
          ]
        },
        {
          "ename": "UnexpectedResponse",
          "evalue": "Unexpected Response: 409 (Conflict)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Collection `clinical_trials` already exists!\"},\"time\":0.038894767}'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnexpectedResponse\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2140676068.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Create collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m client.create_collection(\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"clinical_trials\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mvectors_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVectorParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOSINE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/qdrant_client.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, collection_name, vectors_config, sparse_vectors_config, shard_number, sharding_method, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, timeout, strict_mode_config, metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Unknown arguments: {list(kwargs.keys())}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m         return self._client.create_collection(\n\u001b[0m\u001b[1;32m   1704\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m             \u001b[0mvectors_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectors_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/qdrant_remote.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, collection_name, vectors_config, shard_number, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, timeout, sparse_vectors_config, sharding_method, strict_mode_config, metadata, **kwargs)\u001b[0m\n\u001b[1;32m   2037\u001b[0m         )\n\u001b[1;32m   2038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2039\u001b[0;31m         result: Optional[bool] = self.http.collections_api.create_collection(\n\u001b[0m\u001b[1;32m   2040\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m             \u001b[0mcreate_collection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_collection_request\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api/collections_api.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, collection_name, timeout, create_collection)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mcollection\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \"\"\"\n\u001b[0;32m--> 294\u001b[0;31m         return self._build_for_create_collection(\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api/collections_api.py\u001b[0m in \u001b[0;36m_build_for_create_collection\u001b[0;34m(self, collection_name, timeout, create_collection)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"Content-Type\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         return self.api_client.request(\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mtype_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInlineResponse200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"PUT\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, type_, method, url, path_params, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, type_)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValidationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mResponseHandlingException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mUnexpectedResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnexpectedResponse\u001b[0m: Unexpected Response: 409 (Conflict)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Collection `clinical_trials` already exists!\"},\"time\":0.038894767}'"
          ]
        }
      ],
      "source": [
        "# Install Qdrant client\n",
        "!pip install qdrant-client -q\n",
        "\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams\n",
        "import getpass\n",
        "\n",
        "# üîë Secure API Key Input (invisible)\n",
        "print(\"üîë Enter your Qdrant API Key (input will be hidden):\")\n",
        "qdrant_api_key = getpass.getpass(\"Qdrant API Key: \")\n",
        "\n",
        "# Verify key format\n",
        "if qdrant_api_key and len(qdrant_api_key) > 10:\n",
        "    print(\"‚úÖ API Key captured securely\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è API Key seems invalid\")\n",
        "\n",
        "# Connect to your cluster\n",
        "client = QdrantClient(\n",
        "    url=\"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\",\n",
        "    api_key=qdrant_api_key\n",
        ")\n",
        "\n",
        "# Create collection\n",
        "client.create_collection(\n",
        "    collection_name=\"clinical_trials\",\n",
        "    vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Collection 'clinical_trials' created successfully!\")\n",
        "\n",
        "# Verify\n",
        "collections = client.get_collections()\n",
        "print(f\"\\nüìä Collections: {collections}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34p7QlZPD7O6",
        "outputId": "00393c14-01d7-44f7-d5d3-263bade3f329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni15p_feDbUn",
        "outputId": "d217654a-ca5c-4500-e11b-9570fced2601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Checking if files exist in Drive:\n",
            "\n",
            "‚úÖ clinical_trials_all_full_embeddings.npy: EXISTS (384.8 MB)\n",
            "‚úÖ clinical_trials_all_full_chunk_map.json: EXISTS (230.6 MB)\n",
            "‚úÖ clinical_trials_all_full_faiss.index: EXISTS (384.8 MB)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "BASE = \"/content/drive/.shortcut-targets-by-id/1-SiVJhXHTHtDYSrPmW_0VfuP7gSTePcj/data\"\n",
        "\n",
        "# Check if files exist\n",
        "files_to_check = [\n",
        "    \"clinical_trials_all_full_embeddings.npy\",\n",
        "    \"clinical_trials_all_full_chunk_map.json\",\n",
        "    \"clinical_trials_all_full_faiss.index\"\n",
        "]\n",
        "\n",
        "print(\"üìÅ Checking if files exist in Drive:\\n\")\n",
        "for filename in files_to_check:\n",
        "    filepath = f\"{BASE}/{filename}\"\n",
        "    exists = os.path.exists(filepath)\n",
        "    if exists:\n",
        "        size_mb = os.path.getsize(filepath) / (1024*1024)\n",
        "        print(f\"‚úÖ {filename}: EXISTS ({size_mb:.1f} MB)\")\n",
        "    else:\n",
        "        print(f\"‚ùå {filename}: NOT FOUND\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QncCxftPETth"
      },
      "source": [
        "Load Data and Upload to Qdrant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGUCNt3vCS7i",
        "outputId": "6816c37a-1ae7-4d6b-8dc5-2de2546b7082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Loading embeddings and chunk map from Drive...\n",
            "‚úÖ Loaded 262660 embeddings (shape: (262660, 384))\n",
            "‚úÖ Loaded 262660 chunks of metadata\n",
            "‚úÖ Data verified: 262660 vectors ready to upload\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "BASE = \"/content/drive/.shortcut-targets-by-id/1-SiVJhXHTHtDYSrPmW_0VfuP7gSTePcj/data\"\n",
        "\n",
        "print(\"‚è≥ Loading embeddings and chunk map from Drive...\")\n",
        "\n",
        "# Load embeddings (384.8 MB)\n",
        "embeddings = np.load(f\"{BASE}/clinical_trials_all_full_embeddings.npy\")\n",
        "print(f\"‚úÖ Loaded {len(embeddings)} embeddings (shape: {embeddings.shape})\")\n",
        "\n",
        "# Load chunk map (metadata - 230.6 MB)\n",
        "with open(f\"{BASE}/clinical_trials_all_full_chunk_map.json\", \"r\") as f:\n",
        "    chunk_map = json.load(f)\n",
        "print(f\"‚úÖ Loaded {len(chunk_map)} chunks of metadata\")\n",
        "\n",
        "# Verify sizes match\n",
        "if len(embeddings) == len(chunk_map):\n",
        "    print(f\"‚úÖ Data verified: {len(embeddings)} vectors ready to upload\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è WARNING: Mismatch! {len(embeddings)} embeddings vs {len(chunk_map)} chunks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-ced4uTCTHh",
        "outputId": "aa6fe6e1-6ab4-47b8-d82b-0636e029215f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîë Enter your Qdrant API Key again:\n",
            "Qdrant API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ Connected to Qdrant\n",
            "\n",
            "‚è≥ Uploading vectors to Qdrant...\n",
            "‚ö†Ô∏è This will take 5-10 minutes for 262K vectors. Please wait...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2627/2627 [13:20<00:00,  3.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Successfully uploaded 262660 vectors to Qdrant!\n",
            "\n",
            "üìä Final Collection Stats:\n",
            "   ‚úÖ Total vectors: 262,660\n",
            "   ‚úÖ Vector dimension: 384\n",
            "   ‚úÖ Distance metric: Cosine\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from qdrant_client.models import PointStruct\n",
        "import getpass\n",
        "\n",
        "# Reconnect to Qdrant (in case session expired)\n",
        "print(\"\\nüîë Enter your Qdrant API Key again:\")\n",
        "qdrant_api_key = getpass.getpass(\"Qdrant API Key: \")\n",
        "\n",
        "from qdrant_client import QdrantClient\n",
        "\n",
        "client = QdrantClient(\n",
        "    url=\"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\",\n",
        "    api_key=qdrant_api_key\n",
        ")\n",
        "print(\"‚úÖ Connected to Qdrant\")\n",
        "\n",
        "print(\"\\n‚è≥ Uploading vectors to Qdrant...\")\n",
        "print(\"‚ö†Ô∏è This will take 5-10 minutes for 262K vectors. Please wait...\\n\")\n",
        "\n",
        "# Batch upload (100 vectors at a time)\n",
        "batch_size = 100\n",
        "total_batches = (len(embeddings) + batch_size - 1) // batch_size\n",
        "\n",
        "for i in tqdm(range(0, len(embeddings), batch_size), desc=\"Uploading\", total=total_batches):\n",
        "    batch_end = min(i + batch_size, len(embeddings))\n",
        "\n",
        "    points = []\n",
        "    for idx in range(i, batch_end):\n",
        "        points.append(\n",
        "            PointStruct(\n",
        "                id=idx,\n",
        "                vector=embeddings[idx].tolist(),\n",
        "                payload={\n",
        "                    \"nct_id\": chunk_map[idx][\"nct_id\"],\n",
        "                    \"title\": chunk_map[idx][\"title\"],\n",
        "                    \"text\": chunk_map[idx][\"text\"],\n",
        "                    \"status\": chunk_map[idx][\"status\"]\n",
        "                }\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Upload batch\n",
        "    client.upsert(\n",
        "        collection_name=\"clinical_trials\",\n",
        "        points=points\n",
        "    )\n",
        "\n",
        "print(f\"\\n‚úÖ Successfully uploaded {len(embeddings)} vectors to Qdrant!\")\n",
        "\n",
        "# Verify upload\n",
        "collection_info = client.get_collection(\"clinical_trials\")\n",
        "print(f\"\\nüìä Final Collection Stats:\")\n",
        "print(f\"   ‚úÖ Total vectors: {collection_info.points_count:,}\")\n",
        "print(f\"   ‚úÖ Vector dimension: {collection_info.config.params.vectors.size}\")\n",
        "print(f\"   ‚úÖ Distance metric: {collection_info.config.params.vectors.distance}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc0oinFnhY8p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvziMQpXhY_J"
      },
      "outputs": [],
      "source": [
        "%%writefile update_qdrant_from_drive.py\n",
        "\"\"\"\n",
        "Read CSV files from Google Drive ‚Üí Generate embeddings ‚Üí Upload to Qdrant\n",
        "No intermediate files needed!\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import PointStruct, Distance, VectorParams\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "class QdrantDataPipeline:\n",
        "    def __init__(self, qdrant_url, qdrant_api_key):\n",
        "        self.client = QdrantClient(url=qdrant_url, api_key=qdrant_api_key)\n",
        "        self.embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "        self.collection_name = \"clinical_trials\"\n",
        "\n",
        "    def load_and_filter_csvs(self, drive_base_path, csv_names):\n",
        "        \"\"\"Load multiple CSVs from Drive and filter\"\"\"\n",
        "        print(\"üìÇ Loading CSV files from Drive...\")\n",
        "\n",
        "        dfs = []\n",
        "        for csv_name in csv_names:\n",
        "            csv_path = f\"{drive_base_path}/{csv_name}\"\n",
        "            print(f\"   Loading {csv_name}...\")\n",
        "            df = pd.read_csv(csv_path)\n",
        "            dfs.append(df)\n",
        "\n",
        "        # Concatenate all\n",
        "        df_all = pd.concat(dfs, ignore_index=True)\n",
        "        print(f\"‚úÖ Loaded {len(df_all)} total trials\")\n",
        "\n",
        "        # Filter bad statuses\n",
        "        df_all[\"status\"] = df_all[\"status\"].astype(str).str.strip().str.title()\n",
        "        bad_status = [\"Terminated\", \"Withdrawn\", \"Suspended\", \"No Longer Available\", \"Unknown\"]\n",
        "        df_clean = df_all[~df_all[\"status\"].isin(bad_status)].copy()\n",
        "\n",
        "        print(f\"‚úÖ After filtering: {len(df_clean)} trials\")\n",
        "        return df_clean\n",
        "\n",
        "    def create_chunks(self, df_clean):\n",
        "        \"\"\"Create text chunks from DataFrame\"\"\"\n",
        "        print(\"üìù Creating chunks...\")\n",
        "\n",
        "        chunks = []\n",
        "        for idx, row in df_clean.iterrows():\n",
        "            title = str(row.get(\"brief_title\", \"\")).strip()\n",
        "            summary = str(row.get(\"brief_summary\", \"\")).strip()\n",
        "\n",
        "            if len(summary) < 20:\n",
        "                continue\n",
        "\n",
        "            text = f\"Title: {title}\\nSummary: {summary}\"\n",
        "\n",
        "            chunks.append({\n",
        "                \"nct_id\": row[\"nct_id\"],\n",
        "                \"title\": title,\n",
        "                \"text\": text,\n",
        "                \"status\": row[\"status\"]\n",
        "            })\n",
        "\n",
        "        print(f\"‚úÖ Created {len(chunks)} chunks\")\n",
        "        return chunks\n",
        "\n",
        "    def generate_embeddings(self, chunks):\n",
        "        \"\"\"Generate embeddings for all chunks\"\"\"\n",
        "        print(\"üß† Generating embeddings...\")\n",
        "\n",
        "        texts = [c[\"text\"] for c in chunks]\n",
        "        embeddings = self.embed_model.encode(\n",
        "            texts,\n",
        "            batch_size=64,\n",
        "            show_progress_bar=True,\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "        print(f\"‚úÖ Generated {len(embeddings)} embeddings\")\n",
        "        return embeddings\n",
        "\n",
        "    def upload_to_qdrant(self, embeddings, chunks, mode=\"refresh\"):\n",
        "        \"\"\"Upload data to Qdrant\"\"\"\n",
        "\n",
        "        if mode == \"refresh\":\n",
        "            print(\"üóëÔ∏è Deleting old collection...\")\n",
        "            try:\n",
        "                self.client.delete_collection(self.collection_name)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            print(\"üì¶ Creating fresh collection...\")\n",
        "            self.client.create_collection(\n",
        "                collection_name=self.collection_name,\n",
        "                vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
        "            )\n",
        "            start_id = 0\n",
        "        else:  # mode == \"add\"\n",
        "            collection_info = self.client.get_collection(self.collection_name)\n",
        "            start_id = collection_info.points_count\n",
        "            print(f\"üìä Adding to existing data, starting from ID: {start_id}\")\n",
        "\n",
        "        print(f\"‚è≥ Uploading {len(embeddings)} vectors to Qdrant...\")\n",
        "\n",
        "        batch_size = 100\n",
        "        for i in tqdm(range(0, len(embeddings), batch_size), desc=\"Uploading\"):\n",
        "            batch_end = min(i + batch_size, len(embeddings))\n",
        "\n",
        "            points = []\n",
        "            for idx in range(i, batch_end):\n",
        "                points.append(PointStruct(\n",
        "                    id=start_id + idx,\n",
        "                    vector=embeddings[idx].tolist(),\n",
        "                    payload=chunks[idx]\n",
        "                ))\n",
        "\n",
        "            self.client.upsert(\n",
        "                collection_name=self.collection_name,\n",
        "                points=points\n",
        "            )\n",
        "\n",
        "        # Verify\n",
        "        final_count = self.client.get_collection(self.collection_name).points_count\n",
        "        print(f\"‚úÖ Upload complete! Total vectors in Qdrant: {final_count:,}\")\n",
        "\n",
        "    def run_pipeline_from_drive(self, drive_base_path, csv_names, mode=\"refresh\"):\n",
        "        \"\"\"Complete pipeline: Drive CSVs ‚Üí Qdrant\"\"\"\n",
        "        print(\"\\nüöÄ Starting Qdrant Update Pipeline from Drive\\n\")\n",
        "\n",
        "        # Step 1: Load and filter CSVs\n",
        "        df_clean = self.load_and_filter_csvs(drive_base_path, csv_names)\n",
        "\n",
        "        # Step 2: Create chunks\n",
        "        chunks = self.create_chunks(df_clean)\n",
        "\n",
        "        # Step 3: Generate embeddings\n",
        "        embeddings = self.generate_embeddings(chunks)\n",
        "\n",
        "        # Step 4: Upload to Qdrant\n",
        "        self.upload_to_qdrant(embeddings, chunks, mode=mode)\n",
        "\n",
        "        print(\"\\n‚úÖ Pipeline complete! Your app will now use the updated data.\")\n",
        "\n",
        "\n",
        "# Usage Example\n",
        "if __name__ == \"__main__\":\n",
        "    import getpass\n",
        "\n",
        "    # Configuration\n",
        "    DRIVE_BASE = \"/content/drive/.shortcut-targets-by-id/1-SiVJhXHTHtDYSrPmW_0VfuP7gSTePcj/data\"\n",
        "\n",
        "    CSV_FILES = [\n",
        "        \"clinical_trials_diabetes_full.csv\",\n",
        "        \"clinical_trials_cancer_full.csv\",\n",
        "        \"clinical_trials_alzheimer_full.csv\",\n",
        "        \"clinical_trials_asthma_full.csv\",\n",
        "        \"clinical_trials_cardiovascular_full.csv\"\n",
        "    ]\n",
        "\n",
        "    QDRANT_URL = \"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\"\n",
        "\n",
        "    # Get API key\n",
        "    qdrant_key = getpass.getpass(\"üîë Enter Qdrant API Key: \")\n",
        "\n",
        "    # Run pipeline\n",
        "    pipeline = QdrantDataPipeline(QDRANT_URL, qdrant_key)\n",
        "    pipeline.run_pipeline_from_drive(\n",
        "        drive_base_path=DRIVE_BASE,\n",
        "        csv_names=CSV_FILES,\n",
        "        mode=\"refresh\"  # Change to \"add\" to append instead of replace\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv4FcQnIhZDz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQpdvAiNITvP"
      },
      "source": [
        "Update Code to Use Qdrant Instead of FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzgNJNuFCTNh",
        "outputId": "5e77b451-9fe8-41a1-dbb2-8c03da187430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting utils_qdrant.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils_qdrant.py\n",
        "import json\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "from qdrant_client import QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# --- Confidence score from distance ---\n",
        "\n",
        "def calculate_confidence_score(distance: float, normalization_factor: float = 1.0) -> float:\n",
        "    \"\"\"Inverse L2 distance score in (0,1]; closer = higher confidence.\"\"\"\n",
        "    return normalization_factor / (normalization_factor + float(distance))\n",
        "\n",
        "\n",
        "# --- Load Qdrant client + embedding model ---\n",
        "\n",
        "def load_qdrant_and_model(qdrant_url: str, qdrant_api_key: str):\n",
        "    \"\"\"Loads Qdrant client and embedding model.\"\"\"\n",
        "    print(\"‚è≥ Connecting to Qdrant...\")\n",
        "\n",
        "    client = QdrantClient(url=qdrant_url, api_key=qdrant_api_key)\n",
        "\n",
        "    # Verify connection\n",
        "    collection_info = client.get_collection(\"clinical_trials\")\n",
        "    print(f\"‚úÖ Connected to Qdrant: {collection_info.points_count:,} vectors ready\")\n",
        "\n",
        "    # Load embedding model (same as before)\n",
        "    embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    print(\"‚úÖ Embedding model loaded\")\n",
        "\n",
        "    return client, embed_model\n",
        "\n",
        "\n",
        "# --- Provenance logging (unchanged) ---\n",
        "\n",
        "def log_provenance_step(agent_name: str, input_data, output_data, detail=None):\n",
        "    \"\"\"Creates a detailed log entry for a single agent step.\"\"\"\n",
        "    log_entry = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"agent\": agent_name,\n",
        "        \"input\": input_data,\n",
        "        \"output\": output_data,\n",
        "        \"detail\": detail or {},\n",
        "        \"model_version\": \"gemini-2.0-flash\",\n",
        "    }\n",
        "    return log_entry\n",
        "\n",
        "\n",
        "# --- Reproducibility hash (unchanged) ---\n",
        "\n",
        "def generate_reproducibility_hash(conversation_history, corpus_version: str = \"v1.0\"):\n",
        "    \"\"\"Generates a deterministic session hash based on conversation history.\"\"\"\n",
        "    queries = [turn.get(\"query\", \"\") for turn in conversation_history]\n",
        "    raw = f\"{corpus_version}|{'|'.join(queries)}\"\n",
        "    return hashlib.md5(raw.encode(\"utf-8\")).hexdigest()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM4rCpCCJQVJ",
        "outputId": "19534de5-d8fb-43af-a5dd-bbf4e9b4b61d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîë Qdrant API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Available search methods:\n",
            "['_resolve_query', '_resolve_query_batch_request', '_resolve_query_request', '_scored_points_to_query_responses', 'query', 'query_batch', 'query_batch_points', 'query_points', 'query_points_groups', 'search_matrix_offsets', 'search_matrix_pairs']\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "from qdrant_client import QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Get API key\n",
        "qdrant_api_key = getpass.getpass(\"üîë Qdrant API Key: \")\n",
        "\n",
        "# Connect\n",
        "qdrant_client = QdrantClient(\n",
        "    url=\"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\",\n",
        "    api_key=qdrant_api_key\n",
        ")\n",
        "\n",
        "# Check what methods are available\n",
        "print(\"Available search methods:\")\n",
        "print([m for m in dir(qdrant_client) if 'search' in m.lower() or 'query' in m.lower()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGBG0m7XIcUi",
        "outputId": "3c334e5b-879f-4517-e117-9c1f06267380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîë Qdrant API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Test Query: 'diabetes insulin therapy trials'\n",
            "\n",
            "üìä Top 3 Results:\n",
            "\n",
            "1. NCT ID: NCT00151697\n",
            "   Score: 0.752\n",
            "   Title: LANN-study: Lantus, Amaryl, Novorapid, Novomix Study...\n",
            "\n",
            "2. NCT ID: NCT00151697\n",
            "   Score: 0.752\n",
            "   Title: LANN-study: Lantus, Amaryl, Novorapid, Novomix Study...\n",
            "\n",
            "3. NCT ID: NCT02192424\n",
            "   Score: 0.697\n",
            "   Title: Early Intermittent Intensive Insulin Therapy as an Effective Treatment of Type 2...\n",
            "\n",
            "‚úÖ Qdrant search working!\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "from qdrant_client import QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Get API key\n",
        "qdrant_api_key = getpass.getpass(\"üîë Qdrant API Key: \")\n",
        "\n",
        "# Connect\n",
        "qdrant_client = QdrantClient(\n",
        "    url=\"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\",\n",
        "    api_key=qdrant_api_key\n",
        ")\n",
        "\n",
        "# Load model\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Test search\n",
        "test_query = \"diabetes insulin therapy trials\"\n",
        "q_emb = embed_model.encode([test_query])[0]\n",
        "\n",
        "# Use query_points (correct method)\n",
        "results = qdrant_client.query_points(\n",
        "    collection_name=\"clinical_trials\",\n",
        "    query=q_emb.tolist(),\n",
        "    limit=3\n",
        ")\n",
        "\n",
        "print(f\"\\nüîç Test Query: '{test_query}'\")\n",
        "print(f\"\\nüìä Top 3 Results:\\n\")\n",
        "\n",
        "for i, point in enumerate(results.points, 1):\n",
        "    print(f\"{i}. NCT ID: {point.payload['nct_id']}\")\n",
        "    print(f\"   Score: {point.score:.3f}\")\n",
        "    print(f\"   Title: {point.payload['title'][:80]}...\")\n",
        "    print()\n",
        "\n",
        "print(\"‚úÖ Qdrant search working!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wbqFEilJxIZ"
      },
      "source": [
        "Fix RetrievalAgent to Use query_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIjl0L_BIcZu",
        "outputId": "783d82a3-34d5-47d4-a4fb-0e0f7641188e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting retrieval_agent_qdrant.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile retrieval_agent_qdrant.py\n",
        "import numpy as np\n",
        "from typing import Dict, Any\n",
        "from qdrant_client import QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Import scoring from your existing code\n",
        "from utils_qdrant import calculate_confidence_score, log_provenance_step\n",
        "\n",
        "# Try to import reranker\n",
        "CrossEncoder = None\n",
        "try:\n",
        "    from sentence_transformers import CrossEncoder\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "\n",
        "class RetrievalAgentQdrant:\n",
        "    \"\"\"Retrieval agent using Qdrant instead of FAISS.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        qdrant_client: QdrantClient,\n",
        "        embed_model: SentenceTransformer,\n",
        "        evidence_scorer,\n",
        "        profile_agent=None\n",
        "    ):\n",
        "        self.client = qdrant_client\n",
        "        self.embed_model = embed_model\n",
        "        self.evidence_scorer = evidence_scorer\n",
        "        self.profile_agent = profile_agent\n",
        "\n",
        "        # Optional: Load reranker\n",
        "        self.reranker = None\n",
        "        if CrossEncoder:\n",
        "            try:\n",
        "                print(\"‚è≥ Loading Cross-Encoder reranker...\")\n",
        "                self.reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "                print(\"‚úÖ Reranker loaded\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Reranker failed to load: {e}\")\n",
        "\n",
        "    def retrieve(self, parsed: Dict[str, Any], top_k: int = 5):\n",
        "        \"\"\"Retrieve trials from Qdrant.\"\"\"\n",
        "        FETCH_K = top_k * 3\n",
        "\n",
        "        symptoms = parsed.get(\"symptoms\") or []\n",
        "        context = parsed.get(\"context\") or \"\"\n",
        "        query = parsed.get(\"user_question\") or (\" \".join(symptoms) + \" \" + context).strip()\n",
        "\n",
        "        if not query:\n",
        "            retrieval = {\"query\": \"\", \"trials\": [], \"avg_confidence\": 0.0}\n",
        "            log = log_provenance_step(\"RetrievalAgentQdrant\", parsed, retrieval, {\"reason\": \"empty_query\"})\n",
        "            return retrieval, log\n",
        "\n",
        "        # Query expansion (same as before)\n",
        "        EXPANSIONS = {\n",
        "            \"insulin\": \"insulin OR insulin therapy OR insulin treatment OR insulin pump\",\n",
        "            \"medication\": \"medication OR drug OR pharmaceutical OR pharmacological OR treatment\",\n",
        "            \"diet\": \"diet OR dietary OR nutrition OR nutritional OR eating\",\n",
        "            \"exercise\": \"exercise OR physical activity OR fitness OR activity\",\n",
        "            \"chemo\": \"chemotherapy OR antineoplastic OR oncology\",\n",
        "            \"cancer\": \"cancer OR tumor OR tumour OR malignancy OR oncology\",\n",
        "            \"alzheim\": \"alzheimer OR dementia OR cognitive decline OR memory loss\",\n",
        "        }\n",
        "\n",
        "        query_lower = query.lower()\n",
        "        for term, expansion in EXPANSIONS.items():\n",
        "            if term in query_lower:\n",
        "                query = f\"{query} {expansion}\"\n",
        "                break\n",
        "\n",
        "        # 1. Generate query embedding\n",
        "        q_emb = self.embed_model.encode([query])[0]\n",
        "\n",
        "        # 2. Search Qdrant (FIXED: use query_points)\n",
        "        search_results = self.client.query_points(\n",
        "            collection_name=\"clinical_trials\",\n",
        "            query=q_emb.tolist(),\n",
        "            limit=FETCH_K\n",
        "        )\n",
        "\n",
        "        # 3. Convert to candidate format\n",
        "        initial_candidates = []\n",
        "        for point in search_results.points:\n",
        "            initial_candidates.append({\n",
        "                \"nct_id\": point.payload[\"nct_id\"],\n",
        "                \"title\": point.payload.get(\"title\", \"\"),\n",
        "                \"text\": point.payload[\"text\"],\n",
        "                \"status\": point.payload.get(\"status\", \"Unknown Status\"),\n",
        "                \"qdrant_score\": point.score,  # Cosine similarity (higher = better)\n",
        "            })\n",
        "\n",
        "        final_trials = []\n",
        "\n",
        "        # 4. Optional CrossEncoder reranking\n",
        "        if self.reranker and initial_candidates:\n",
        "            pairs = [[query, cand[\"text\"]] for cand in initial_candidates]\n",
        "            scores = self.reranker.predict(pairs)\n",
        "\n",
        "            for i, cand in enumerate(initial_candidates):\n",
        "                cand[\"rerank_score\"] = float(scores[i])\n",
        "\n",
        "            initial_candidates.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                logit = item[\"rerank_score\"]\n",
        "                base_conf = 1 / (1 + np.exp(-logit))\n",
        "\n",
        "                scoring_result = self.evidence_scorer.calculate_weighted_score(\n",
        "                    trial=item,\n",
        "                    base_confidence=base_conf,\n",
        "                    query=query,\n",
        "                )\n",
        "\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"title\"],\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": base_conf,\n",
        "                    \"weighted_score\": scoring_result[\"weighted_score\"],\n",
        "                    \"score_breakdown\": scoring_result[\"breakdown\"],\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"qdrant_evidence_weighted\",\n",
        "                })\n",
        "        else:\n",
        "            # Qdrant-only path (no reranking)\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                # Qdrant uses cosine similarity (0-1, higher = better)\n",
        "                base_conf = item[\"qdrant_score\"]\n",
        "\n",
        "                scoring_result = self.evidence_scorer.calculate_weighted_score(\n",
        "                    trial=item,\n",
        "                    base_confidence=base_conf,\n",
        "                    query=query,\n",
        "                )\n",
        "\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"title\"],\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": base_conf,\n",
        "                    \"weighted_score\": scoring_result[\"weighted_score\"],\n",
        "                    \"score_breakdown\": scoring_result[\"breakdown\"],\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"qdrant_evidence_weighted\",\n",
        "                })\n",
        "\n",
        "        # Sort by weighted score\n",
        "        final_trials.sort(key=lambda x: x[\"weighted_score\"], reverse=True)\n",
        "        for i, trial in enumerate(final_trials):\n",
        "            trial[\"rank\"] = i + 1\n",
        "\n",
        "        confs = [t[\"weighted_score\"] for t in final_trials]\n",
        "        avg_conf = float(np.mean(confs)) if confs else 0.0\n",
        "\n",
        "        retrieval = {\n",
        "            \"query\": query,\n",
        "            \"trials\": final_trials,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "        }\n",
        "\n",
        "        detail = {\n",
        "            \"top_k\": top_k,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"num_trials\": len(final_trials),\n",
        "            \"method\": \"qdrant_reranked\" if self.reranker else \"qdrant_only\",\n",
        "        }\n",
        "\n",
        "        log = log_provenance_step(\"RetrievalAgentQdrant\", parsed, retrieval, detail)\n",
        "        return retrieval, log\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXknHDeuKZMY"
      },
      "source": [
        "Update Main Bot Code to Use Qdrant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pxoihznCTRf",
        "outputId": "99548a5f-ae31-449f-c497-2a48a8d990af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting run_bot_qdrant.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile run_bot_qdrant.py\n",
        "\"\"\"\n",
        "Updated HealthcareBot using Qdrant instead of FAISS\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "from typing import List, Dict, Any\n",
        "import numpy as np\n",
        "import requests\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "\n",
        "# Import utilities\n",
        "from utils_qdrant import (\n",
        "    load_qdrant_and_model,\n",
        "    log_provenance_step,\n",
        "    generate_reproducibility_hash,\n",
        ")\n",
        "\n",
        "from retrieval_agent_qdrant import RetrievalAgentQdrant\n",
        "\n",
        "# CrossEncoder\n",
        "CrossEncoder = None\n",
        "try:\n",
        "    from sentence_transformers import CrossEncoder\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PARSER\n",
        "# ============================================================\n",
        "class SymptomParser:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def parse(self, text: str):\n",
        "        \"\"\"\n",
        "        Enhanced parser for clinical trial search queries.\n",
        "        Decides:\n",
        "        - Are they searching for trials or just asking a question?\n",
        "        - Which disease (diabetes, cancer, Alzheimer‚Äôs, asthma, cardiovascular) is implied?\n",
        "        \"\"\"\n",
        "        prompt = (\n",
        "            \"You are a clinical trial search classifier for medical research.\\n\"\n",
        "            \"You support conditions including diabetes, cancer, Alzheimer's disease, asthma, and cardiovascular disease.\\n\\n\"\n",
        "            f\"User Input: \\\"{text}\\\"\\n\\n\"\n",
        "            \"Your tasks:\\n\"\n",
        "            \"1) Decide if the user is searching for clinical trials or just asking a general question.\\n\"\n",
        "            \"2) Detect which disease(s) they are talking about.\\n\"\n",
        "            \"3) Detect if the query is not about health or clinical trials (off_topic).\\n\\n\"\n",
        "            \"Classification Rules:\\n\"\n",
        "            \"- If the query mentions or implies trials, studies, research, clinical experiments, etc. ‚Üí intent='trial_search'\\n\"\n",
        "            \"- If the user is mainly describing themselves (age, diagnosis, comorbidities, meds) ‚Üí intent='profile_info'\\n\"\n",
        "            \"- If they ask 'what is X', 'how does Y work', etc. without asking about trials ‚Üí intent='general_question'\\n\"\n",
        "            \"- Simple greetings (hi, hello, hey) ‚Üí intent='greeting'\\n\"\n",
        "            \"- If clearly not about health or clinical research ‚Üí intent='off_topic', is_disease_related=false\\n\\n\"\n",
        "            \"You must detect disease_focus whenever possible:\\n\"\n",
        "            \"- diabetes: diabetes, blood sugar, glucose, insulin, HbA1c, metformin, GLP-1, SGLT2\\n\"\n",
        "            \"- cancer: cancer, tumor/tumour, chemotherapy, oncology, breast cancer, lung cancer, leukemia, lymphoma\\n\"\n",
        "            \"- alzheimers: Alzheimer's, dementia, memory loss, cognitive decline\\n\"\n",
        "            \"- asthma: asthma, wheezing, bronchodilator, inhaler\\n\"\n",
        "            \"- cardiovascular: heart failure, cardiovascular disease, hypertension, high blood pressure, angina,\\n\"\n",
        "            \"  myocardial infarction, coronary artery disease, stroke\\n\\n\"\n",
        "            \"Return ONLY valid JSON with this exact format:\\n\"\n",
        "            \"{\\n\"\n",
        "            \"  \\\"intent\\\": \\\"trial_search\\\" | \\\"profile_info\\\" | \\\"general_question\\\" | \\\"greeting\\\" | \\\"off_topic\\\",\\n\"\n",
        "            \"  \\\"query_type\\\": \\\"trial_query\\\" | \\\"profile_statement\\\" | \\\"knowledge_seeking\\\" | \\\"greeting\\\",\\n\"\n",
        "            \"  \\\"search_keywords\\\": [\\\"keyword1\\\", \\\"keyword2\\\"],\\n\"\n",
        "            \"  \\\"is_disease_related\\\": true or false,\\n\"\n",
        "            \"  \\\"disease_focus\\\": [\\\"diabetes\\\", \\\"cancer\\\", \\\"alzheimers\\\", \\\"asthma\\\", \\\"cardiovascular\\\"],\\n\"\n",
        "            \"  \\\"user_question\\\": \\\"the question in plain English\\\",\\n\"\n",
        "            \"  \\\"trial_interest\\\": \\\"what type of trial they want (diet, medication, technology, surgery, etc.)\\\"\\n\"\n",
        "            \"}\\n\\n\"\n",
        "            \"Examples:\\n\"\n",
        "            \"- 'What trials study liraglutide in diabetes?' ‚Üí intent='trial_search', query_type='trial_query',\\n\"\n",
        "            \"  is_disease_related=true, disease_focus=['diabetes'], search_keywords=['liraglutide']\\n\"\n",
        "            \"- 'My mom has breast cancer, are there trials?' ‚Üí intent='trial_search', disease_focus=['cancer']\\n\"\n",
        "            \"- 'I am 70 with memory loss and Alzheimer's' ‚Üí intent='profile_info', disease_focus=['alzheimers']\\n\"\n",
        "            \"- 'What is HbA1c?' ‚Üí intent='general_question', disease_focus=['diabetes']\\n\"\n",
        "            \"- 'What is the weather in Paris?' ‚Üí intent='off_topic', is_disease_related=false, disease_focus=[]\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            raw = (res.text or \"\").strip()\n",
        "            match = re.search(r\"\\{.*\\}\", raw, re.DOTALL)\n",
        "            if match:\n",
        "                parsed = json.loads(match.group(0))\n",
        "            else:\n",
        "                parsed = json.loads(raw)\n",
        "        except Exception:\n",
        "            # Fallback: simple heuristic if model fails\n",
        "            text_lower = text.lower()\n",
        "            disease_focus = []\n",
        "            if any(x in text_lower for x in [\"diabetes\", \"insulin\", \"glucose\", \"hba1c\", \"metformin\", \"glp-1\", \"sglt2\"]):\n",
        "                disease_focus.append(\"diabetes\")\n",
        "            if any(x in text_lower for x in [\"cancer\", \"tumor\", \"tumour\", \"chemo\", \"chemotherapy\", \"oncology\"]):\n",
        "                disease_focus.append(\"cancer\")\n",
        "            if any(x in text_lower for x in [\"alzheimer\", \"dementia\", \"memory loss\", \"cognitive decline\"]):\n",
        "                disease_focus.append(\"alzheimers\")\n",
        "            if \"asthma\" in text_lower or \"wheezing\" in text_lower:\n",
        "                disease_focus.append(\"asthma\")\n",
        "            if any(x in text_lower for x in [\"heart failure\", \"cardiovascular\", \"hypertension\",\n",
        "                                             \"high blood pressure\", \"angina\", \"myocardial\", \"coronary\", \"stroke\"]):\n",
        "                disease_focus.append(\"cardiovascular\")\n",
        "\n",
        "            if any(kw in text_lower for kw in [\"trial\", \"study\", \"research\", \"clinical\"]):\n",
        "                intent = \"trial_search\"\n",
        "                query_type = \"trial_query\"\n",
        "            elif any(kw in text_lower for kw in [\"hi\", \"hello\", \"hey\"]):\n",
        "                intent = \"greeting\"\n",
        "                query_type = \"greeting\"\n",
        "            else:\n",
        "                intent = \"general_question\"\n",
        "                query_type = \"knowledge_seeking\"\n",
        "\n",
        "            parsed = {\n",
        "                \"intent\": intent,\n",
        "                \"query_type\": query_type,\n",
        "                \"search_keywords\": [text] if intent == \"trial_search\" else [],\n",
        "                \"is_disease_related\": bool(disease_focus),\n",
        "                \"disease_focus\": disease_focus,\n",
        "                \"user_question\": text,\n",
        "                \"trial_interest\": \"general\",\n",
        "            }\n",
        "\n",
        "        # --- Heuristic correction layer on top of model output ---\n",
        "        text_lower = text.lower()\n",
        "        diseases = set(parsed.get(\"disease_focus\") or [])\n",
        "\n",
        "        if any(x in text_lower for x in [\"diabetes\", \"insulin\", \"glucose\", \"hba1c\", \"metformin\", \"glp-1\", \"sglt2\"]):\n",
        "            diseases.add(\"diabetes\")\n",
        "        if any(x in text_lower for x in [\"cancer\", \"tumor\", \"tumour\", \"chemo\", \"chemotherapy\", \"oncology\"]):\n",
        "            diseases.add(\"cancer\")\n",
        "        if any(x in text_lower for x in [\"alzheimer\", \"alzheimers\", \"dementia\", \"memory loss\", \"cognitive decline\"]):\n",
        "            diseases.add(\"alzheimers\")\n",
        "        if \"asthma\" in text_lower or \"wheezing\" in text_lower or \"inhaler\" in text_lower:\n",
        "            diseases.add(\"asthma\")\n",
        "        if any(x in text_lower for x in [\"heart failure\", \"cardiovascular\", \"hypertension\",\n",
        "                                         \"high blood pressure\", \"angina\", \"myocardial\", \"coronary\", \"stroke\"]):\n",
        "            diseases.add(\"cardiovascular\")\n",
        "\n",
        "        parsed[\"disease_focus\"] = list(diseases)\n",
        "\n",
        "        # Force trial_search if obvious trial keywords\n",
        "        trial_keywords = [\n",
        "            \"trial\", \"study\", \"studies\", \"research\",\n",
        "            \"clinical\", \"show me\", \"are there\", \"what trials\"\n",
        "        ]\n",
        "        if any(kw in text_lower for kw in trial_keywords):\n",
        "            parsed[\"intent\"] = \"trial_search\"\n",
        "            parsed[\"query_type\"] = \"trial_query\"\n",
        "\n",
        "        # If we detected diseases, ensure is_disease_related = True\n",
        "        if diseases and parsed.get(\"intent\") != \"off_topic\":\n",
        "            parsed[\"is_disease_related\"] = True\n",
        "        elif \"is_disease_related\" not in parsed:\n",
        "            parsed[\"is_disease_related\"] = bool(diseases)\n",
        "\n",
        "        log = log_provenance_step(\"SymptomParser\", text, parsed)\n",
        "        return parsed, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PROFILE AGENT\n",
        "# ============================================================\n",
        "class ProfileAgent:\n",
        "    def __init__(self, initial_profile: Dict[str, Any] = None):\n",
        "        if initial_profile is None:\n",
        "            initial_profile = {\n",
        "                \"user_id\": \"Patient\",\n",
        "                \"conditions\": [],          # could be filled later\n",
        "                \"extracted_conditions\": [],  # dynamic memory\n",
        "                \"history\": [],\n",
        "            }\n",
        "        self.profile = initial_profile\n",
        "\n",
        "    def update_profile(self, turn_data: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Updates history and extracts persistent medical entities.\n",
        "        \"\"\"\n",
        "        self.profile.setdefault(\"history\", []).append(turn_data)\n",
        "        self.profile.setdefault(\"extracted_conditions\", [])\n",
        "\n",
        "        parsed = turn_data.get(\"parsed\", {})\n",
        "        # optional: keep disease_focus as conditions\n",
        "        diseases = parsed.get(\"disease_focus\") or []\n",
        "        if diseases:\n",
        "            current = set(self.profile[\"extracted_conditions\"])\n",
        "            for d in diseases:\n",
        "                current.add(d)\n",
        "            self.profile[\"extracted_conditions\"] = list(current)\n",
        "\n",
        "        snapshot = {\n",
        "            \"user_id\": self.profile.get(\"user_id\", \"Patient\"),\n",
        "            \"known_conditions\": self.profile.get(\"extracted_conditions\", []),\n",
        "            \"num_turns\": len(self.profile[\"history\"]),\n",
        "        }\n",
        "        log = log_provenance_step(\"ProfileAgent\", turn_data, {\"profile_snapshot\": snapshot})\n",
        "        return log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# EVIDENCE-WEIGHTED SCORER\n",
        "# ============================================================\n",
        "class EvidenceWeightedScorer:\n",
        "    \"\"\"\n",
        "    Implements evidence-weighted scoring for clinical trials.\n",
        "    Ranks trials based on multiple quality factors beyond semantic similarity.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.status_weights = {\n",
        "            \"Completed\": 1.0,\n",
        "            \"Active, Not Recruiting\": 0.9,\n",
        "            \"Recruiting\": 0.85,\n",
        "            \"Enrolling By Invitation\": 0.8,\n",
        "            \"Not Yet Recruiting\": 0.6,\n",
        "            \"Terminated\": 0.4,\n",
        "            \"Withdrawn\": 0.3,\n",
        "            \"Suspended\": 0.3,\n",
        "            \"Unknown Status\": 0.5,\n",
        "        }\n",
        "\n",
        "        self.design_keywords = {\n",
        "            \"randomized controlled\": 1.0,\n",
        "            \"double-blind\": 0.95,\n",
        "            \"randomized\": 0.9,\n",
        "            \"controlled\": 0.85,\n",
        "            \"interventional\": 0.8,\n",
        "            \"prospective\": 0.75,\n",
        "            \"observational\": 0.6,\n",
        "            \"retrospective\": 0.5,\n",
        "        }\n",
        "\n",
        "    def calculate_weighted_score(\n",
        "        self,\n",
        "        trial: Dict[str, Any],\n",
        "        base_confidence: float,\n",
        "        query: str,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Calculate evidence-weighted score for a trial.\n",
        "        \"\"\"\n",
        "\n",
        "        # Factor 1: Base semantic match (35%)\n",
        "        match_score = base_confidence * 0.35\n",
        "\n",
        "        # Factor 2: Trial status quality (25%)\n",
        "        status = str(trial.get(\"status\", \"Unknown Status\")).strip().title()\n",
        "        status_score = self.status_weights.get(status, 0.5) * 0.25\n",
        "\n",
        "        # Factor 3: Study design quality (20%)\n",
        "        design_score = self._calculate_design_quality(trial) * 0.20\n",
        "\n",
        "        # Factor 4: Keyword density (10%)\n",
        "        keyword_score = self._calculate_keyword_density(trial, query) * 0.10\n",
        "\n",
        "        # Factor 5: Metadata completeness (10%)\n",
        "        completeness_score = self._calculate_completeness(trial) * 0.10\n",
        "\n",
        "        weighted_score = (\n",
        "            match_score +\n",
        "            status_score +\n",
        "            design_score +\n",
        "            keyword_score +\n",
        "            completeness_score\n",
        "        )\n",
        "\n",
        "        breakdown = {\n",
        "            \"base_confidence\": base_confidence,\n",
        "            \"weighted_score\": weighted_score,\n",
        "            \"factors\": {\n",
        "                \"semantic_match\": match_score,\n",
        "                \"trial_status\": status_score,\n",
        "                \"study_design\": design_score,\n",
        "                \"keyword_density\": keyword_score,\n",
        "                \"completeness\": completeness_score,\n",
        "            },\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"weighted_score\": min(weighted_score, 1.0),\n",
        "            \"breakdown\": breakdown,\n",
        "        }\n",
        "\n",
        "    def _calculate_design_quality(self, trial: Dict[str, Any]) -> float:\n",
        "        text = f\"{trial.get('title', '')} {trial.get('text', '')}\".lower()\n",
        "        max_score = 0.0\n",
        "        for keyword, weight in self.design_keywords.items():\n",
        "            if keyword in text:\n",
        "                max_score = max(max_score, weight)\n",
        "        return max_score if max_score > 0 else 0.6\n",
        "\n",
        "    def _calculate_keyword_density(self, trial: Dict[str, Any], query: str) -> float:\n",
        "        text = f\"{trial.get('title', '')} {trial.get('text', '')}\".lower()\n",
        "        stopwords = {\n",
        "            \"the\", \"a\", \"an\", \"and\", \"or\", \"for\", \"with\", \"in\", \"on\", \"at\", \"to\",\n",
        "            \"of\", \"is\", \"are\", \"what\", \"trials\", \"trial\", \"study\", \"studies\", \"clinical\"\n",
        "        }\n",
        "        query_terms = [\n",
        "            term for term in query.lower().split()\n",
        "            if term not in stopwords and len(term) > 2\n",
        "        ]\n",
        "        if not query_terms:\n",
        "            return 0.5\n",
        "        matches = sum(1 for term in query_terms if term in text)\n",
        "        density = matches / len(query_terms)\n",
        "        return min(density, 1.0)\n",
        "\n",
        "    def _calculate_completeness(self, trial: Dict[str, Any]) -> float:\n",
        "        # Our chunk_map has \"title\" and \"text\"; treat longer text as more complete\n",
        "        text = trial.get(\"text\", \"\") or \"\"\n",
        "        title = trial.get(\"title\", \"\") or \"\"\n",
        "        score = 0.0\n",
        "        if len(title) > 10:\n",
        "            score += 0.3\n",
        "        if len(text) > 200:\n",
        "            score += 0.7\n",
        "        return min(score, 1.0)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PubMed Helper (NCT ‚Üí PubMed abstract)\n",
        "# ============================================================\n",
        "def fetch_pubmed_abstract_for_nct(nct_id: str):\n",
        "    \"\"\"\n",
        "    Try to find a PubMed article linked to this NCT ID and return its abstract.\n",
        "    Returns: {\"pmid\": str, \"abstract\": str} or None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        esearch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "        params = {\n",
        "            \"db\": \"pubmed\",\n",
        "            \"term\": f\"{nct_id}[si]\",\n",
        "            \"retmode\": \"json\",\n",
        "            \"retmax\": 1,\n",
        "        }\n",
        "        r = requests.get(esearch_url, params=params, timeout=10)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        idlist = data.get(\"esearchresult\", {}).get(\"idlist\", [])\n",
        "        if not idlist:\n",
        "            return None\n",
        "\n",
        "        pmid = idlist[0]\n",
        "\n",
        "        efetch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "        params = {\n",
        "            \"db\": \"pubmed\",\n",
        "            \"id\": pmid,\n",
        "            \"rettype\": \"abstract\",\n",
        "            \"retmode\": \"text\",\n",
        "        }\n",
        "        r2 = requests.get(efetch_url, params=params, timeout=10)\n",
        "        r2.raise_for_status()\n",
        "        abstract_text = r2.text.strip()\n",
        "        if not abstract_text:\n",
        "            return None\n",
        "\n",
        "        return {\"pmid\": pmid, \"abstract\": abstract_text}\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# RETRIEVAL AGENT\n",
        "# ============================================================\n",
        "class RetrievalAgent:\n",
        "    def __init__(self, embed_model, faiss_index, chunk_map, profile_agent: ProfileAgent = None):\n",
        "        self.embed_model = embed_model\n",
        "        self.index = faiss_index\n",
        "        self.chunk_map = chunk_map\n",
        "        self.profile_agent = profile_agent\n",
        "        self.evidence_scorer = EvidenceWeightedScorer()\n",
        "\n",
        "    def retrieve(self, parsed: Dict[str, Any], top_k: int = 5):\n",
        "        FETCH_K = top_k * 3\n",
        "\n",
        "        symptoms = parsed.get(\"symptoms\") or []\n",
        "        context = parsed.get(\"context\") or \"\"\n",
        "        query = parsed.get(\"user_question\") or (\" \".join(symptoms) + \" \" + context).strip()\n",
        "\n",
        "        if not query:\n",
        "            retrieval = {\"query\": \"\", \"trials\": [], \"avg_confidence\": 0.0}\n",
        "            log = log_provenance_step(\"RetrievalAgent\", parsed, retrieval, {\"reason\": \"empty_query\"})\n",
        "            return retrieval, log\n",
        "\n",
        "        # Simple expansions (still useful across diseases)\n",
        "        EXPANSIONS = {\n",
        "            \"insulin\": \"insulin OR insulin therapy OR insulin treatment OR insulin pump\",\n",
        "            \"medication\": \"medication OR drug OR pharmaceutical OR pharmacological OR treatment\",\n",
        "            \"diet\": \"diet OR dietary OR nutrition OR nutritional OR eating\",\n",
        "            \"exercise\": \"exercise OR physical activity OR fitness OR activity\",\n",
        "            \"chemo\": \"chemotherapy OR antineoplastic OR oncology\",\n",
        "            \"cancer\": \"cancer OR tumor OR tumour OR malignancy OR oncology\",\n",
        "            \"alzheim\": \"alzheimer OR dementia OR cognitive decline OR memory loss\",\n",
        "        }\n",
        "\n",
        "        query_lower = query.lower()\n",
        "        for term, expansion in EXPANSIONS.items():\n",
        "            if term in query_lower:\n",
        "                query = f\"{query} {expansion}\"\n",
        "                break\n",
        "\n",
        "        # 1. FAISS retrieval\n",
        "        q_emb = self.embed_model.encode([query])\n",
        "        distances, indices = self.index.search(q_emb.astype(\"float32\"), FETCH_K)\n",
        "\n",
        "        initial_candidates = []\n",
        "        for rank, idx in enumerate(indices[0]):\n",
        "            if idx == -1:\n",
        "                continue\n",
        "            item = self.chunk_map[idx]\n",
        "            dist = float(distances[0][rank])\n",
        "            initial_candidates.append({\n",
        "                \"nct_id\": item[\"nct_id\"],\n",
        "                \"title\": item.get(\"title\", \"\"),\n",
        "                \"text\": item[\"text\"],\n",
        "                \"status\": item.get(\"status\", \"Unknown Status\"),\n",
        "                \"faiss_dist\": dist,\n",
        "            })\n",
        "\n",
        "        final_trials = []\n",
        "        confs = []\n",
        "\n",
        "        # 2. Optional CrossEncoder reranking\n",
        "        if reranker and initial_candidates:\n",
        "            pairs = [[query, cand[\"text\"]] for cand in initial_candidates]\n",
        "            scores = reranker.predict(pairs)\n",
        "\n",
        "            for i, cand in enumerate(initial_candidates):\n",
        "                cand[\"rerank_score\"] = float(scores[i])\n",
        "\n",
        "            initial_candidates.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                logit = item[\"rerank_score\"]\n",
        "                base_conf = 1 / (1 + np.exp(-logit))\n",
        "\n",
        "                scoring_result = self.evidence_scorer.calculate_weighted_score(\n",
        "                    trial=item,\n",
        "                    base_confidence=base_conf,\n",
        "                    query=query,\n",
        "                )\n",
        "\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"title\"],\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": base_conf,\n",
        "                    \"weighted_score\": scoring_result[\"weighted_score\"],\n",
        "                    \"score_breakdown\": scoring_result[\"breakdown\"],\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"evidence_weighted\",\n",
        "                })\n",
        "\n",
        "            final_trials.sort(key=lambda x: x[\"weighted_score\"], reverse=True)\n",
        "            for i, trial in enumerate(final_trials):\n",
        "                trial[\"rank\"] = i + 1\n",
        "\n",
        "            confs = [t[\"weighted_score\"] for t in final_trials]\n",
        "\n",
        "        else:\n",
        "            # FAISS-only path\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                base_conf = calculate_confidence_score(item[\"faiss_dist\"])\n",
        "                scoring_result = self.evidence_scorer.calculate_weighted_score(\n",
        "                    trial=item,\n",
        "                    base_confidence=base_conf,\n",
        "                    query=query,\n",
        "                )\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"title\"],\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": base_conf,\n",
        "                    \"weighted_score\": scoring_result[\"weighted_score\"],\n",
        "                    \"score_breakdown\": scoring_result[\"breakdown\"],\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"evidence_weighted_faiss\",\n",
        "                })\n",
        "\n",
        "            final_trials.sort(key=lambda x: x[\"weighted_score\"], reverse=True)\n",
        "            for i, trial in enumerate(final_trials):\n",
        "                trial[\"rank\"] = i + 1\n",
        "\n",
        "            confs = [t[\"weighted_score\"] for t in final_trials]\n",
        "\n",
        "        avg_conf = float(np.mean(confs)) if confs else 0.0\n",
        "\n",
        "        retrieval = {\n",
        "            \"query\": query,\n",
        "            \"trials\": final_trials,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "        }\n",
        "\n",
        "        detail = {\n",
        "            \"top_k\": top_k,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"num_trials\": len(final_trials),\n",
        "            \"method\": \"reranked\" if reranker else \"faiss_only\",\n",
        "        }\n",
        "\n",
        "        log = log_provenance_step(\"RetrievalAgent\", parsed, retrieval, detail)\n",
        "        return retrieval, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# DIAGNOSIS / ADVISOR\n",
        "# ============================================================\n",
        "class DiagnosisAdvisor:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def _handle_general_question(self, parsed: Dict[str, Any], retrieved: Dict[str, Any]):\n",
        "        \"\"\"Handle general medical knowledge questions.\"\"\"\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        user_question = parsed.get(\"user_question\") or \" \".join(parsed.get(\"symptoms\", []))\n",
        "\n",
        "        evidence_parts = []\n",
        "        for t in trials[:3]:\n",
        "            evidence_parts.append(f\"Trial {t['nct_id']}: {t['text'][:400]}\")\n",
        "        evidence = \"\\n\\n\".join(evidence_parts) if evidence_parts else \"No specific trials available.\"\n",
        "\n",
        "        prompt = (\n",
        "            \"You are a medical research educator. Answer the user's question clearly using reliable medical knowledge.\\n\"\n",
        "            \"The clinical trial evidence below provides real-world context - mention it if helpful.\\n\\n\"\n",
        "            f\"USER'S QUESTION: {user_question}\\n\\n\"\n",
        "            \"CLINICAL TRIAL CONTEXT (for reference only):\\n\"\n",
        "            f\"{evidence}\\n\\n\"\n",
        "            \"Instructions:\\n\"\n",
        "            \"- Answer the question directly in 3‚Äì5 sentences.\\n\"\n",
        "            \"- Be specific and educational.\\n\"\n",
        "            \"- Do NOT give diagnoses or treatment instructions.\\n\"\n",
        "            \"- End with: 'For personalized advice, please consult your healthcare provider.'\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            text = (res.text or \"\").strip()\n",
        "            if not text or len(text) < 50:\n",
        "                text = (\n",
        "                    \"I don't have enough information to answer this question accurately. \"\n",
        "                    \"For personalized guidance, please consult your healthcare provider.\"\n",
        "                )\n",
        "            return text\n",
        "        except Exception:\n",
        "            return (\n",
        "                \"I'm unable to generate a detailed answer right now. \"\n",
        "                \"For personalized guidance, please consult your healthcare provider.\"\n",
        "            )\n",
        "\n",
        "    def _handle_symptom_query(\n",
        "        self,\n",
        "        parsed: Dict[str, Any],\n",
        "        retrieved: Dict[str, Any],\n",
        "        profile: Dict[str, Any],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Generate response for clinical trial search queries with\n",
        "        readable paragraph summaries and PubMed abstracts when available.\n",
        "        \"\"\"\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        if not trials:\n",
        "            return \"No relevant trials were found. Please try refining your query.\"\n",
        "\n",
        "        formatted_trials = []\n",
        "        for t in trials[:5]:\n",
        "            title = t.get(\"title\", \"\") or t[\"text\"].split(\"\\n\")[0].replace(\"Title: \", \"\")\n",
        "            status = t.get(\"status\", \"Unknown\")\n",
        "            weighted_score = t.get(\"weighted_score\", 0.0)\n",
        "\n",
        "            # Extract the ClinicalTrials.gov summary text\n",
        "            raw_text = t.get(\"text\", \"\")\n",
        "            brief_summary = raw_text.split(\"Summary:\", 1)[-1].strip() if \"Summary:\" in raw_text else raw_text\n",
        "\n",
        "            if brief_summary:\n",
        "                # Ask Gemini to turn the CT.gov summary into a short paragraph\n",
        "                prompt = (\n",
        "                    \"Rewrite the following clinical trial description as a short, clear paragraph \"\n",
        "                    \"about what the study is testing:\\n\\n\"\n",
        "                    f\"{brief_summary}\\n\\n\"\n",
        "                    \"Guidelines:\\n\"\n",
        "                    \"- Use 2‚Äì4 sentences.\\n\"\n",
        "                    \"- Plain English, minimal jargon.\\n\"\n",
        "                    \"- Include the purpose and the main type of participant.\\n\"\n",
        "                )\n",
        "                try:\n",
        "                    res = self.model.generate_content(prompt)\n",
        "                    brief_summary = res.text.strip() if res.text else brief_summary\n",
        "                except Exception:\n",
        "                    if len(brief_summary) > 600:\n",
        "                        brief_summary = brief_summary[:600] + \"...\"\n",
        "            else:\n",
        "                brief_summary = \"No summary available.\"\n",
        "\n",
        "            # PubMed abstract lookup\n",
        "            pubmed_block = \"\"\n",
        "            pub = fetch_pubmed_abstract_for_nct(t[\"nct_id\"])\n",
        "            if pub:\n",
        "                abs_text = pub[\"abstract\"]\n",
        "                max_len = 2000\n",
        "                if len(abs_text) > max_len:\n",
        "                    abs_text = abs_text[:max_len] + \"...\"\n",
        "                pubmed_block = (\n",
        "                    f\"  PubMed abstract (PMID {pub['pmid']}):\\n\"\n",
        "                    f\"  {abs_text}\\n\\n\"\n",
        "                    f\"  PubMed link: https://pubmed.ncbi.nlm.nih.gov/{pub['pmid']}/\\n\\n\"\n",
        "                )\n",
        "\n",
        "            formatted_trials.append(\n",
        "                f\"**{t['nct_id']}** (Relevance: {weighted_score:.0%})\\n\"\n",
        "                f\"‚Ä¢ {title}\\n\"\n",
        "                f\"  Status: {status}\\n\\n\"\n",
        "                f\"  {brief_summary}\\n\\n\"\n",
        "                f\"{pubmed_block}\"\n",
        "            )\n",
        "\n",
        "        trials_text = \"\\n\\n\".join(formatted_trials)\n",
        "        num_trials = len(formatted_trials)\n",
        "\n",
        "        response = (\n",
        "            f\"I found {num_trials} clinical trial{'s' if num_trials != 1 else ''} relevant to your request:\\n\\n\"\n",
        "            f\"{trials_text}\\n\\n\"\n",
        "            \"Summary: These trials explore potential treatments or management strategies for the condition you asked about. \"\n",
        "            \"More details are available using the listed NCT IDs.\\n\\n\"\n",
        "            \"To learn more or consider participation, visit clinicaltrials.gov and search by NCT ID. \"\n",
        "            \"Always discuss clinical trial options with your healthcare provider.\"\n",
        "        )\n",
        "\n",
        "        return response\n",
        "\n",
        "    def advise(self, parsed: Dict[str, Any], retrieved: Dict[str, Any], profile: Dict[str, Any]):\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        avg_conf = retrieved.get(\"avg_confidence\", 0.0)\n",
        "        query_type = parsed.get(\"query_type\", \"trial_query\")\n",
        "        is_disease_related = parsed.get(\"is_disease_related\", True)\n",
        "\n",
        "        draft = {\n",
        "            \"recommendation\": \"\",\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"query_type\": query_type,\n",
        "        }\n",
        "\n",
        "        if not is_disease_related:\n",
        "            draft[\"recommendation\"] = (\n",
        "                \"I‚Äôm specialized in clinical trials for medical conditions (for example diabetes, cancer, \"\n",
        "                \"Alzheimer‚Äôs disease, asthma, and cardiovascular diseases). \"\n",
        "                \"Your question does not appear to be about a health condition or clinical research. \"\n",
        "                \"If you‚Äôd like, you can ask me about trials for a specific condition.\"\n",
        "            )\n",
        "            draft[\"confidence_veto\"] = True\n",
        "            log = log_provenance_step(\n",
        "                \"DiagnosisAdvisor\",\n",
        "                parsed,\n",
        "                draft,\n",
        "                {\"veto\": True, \"reason\": \"off_topic\"},\n",
        "            )\n",
        "            return draft, log\n",
        "\n",
        "        if not trials or avg_conf < 0.05:\n",
        "            draft[\"recommendation\"] = (\n",
        "                \"Based on the trials I retrieved, I don‚Äôt have strong enough evidence to answer this question directly. \"\n",
        "                \"Please consult your healthcare provider for personalized advice.\"\n",
        "            )\n",
        "            draft[\"confidence_veto\"] = True\n",
        "            log = log_provenance_step(\n",
        "                \"DiagnosisAdvisor\",\n",
        "                parsed,\n",
        "                draft,\n",
        "                {\"veto\": True, \"reason\": \"low_confidence\"},\n",
        "            )\n",
        "            return draft, log\n",
        "\n",
        "        if query_type == \"knowledge_seeking\":\n",
        "            draft[\"recommendation\"] = self._handle_general_question(parsed, retrieved)\n",
        "        else:\n",
        "            draft[\"recommendation\"] = self._handle_symptom_query(parsed, retrieved, profile)\n",
        "\n",
        "        draft[\"confidence_veto\"] = False\n",
        "        log = log_provenance_step(\"DiagnosisAdvisor\", parsed, draft)\n",
        "        return draft, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SAFETY FILTER\n",
        "# ============================================================\n",
        "class ActiveSafetyFilter:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.safety_cfg = {\n",
        "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "        }\n",
        "\n",
        "    def verify(self, advice_text: str, trials: List[Dict[str, Any]]):\n",
        "        # Skip safety check for list-type responses about trials\n",
        "        if any(marker in advice_text for marker in [\"NCT\", \"clinical trial\", \"clinicaltrials.gov\"]):\n",
        "            log = log_provenance_step(\n",
        "                \"ActiveSafetyFilter\",\n",
        "                {\"advice\": advice_text},\n",
        "                {\"final_text\": advice_text, \"status\": \"Pass (Trial Listing)\"},\n",
        "            )\n",
        "            return advice_text, \"Pass (Trial Listing)\", log\n",
        "\n",
        "        evidence_text = \"\\n\".join(t[\"text\"][:500] for t in trials[:3])\n",
        "\n",
        "        audit_prompt = (\n",
        "            \"You are a Medical Safety Officer reviewing AI-generated advice.\\n\\n\"\n",
        "            \"ADVICE:\\n\"\n",
        "            f\"{advice_text}\\n\\n\"\n",
        "            \"EVIDENCE FROM CLINICAL TRIALS (for context):\\n\"\n",
        "            f\"{evidence_text}\\n\\n\"\n",
        "            \"Check for safety issues:\\n\"\n",
        "            \"- If the advice suggests starting/stopping/changing medication without a doctor ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it gives a diagnosis ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it makes strong clinical claims not supported by evidence ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it simply lists clinical trials with neutral wording and a recommendation to talk to a doctor ‚Üí SAFE.\\n\\n\"\n",
        "            \"If the advice is acceptable, respond with exactly: SAFE\\n\"\n",
        "            \"If it is not acceptable, respond starting with: CORRECTED: <safer version>\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(audit_prompt, safety_settings=self.safety_cfg)\n",
        "            txt = (res.text or \"\").strip()\n",
        "            if txt.startswith(\"SAFE\") or \"SAFE\" in txt:\n",
        "                final_text = advice_text\n",
        "                status = \"Pass\"\n",
        "            else:\n",
        "                final_text = f\"‚ö†Ô∏è SAFETY REVISION:\\n{txt}\"\n",
        "                status = \"Revised\"\n",
        "        except Exception:\n",
        "            if \"NCT\" in advice_text or \"clinical trial\" in advice_text.lower():\n",
        "                final_text = advice_text\n",
        "                status = \"Pass (API Fallback)\"\n",
        "            else:\n",
        "                final_text = \"‚ö†Ô∏è Safety filter triggered. Please consult a doctor.\"\n",
        "                status = \"Revised (API Error)\"\n",
        "\n",
        "        log = log_provenance_step(\n",
        "            \"ActiveSafetyFilter\",\n",
        "            {\"advice\": advice_text},\n",
        "            {\"final_text\": final_text, \"status\": status},\n",
        "        )\n",
        "        return final_text, status, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# HEALTHCAREBOT - Updated to use Qdrant\n",
        "# ============================================================\n",
        "\n",
        "class HealthcareBot:\n",
        "    def __init__(self, qdrant_client, embed_model, gemini_model, initial_profile=None):\n",
        "        self.parser = SymptomParser(gemini_model)\n",
        "        self.profile_agent = ProfileAgent(initial_profile)\n",
        "        self.evidence_scorer = EvidenceWeightedScorer()\n",
        "\n",
        "        # NEW: Use Qdrant retrieval agent\n",
        "        self.retrieval = RetrievalAgentQdrant(\n",
        "            qdrant_client=qdrant_client,\n",
        "            embed_model=embed_model,\n",
        "            evidence_scorer=self.evidence_scorer,\n",
        "            profile_agent=self.profile_agent\n",
        "        )\n",
        "\n",
        "        self.advisor = DiagnosisAdvisor(gemini_model)\n",
        "        self.safety_filter = ActiveSafetyFilter(gemini_model)\n",
        "        self.conversation_history = []\n",
        "        self.provenance_log = []\n",
        "\n",
        "\n",
        "    def chat(self, user_input: str) -> Dict[str, Any]:\n",
        "        \"\"\"Process user input through the pipeline.\"\"\"\n",
        "\n",
        "        # Parse intent\n",
        "        parsed, parse_log = self.parser.parse(user_input)\n",
        "        self.provenance_log.append(parse_log)\n",
        "\n",
        "        # Update profile\n",
        "        turn_data = {\"query\": user_input, \"parsed\": parsed}\n",
        "        profile_log = self.profile_agent.update_profile(turn_data)\n",
        "        self.provenance_log.append(profile_log)\n",
        "\n",
        "        # Retrieve trials (now from Qdrant!)\n",
        "        retrieved, retrieval_log = self.retrieval.retrieve(parsed, top_k=5)\n",
        "        self.provenance_log.append(retrieval_log)\n",
        "\n",
        "        # Generate response\n",
        "        profile_snapshot = {\n",
        "            \"user_id\": self.profile_agent.profile.get(\"user_id\", \"Patient\"),\n",
        "            \"known_conditions\": self.profile_agent.profile.get(\"extracted_conditions\", []),\n",
        "        }\n",
        "\n",
        "\n",
        "        draft, advisor_log = self.advisor.advise(parsed, retrieved, profile_snapshot)\n",
        "        self.provenance_log.append(advisor_log)\n",
        "\n",
        "        # Safety filter - FIXED: verify() returns (text, status, log)\n",
        "        advice_text = draft.get(\"recommendation\", \"\") if isinstance(draft, dict) else str(draft)\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "\n",
        "        final_response, safety_status, safety_log = self.safety_filter.verify(advice_text, trials)\n",
        "        self.provenance_log.append(safety_log)\n",
        "\n",
        "        # Save turn\n",
        "        full_turn = {\n",
        "            \"query\": user_input,\n",
        "            \"parsed\": parsed,\n",
        "            \"retrieved\": retrieved,\n",
        "            \"response\": final_response,\n",
        "            \"timestamp\": parse_log[\"timestamp\"],\n",
        "        }\n",
        "        self.conversation_history.append(full_turn)\n",
        "\n",
        "        return {\n",
        "            \"response\": final_response,\n",
        "            \"avg_confidence\": retrieved.get(\"avg_confidence\", 0.0),\n",
        "            \"num_trials\": len(retrieved.get(\"trials\", [])),\n",
        "            \"provenance\": self.provenance_log[-5:],\n",
        "            \"session_hash\": generate_reproducibility_hash(self.conversation_history),\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "def run_bot(user_input: str, qdrant_client, embed_model, gemini_model) -> Dict[str, Any]:\n",
        "    \"\"\"Convenience wrapper for single queries.\"\"\"\n",
        "    bot = HealthcareBot(qdrant_client, embed_model, gemini_model)\n",
        "    return bot.chat(user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilWN6ecnKaR8",
        "outputId": "a0f16414-17d7-45d3-95c2-6f48f348e32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(self, advice_text: str, trials: List[Dict[str, Any]])\n"
          ]
        }
      ],
      "source": [
        "# # Quick check - what does verify expect?\n",
        "# import inspect\n",
        "# from run_bot_qdrant import ActiveSafetyFilter\n",
        "\n",
        "# print(inspect.signature(ActiveSafetyFilter.verify))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKelNxetKaW6",
        "outputId": "fd424dfc-682d-472d-e79e-0671338d21e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        # Safety filter - FIXED: verify() returns (text, status, log)\n",
            "        advice_text = draft.get(\"recommendation\", \"\") if isinstance(draft, dict) else str(draft)\n",
            "        trials = retrieved.get(\"trials\", [])\n",
            "\n",
            "        final_response, safety_status, safety_log = self.safety_filter.verify(advice_text, trials)\n",
            "        self.provenance_log.append(safety_log)\n",
            "\n",
            "        # Save turn\n"
          ]
        }
      ],
      "source": [
        "# !sed -n '805,812p' /content/run_bot_qdrant.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "w4AX_Q9xKach",
        "outputId": "f4f4a77b-9205-447c-9709-52966151a7a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Loading Cross-Encoder reranker...\n",
            "‚úÖ Reranker loaded\n"
          ]
        }
      ],
      "source": [
        "# # Force reload the module\n",
        "# import sys\n",
        "# if 'run_bot_qdrant' in sys.modules:\n",
        "#     del sys.modules['run_bot_qdrant']\n",
        "\n",
        "# # Now import fresh\n",
        "# from run_bot_qdrant import run_bot\n",
        "\n",
        "# # Test again\n",
        "# result = run_bot(\n",
        "#     \"What trials are studying insulin therapy for diabetes?\",\n",
        "#     qdrant_client,\n",
        "#     embed_model,\n",
        "#     gemini_model\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLR9-TISTbCa",
        "outputId": "ae443e13-f84c-4ca5-e6de-93d465b72c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    def verify(self, advice_text: str, trials: List[Dict[str, Any]]):\n",
            "        # Skip safety check for list-type responses about trials\n",
            "        if any(marker in advice_text for marker in [\"NCT\", \"clinical trial\", \"clinicaltrials.gov\"]):\n",
            "            log = log_provenance_step(\n",
            "                \"ActiveSafetyFilter\",\n",
            "                {\"advice\": advice_text},\n",
            "                {\"final_text\": advice_text, \"status\": \"Pass (Trial Listing)\"},\n",
            "            )\n",
            "            return advice_text, \"Pass (Trial Listing)\", log\n",
            "\n",
            "        evidence_text = \"\\n\".join(t[\"text\"][:500] for t in trials[:3])\n",
            "\n",
            "        audit_prompt = (\n",
            "            \"You are a Medical Safety Officer reviewing AI-generated advice.\\n\\n\"\n",
            "            \"ADVICE:\\n\"\n",
            "            f\"{advice_text}\\n\\n\"\n",
            "            \"EVIDENCE FROM CLINICAL TRIALS (for context):\\n\"\n",
            "            f\"{evidence_text}\\n\\n\"\n",
            "            \"Check for safety issues:\\n\"\n",
            "            \"- If the advice suggests starting/stopping/changing medication without a doctor ‚Üí UNSAFE.\\n\"\n",
            "            \"- If it gives a diagnosis ‚Üí UNSAFE.\\n\"\n",
            "            \"- If it makes strong clinical claims not supported by evidence ‚Üí UNSAFE.\\n\"\n",
            "            \"- If it simply lists clinical trials with neutral wording and a recommendation to talk to a doctor ‚Üí SAFE.\\n\\n\"\n",
            "            \"If the advice is acceptable, respond with exactly: SAFE\\n\"\n",
            "            \"If it is not acceptable, respond starting with: CORRECTED: <safer version>\\n\"\n",
            "        )\n",
            "\n",
            "        try:\n",
            "            res = self.model.generate_content(audit_prompt, safety_settings=self.safety_cfg)\n",
            "            txt = (res.text or \"\").strip()\n",
            "            if txt.startswith(\"SAFE\") or \"SAFE\" in txt:\n",
            "                final_text = advice_text\n",
            "                status = \"Pass\"\n",
            "            else:\n",
            "                final_text = f\"‚ö†Ô∏è SAFETY REVISION:\\n{txt}\"\n",
            "                status = \"Revised\"\n",
            "        except Exception:\n",
            "            if \"NCT\" in advice_text or \"clinical trial\" in advice_text.lower():\n",
            "                final_text = advice_text\n",
            "                status = \"Pass (API Fallback)\"\n",
            "            else:\n",
            "                final_text = \"‚ö†Ô∏è Safety filter triggered. Please consult a doctor.\"\n",
            "                status = \"Revised (API Error)\"\n",
            "\n",
            "        log = log_provenance_step(\n",
            "            \"ActiveSafetyFilter\",\n",
            "            {\"advice\": advice_text},\n",
            "            {\"final_text\": final_text, \"status\": status},\n",
            "        )\n",
            "        return final_text, status, log\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# import inspect\n",
        "# from run_bot_qdrant import ActiveSafetyFilter\n",
        "\n",
        "# # Show the FULL source code of verify\n",
        "# print(inspect.getsource(ActiveSafetyFilter.verify))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcktXAO0TbFZ",
        "outputId": "6c587226-96ba-4c8f-c1c6-068853ef91d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Modules cleared\n"
          ]
        }
      ],
      "source": [
        "# # Kill all cached modules\n",
        "# import sys\n",
        "# for key in list(sys.modules.keys()):\n",
        "#     if any(x in key for x in ['run_bot', 'utils_qdrant', 'retrieval_agent']):\n",
        "#         del sys.modules[key]\n",
        "\n",
        "# print(\"‚úÖ Modules cleared\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JBicUGwwTbJN",
        "outputId": "9adb69e0-081f-4854-d714-948cf995225b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîë Gemini API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "üîë Qdrant API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚è≥ Connecting to Qdrant...\n",
            "‚úÖ Connected to Qdrant: 262,660 vectors ready\n",
            "‚úÖ Embedding model loaded\n",
            "\n",
            "ü§ñ Testing bot...\n",
            "\n",
            "‚è≥ Loading Cross-Encoder reranker...\n",
            "‚úÖ Reranker loaded\n",
            "I found 5 clinical trials relevant to your request:\n",
            "\n",
            "**NCT00151697** (Relevance: 91%)\n",
            "‚Ä¢ LANN-study: Lantus, Amaryl, Novorapid, Novomix Study\n",
            "  Status: Completed\n",
            "\n",
            "  This clinical trial aims to determine if a new combination of glimepiride and short-acting insulin can better control blood sugar and weight gain compared to standard insulin injections in people with diabetes whose current oral medications are not enough. The study will follow 150 participants with poorly controlled diabetes on oral medications for one year, comparing their glucose levels and weight changes under the new combination treatment, twice-daily mixed insulin injections, or once-daily basal insulin injections.\n",
            "\n",
            "\n",
            "\n",
            "**NCT00922649** (Relevance: 88%)\n",
            "‚Ä¢ Pilot Study Assessing Insulin Pump Therapy in Type 2 Diabetes\n",
            "  Status: Completed\n",
            "\n",
            "  This pilot study is testing the effectiveness of starting insulin pump therapy using rapid-acting insulin for people with type 2 diabetes who haven't used an insulin pump before and whose blood sugar is not well-controlled with their current medication. Participants are divided into three groups based on their existing treatment: oral medications only, basal insulin with or without oral medications, or basal-bolus insulin with or without oral medications. The study will follow participants for 16 weeks to see if the pump therapy improves their blood sugar control.\n",
            "\n",
            "  PubMed abstract (PMID 21355725):\n",
            "  1. Diabetes Technol Ther. 2011 Apr;13(4):471-6. doi: 10.1089/dia.2010.0167. Epub \n",
            "2011 Feb 28.\n",
            "\n",
            "Associations between improved glucose control and patient-reported outcomes \n",
            "after initiation of insulin pump therapy in patients with type 2 diabetes \n",
            "mellitus.\n",
            "\n",
            "Peyrot M(1), Rubin RR, Chen X, Frias JP.\n",
            "\n",
            "Author information:\n",
            "(1)Loyola University Maryland, Baltimore, Maryland, USA. Mark.peyrot@gmail.com\n",
            "\n",
            "BACKGROUND: This study assessed the relationship between changes in glucose \n",
            "control and changes in patient-reported outcomes (PRO)--health-related quality \n",
            "of life (HR-QoL) and treatment satisfaction (TxSat)--in patients with type 2 \n",
            "diabetes initiating insulin pump therapy.\n",
            "METHODS: Patients (n = 54) initiating insulin pump therapy (Animas(¬Æ) 2020, \n",
            "Animas Corp., West Chester, PA) were studied for 16 weeks. Glucose control was \n",
            "measured with patient-blinded continuous glucose monitoring (CGM) (SEVEN(‚Ñ¢), \n",
            "DexCom, San Diego, CA) and unblinded glycosylated hemoglobin (A1C) and \n",
            "seven-point self-monitored blood glucose (SMBG) profiles. HR-QoL was measured \n",
            "using the Diabetes Symptom Checklist-Revised (DSC-R) and the EuroQol-5 \n",
            "Dimensions (EQ-5D). TxSat was measured using the Insulin Delivery System Rating \n",
            "Questionnaire (IDSRQ) clinical efficacy and treatment preference scales. \n",
            "Bivariate correlations assessed associations between measures of change from \n",
            "baseline.\n",
            "RESULTS: Decreased A1C was associated only with improvement in IDSRQ clinical \n",
            "efficacy. For CGM and SMBG, reductions in mean glucose concentrations were \n",
            "associated with decreased DSC-R symptoms, improved EQ-5D health utility, and \n",
            "increased IDSRQ perceived clinical efficacy and treatment preference. Reduced \n",
            "glycemic variability was associated with improved EQ-5D health utility and \n",
            "increased IDSRQ treatment preference. CGM and SMBG readings from different times \n",
            "of day/night were differentially associated with all PRO.\n",
            "CONCLUSIONS: Findings suggest that A1C, representing an \"average\" of both high \n",
            "and low blood...\n",
            "\n",
            "  PubMed link: https://pubmed.ncbi.nlm.nih.gov/21355725/\n",
            "\n",
            "\n",
            "\n",
            "**NCT00922649** (Relevance: 88%)\n",
            "‚Ä¢ Pilot Study Assessing Insulin Pump Therapy in Type 2 Diabetes\n",
            "  Status: Completed\n",
            "\n",
            "  This pilot study is testing how well insulin pumps work for people with type 2 diabetes who aren't reaching their blood sugar goals with their current diabetes treatments (pills or insulin injections). The study will follow participants for 16 weeks as they switch to using an insulin pump that delivers rapid-acting insulin throughout the day. Participants will be people who have never used an insulin pump before and are currently taking diabetes pills, basal insulin, or basal-bolus insulin along with pills.\n",
            "\n",
            "  PubMed abstract (PMID 21355725):\n",
            "  1. Diabetes Technol Ther. 2011 Apr;13(4):471-6. doi: 10.1089/dia.2010.0167. Epub \n",
            "2011 Feb 28.\n",
            "\n",
            "Associations between improved glucose control and patient-reported outcomes \n",
            "after initiation of insulin pump therapy in patients with type 2 diabetes \n",
            "mellitus.\n",
            "\n",
            "Peyrot M(1), Rubin RR, Chen X, Frias JP.\n",
            "\n",
            "Author information:\n",
            "(1)Loyola University Maryland, Baltimore, Maryland, USA. Mark.peyrot@gmail.com\n",
            "\n",
            "BACKGROUND: This study assessed the relationship between changes in glucose \n",
            "control and changes in patient-reported outcomes (PRO)--health-related quality \n",
            "of life (HR-QoL) and treatment satisfaction (TxSat)--in patients with type 2 \n",
            "diabetes initiating insulin pump therapy.\n",
            "METHODS: Patients (n = 54) initiating insulin pump therapy (Animas(¬Æ) 2020, \n",
            "Animas Corp., West Chester, PA) were studied for 16 weeks. Glucose control was \n",
            "measured with patient-blinded continuous glucose monitoring (CGM) (SEVEN(‚Ñ¢), \n",
            "DexCom, San Diego, CA) and unblinded glycosylated hemoglobin (A1C) and \n",
            "seven-point self-monitored blood glucose (SMBG) profiles. HR-QoL was measured \n",
            "using the Diabetes Symptom Checklist-Revised (DSC-R) and the EuroQol-5 \n",
            "Dimensions (EQ-5D). TxSat was measured using the Insulin Delivery System Rating \n",
            "Questionnaire (IDSRQ) clinical efficacy and treatment preference scales. \n",
            "Bivariate correlations assessed associations between measures of change from \n",
            "baseline.\n",
            "RESULTS: Decreased A1C was associated only with improvement in IDSRQ clinical \n",
            "efficacy. For CGM and SMBG, reductions in mean glucose concentrations were \n",
            "associated with decreased DSC-R symptoms, improved EQ-5D health utility, and \n",
            "increased IDSRQ perceived clinical efficacy and treatment preference. Reduced \n",
            "glycemic variability was associated with improved EQ-5D health utility and \n",
            "increased IDSRQ treatment preference. CGM and SMBG readings from different times \n",
            "of day/night were differentially associated with all PRO.\n",
            "CONCLUSIONS: Findings suggest that A1C, representing an \"average\" of both high \n",
            "and low blood...\n",
            "\n",
            "  PubMed link: https://pubmed.ncbi.nlm.nih.gov/21355725/\n",
            "\n",
            "\n",
            "\n",
            "**NCT00537303** (Relevance: 86%)\n",
            "‚Ä¢ Comparison of the Blood Sugar Lowering Effect and Safety of Two Insulin Treatments in Type 2 Diabetes\n",
            "  Status: Completed\n",
            "\n",
            "  This international study is comparing the safety and effectiveness of two different insulin treatments for people with type 2 diabetes. The trial aims to determine if an \"advanced\" insulin treatment works better and is safer than a \"basic\" insulin treatment for managing their condition. Participants will be recruited from Europe, Africa, and the USA.\n",
            "\n",
            "  PubMed abstract (PMID 21550957):\n",
            "  1. Endocr Pract. 2011 Sep-Oct;17(5):727-36. doi: 10.4158/EP10367.OR.\n",
            "\n",
            "Comparison of 2 intensification regimens with rapid-acting insulin aspart in \n",
            "type 2 diabetes mellitus inadequately controlled by once-daily insulin detemir \n",
            "and oral antidiabetes drugs: the step-wise randomized study.\n",
            "\n",
            "Meneghini L(1), Mersebach H, Kumar S, Svendsen AL, Hermansen K.\n",
            "\n",
            "Author information:\n",
            "(1)Division of Endocrinology, Diabetes, and Metabolism, University of Miami \n",
            "Miller School of Medicine, Miami, Florida, USA. Lmeneghi@med.miami.edu\n",
            "\n",
            "OBJECTIVE: To compare the efficacy and safety of 2 intensification strategies \n",
            "for stepwise addition of prandial insulin aspart in patients with type 2 \n",
            "diabetes mellitus treated with insulin detemir.\n",
            "METHODS: This randomized, controlled, parallel-group, open-label, 48-week trial \n",
            "compared the stepwise addition of insulin aspart to either the largest meal \n",
            "(titration based on premeal glucose values [SimpleSTEP]) or to the meal with the \n",
            "largest prandial glucose increment (titration based on postmeal glucose values \n",
            "[ExtraSTEP]) in patients with type 2 diabetes inadequately controlled on basal \n",
            "insulin and oral antidiabetes drugs. After 12 weeks of basal insulin detemir \n",
            "dosage optimization, participants with a hemoglobin A1c level of 7% or greater \n",
            "entered three 12-week treatment periods with stepwise addition of a first \n",
            "insulin aspart bolus, then a second, and then a third, if hemoglobin A1c \n",
            "remained at 7% or greater after 12 and 24 weeks of treatment, respectively. \n",
            "Endpoints included hemoglobin A1c (primary endpoint), fasting plasma glucose, \n",
            "self-measured plasma glucose, adverse events, and hypoglycemia.\n",
            "RESULTS: Two hundred ninety-six patients were randomly assigned to treatment \n",
            "with insulin aspart in the SimpleSTEP (n = 150) and ExtraSTEP (n = 146) groups. \n",
            "Hemoglobin A1c decreased by approximately 1.2% in both groups, to 7.5 ¬± 1.1% \n",
            "(Simple-STEP) and 7.7 ¬± 1.2% (ExtraSTEP) at end of trial (estimated treatment \n",
            "difference, SimpleSTEP - ExtraST...\n",
            "\n",
            "  PubMed link: https://pubmed.ncbi.nlm.nih.gov/21550957/\n",
            "\n",
            "\n",
            "\n",
            "**NCT00537303** (Relevance: 86%)\n",
            "‚Ä¢ Comparison of the Blood Sugar Lowering Effect and Safety of Two Insulin Treatments in Type 2 Diabetes\n",
            "  Status: Completed\n",
            "\n",
            "  This international clinical trial is comparing the safety and effectiveness of two different insulin treatments for people with type 2 diabetes. The study aims to determine if an \"advanced\" insulin treatment works better and is safer than a \"basic\" one. Participants will be adults with type 2 diabetes who require insulin.\n",
            "\n",
            "  PubMed abstract (PMID 21550957):\n",
            "  1. Endocr Pract. 2011 Sep-Oct;17(5):727-36. doi: 10.4158/EP10367.OR.\n",
            "\n",
            "Comparison of 2 intensification regimens with rapid-acting insulin aspart in \n",
            "type 2 diabetes mellitus inadequately controlled by once-daily insulin detemir \n",
            "and oral antidiabetes drugs: the step-wise randomized study.\n",
            "\n",
            "Meneghini L(1), Mersebach H, Kumar S, Svendsen AL, Hermansen K.\n",
            "\n",
            "Author information:\n",
            "(1)Division of Endocrinology, Diabetes, and Metabolism, University of Miami \n",
            "Miller School of Medicine, Miami, Florida, USA. Lmeneghi@med.miami.edu\n",
            "\n",
            "OBJECTIVE: To compare the efficacy and safety of 2 intensification strategies \n",
            "for stepwise addition of prandial insulin aspart in patients with type 2 \n",
            "diabetes mellitus treated with insulin detemir.\n",
            "METHODS: This randomized, controlled, parallel-group, open-label, 48-week trial \n",
            "compared the stepwise addition of insulin aspart to either the largest meal \n",
            "(titration based on premeal glucose values [SimpleSTEP]) or to the meal with the \n",
            "largest prandial glucose increment (titration based on postmeal glucose values \n",
            "[ExtraSTEP]) in patients with type 2 diabetes inadequately controlled on basal \n",
            "insulin and oral antidiabetes drugs. After 12 weeks of basal insulin detemir \n",
            "dosage optimization, participants with a hemoglobin A1c level of 7% or greater \n",
            "entered three 12-week treatment periods with stepwise addition of a first \n",
            "insulin aspart bolus, then a second, and then a third, if hemoglobin A1c \n",
            "remained at 7% or greater after 12 and 24 weeks of treatment, respectively. \n",
            "Endpoints included hemoglobin A1c (primary endpoint), fasting plasma glucose, \n",
            "self-measured plasma glucose, adverse events, and hypoglycemia.\n",
            "RESULTS: Two hundred ninety-six patients were randomly assigned to treatment \n",
            "with insulin aspart in the SimpleSTEP (n = 150) and ExtraSTEP (n = 146) groups. \n",
            "Hemoglobin A1c decreased by approximately 1.2% in both groups, to 7.5 ¬± 1.1% \n",
            "(Simple-STEP) and 7.7 ¬± 1.2% (ExtraSTEP) at end of trial (estimated treatment \n",
            "difference, SimpleSTEP - ExtraST...\n",
            "\n",
            "  PubMed link: https://pubmed.ncbi.nlm.nih.gov/21550957/\n",
            "\n",
            "\n",
            "\n",
            "Summary: These trials explore potential treatments or management strategies for the condition you asked about. More details are available using the listed NCT IDs.\n",
            "\n",
            "To learn more or consider participation, visit clinicaltrials.gov and search by NCT ID. Always discuss clinical trial options with your healthcare provider.\n",
            "\n",
            "üìä Found 5 trials\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Setup keys\n",
        "gemini_key = getpass.getpass(\"üîë Gemini API Key: \")\n",
        "os.environ[\"GEMINI_API_KEY\"] = gemini_key\n",
        "\n",
        "qdrant_api_key = getpass.getpass(\"üîë Qdrant API Key: \")\n",
        "\n",
        "# Setup clients\n",
        "genai.configure(api_key=gemini_key)\n",
        "gemini_model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "from utils_qdrant import load_qdrant_and_model\n",
        "qdrant_url = \"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\"\n",
        "qdrant_client, embed_model = load_qdrant_and_model(qdrant_url, qdrant_api_key)\n",
        "\n",
        "# Import and test\n",
        "from run_bot_qdrant import run_bot\n",
        "\n",
        "print(\"\\nü§ñ Testing bot...\\n\")\n",
        "result = run_bot(\n",
        "    \"What trials are studying insulin therapy for diabetes?\",\n",
        "    qdrant_client,\n",
        "    embed_model,\n",
        "    gemini_model\n",
        ")\n",
        "\n",
        "print(result[\"response\"])\n",
        "print(f\"\\nüìä Found {result['num_trials']} trials\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUcIBKF0ZHer"
      },
      "source": [
        "Update Streamlit App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkcOXJy8Kajv",
        "outputId": "531ea92b-e425-47b1-8dcc-91f7e32f8f10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\"\"\"\n",
        "Streamlit UI for HealthcareBot with Qdrant backend\n",
        "\"\"\"\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "from typing import Dict, Any\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Import Qdrant utilities and bot\n",
        "from utils_qdrant import load_qdrant_and_model\n",
        "from run_bot_qdrant import HealthcareBot\n",
        "\n",
        "# Page config\n",
        "st.set_page_config(\n",
        "    page_title=\"Clinical Trials Search Assistant\",\n",
        "    page_icon=\"üè•\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# Title\n",
        "st.title(\"üè• Clinical Trials Search Assistant\")\n",
        "st.markdown(\"**Powered by Qdrant + Gemini 2.0 Flash**\")\n",
        "st.markdown(\"Search across 262,000+ clinical trials for diabetes, cancer, Alzheimer's, asthma, and cardiovascular disease.\")\n",
        "\n",
        "# Sidebar for API keys\n",
        "with st.sidebar:\n",
        "    st.header(\"‚öôÔ∏è Configuration\")\n",
        "\n",
        "    # Gemini API Key\n",
        "    gemini_key = st.text_input(\n",
        "        \"Gemini API Key\",\n",
        "        type=\"password\",\n",
        "        help=\"Enter your Gemini API key\"\n",
        "    )\n",
        "\n",
        "    # Qdrant API Key\n",
        "    qdrant_key = st.text_input(\n",
        "        \"Qdrant API Key\",\n",
        "        type=\"password\",\n",
        "        help=\"Enter your Qdrant API key\"\n",
        "    )\n",
        "\n",
        "    # Qdrant URL (pre-filled)\n",
        "    qdrant_url = st.text_input(\n",
        "        \"Qdrant Cluster URL\",\n",
        "        value=\"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\",\n",
        "        help=\"Your Qdrant cluster URL\"\n",
        "    )\n",
        "\n",
        "    st.divider()\n",
        "\n",
        "    # Info\n",
        "    st.markdown(\"### üìä System Status\")\n",
        "    if gemini_key and qdrant_key:\n",
        "        st.success(\"‚úÖ Keys configured\")\n",
        "    else:\n",
        "        st.warning(\"‚ö†Ô∏è Enter API keys to start\")\n",
        "\n",
        "# Initialize session state\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "if \"bot\" not in st.session_state:\n",
        "    st.session_state.bot = None\n",
        "\n",
        "if \"qdrant_client\" not in st.session_state:\n",
        "    st.session_state.qdrant_client = None\n",
        "\n",
        "if \"embed_model\" not in st.session_state:\n",
        "    st.session_state.embed_model = None\n",
        "\n",
        "# Initialize bot when keys are provided\n",
        "if gemini_key and qdrant_key and st.session_state.bot is None:\n",
        "    with st.spinner(\"üîÑ Initializing system...\"):\n",
        "        try:\n",
        "            # Setup Gemini\n",
        "            os.environ[\"GEMINI_API_KEY\"] = gemini_key\n",
        "            genai.configure(api_key=gemini_key)\n",
        "            gemini_model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "            # Setup Qdrant\n",
        "            qdrant_client, embed_model = load_qdrant_and_model(qdrant_url, qdrant_key)\n",
        "\n",
        "            # Store in session\n",
        "            st.session_state.qdrant_client = qdrant_client\n",
        "            st.session_state.embed_model = embed_model\n",
        "\n",
        "            # Initialize bot\n",
        "            st.session_state.bot = HealthcareBot(\n",
        "                qdrant_client=qdrant_client,\n",
        "                embed_model=embed_model,\n",
        "                gemini_model=gemini_model\n",
        "            )\n",
        "\n",
        "            st.success(\"‚úÖ System ready!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"‚ùå Initialization failed: {str(e)}\")\n",
        "\n",
        "# Display chat messages\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "        # Show metadata for assistant messages\n",
        "        if message[\"role\"] == \"assistant\" and \"metadata\" in message:\n",
        "            with st.expander(\"üìä Details\"):\n",
        "                col1, col2 = st.columns(2)\n",
        "                with col1:\n",
        "                    st.metric(\"Trials Found\", message[\"metadata\"][\"num_trials\"])\n",
        "                with col2:\n",
        "                    st.metric(\"Confidence\", f\"{message['metadata']['avg_confidence']:.0%}\")\n",
        "\n",
        "# Chat input\n",
        "if prompt := st.chat_input(\"Ask about clinical trials...\"):\n",
        "\n",
        "    # Check if bot is initialized\n",
        "    if st.session_state.bot is None:\n",
        "        st.error(\"‚ö†Ô∏è Please enter your API keys in the sidebar first!\")\n",
        "    else:\n",
        "        # Add user message\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "        # Get bot response\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            with st.spinner(\"üîç Searching clinical trials...\"):\n",
        "                try:\n",
        "                    result = st.session_state.bot.chat(prompt)\n",
        "\n",
        "                    response = result[\"response\"]\n",
        "\n",
        "                    # Display response\n",
        "                    st.markdown(response)\n",
        "\n",
        "                    # Show metadata\n",
        "                    with st.expander(\"üìä Details\"):\n",
        "                        col1, col2, col3 = st.columns(3)\n",
        "                        with col1:\n",
        "                            st.metric(\"Trials Found\", result[\"num_trials\"])\n",
        "                        with col2:\n",
        "                            st.metric(\"Avg Confidence\", f\"{result['avg_confidence']:.0%}\")\n",
        "                        with col3:\n",
        "                            st.metric(\"Session Hash\", result[\"session_hash\"][:8])\n",
        "\n",
        "                    # Add to messages\n",
        "                    st.session_state.messages.append({\n",
        "                        \"role\": \"assistant\",\n",
        "                        \"content\": response,\n",
        "                        \"metadata\": {\n",
        "                            \"num_trials\": result[\"num_trials\"],\n",
        "                            \"avg_confidence\": result[\"avg_confidence\"]\n",
        "                        }\n",
        "                    })\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"‚ùå Error: {str(e)}\")\n",
        "                    st.exception(e)\n",
        "\n",
        "# Sidebar examples\n",
        "with st.sidebar:\n",
        "    st.divider()\n",
        "    st.markdown(\"### üí° Example Queries\")\n",
        "\n",
        "    examples = [\n",
        "        \"What trials study insulin therapy for diabetes?\",\n",
        "        \"Show me cancer immunotherapy trials\",\n",
        "        \"Are there trials for Alzheimer's disease?\",\n",
        "        \"What trials are recruiting for asthma?\",\n",
        "        \"Find cardiovascular disease trials\"\n",
        "    ]\n",
        "\n",
        "    for example in examples:\n",
        "        if st.button(example, key=example):\n",
        "            st.session_state.messages.append({\"role\": \"user\", \"content\": example})\n",
        "            st.rerun()\n",
        "\n",
        "# Footer\n",
        "st.divider()\n",
        "st.markdown(\"\"\"\n",
        "<div style='text-align: center; color: gray; font-size: 0.9em;'>\n",
        "    üî¨ Powered by Qdrant Vector Database + Gemini 2.0 Flash<br>\n",
        "    üìä Searching 262,660+ clinical trials across 5 disease areas\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jAd8XzdZeXV",
        "outputId": "2017d827-7e4d-45b9-85cb-001d64745ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ Packages installed!\n"
          ]
        }
      ],
      "source": [
        "# Install Streamlit and pyngrok\n",
        "!pip install -q streamlit pyngrok\n",
        "\n",
        "print(\"‚úÖ Packages installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5h7FMHpyZGtT"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 cloudflared\n",
        "!chmod +x cloudflared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NMIxuy2ZGxo",
        "outputId": "10c375f6-f86a-4d81-81c6-684d3554f84a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90m2025-11-30T15:38:11Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-11-30T15:38:11Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m |  https://com-trackbacks-urge-standards.trycloudflare.com                                   |\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 991dffd8889ee9f0147b6b48933da9e4407e68ea8c6d984f55fa2d3db4bb431d)\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 3789ec36-9375-4d75-8ca0-2f78de5ab91f\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63\n",
            "2025/11/30 15:38:16 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-11-30T15:38:16Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0md27fcf6c-0310-456a-91ad-2c7d41c0b38a \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63 \u001b[36mlocation=\u001b[0mtpe01 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-11-30T15:45:11Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2025-11-30T15:45:11Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to run the datagram handler \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63\n",
            "\u001b[90m2025-11-30T15:45:11Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63\n",
            "\u001b[90m2025-11-30T15:45:11Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Serve tunnel error \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63\n",
            "\u001b[90m2025-11-30T15:45:11Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63\n",
            "\u001b[90m2025-11-30T15:45:11Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Connection terminated \u001b[36mconnIndex=\u001b[0m0\n",
            "\u001b[90m2025-11-30T15:45:11Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2025-11-30T15:45:11Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2025-11-30T15:45:11Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ],
      "source": [
        "#AI LLM\n",
        "!streamlit run app.py &>/dev/null&\n",
        "!./cloudflared tunnel --url http://localhost:8501 --no-autoupdate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTN6OuTUZG5E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKEi7YkmcMKu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-HZlve1cMPA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUmbb9KsIaRL"
      },
      "source": [
        "Step 1: Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2IWghs9QZVy",
        "outputId": "42b27778-5b4b-42ad-dc71-2f7dfd529b64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q requests pandas streamlit pyngrok faiss-cpu sentence-transformers numpy\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUskaUMVEYsn",
        "outputId": "4557aeb4-0acc-4b99-d51a-2a1e66730f0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnfATz0x1DYc",
        "outputId": "0799b647-2c8d-49dc-b2b0-a24aafb8a469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîë Enter Gemini API Key (Invisible Input): ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ API Key captured securely in Environment Variable.\n"
          ]
        }
      ],
      "source": [
        "# Secure KEY INPUT\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# Securely Capture Key\n",
        "# Input will be invisible. Paste key and press Enter.\n",
        "key_input = getpass.getpass(\"üîë Enter Gemini API Key (Invisible Input): \")\n",
        "\n",
        "if not key_input.startswith(\"AIza\"):\n",
        "    print(\"‚ö†Ô∏è Warning: Key might be invalid (usually starts with 'AIza').\")\n",
        "else:\n",
        "    print(\"‚úÖ API Key captured securely in Environment Variable.\")\n",
        "\n",
        "# 2. Set as Environment Variable for the Session\n",
        "os.environ[\"GEMINI_API_KEY\"] = key_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mwEwzAoPHlB",
        "outputId": "f0d16361-3372-4e73-c074-0f2d10956e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing build_embeddings.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile build_embeddings.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "import json\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# === REAL PATH (from readlink) ===\n",
        "BASE = \"/content/drive/.shortcut-targets-by-id/1-SiVJhXHTHtDYSrPmW_0VfuP7gSTePcj/data\"\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Load Data\n",
        "# ---------------------------------------------\n",
        "\n",
        "df1 = pd.read_csv(f\"{BASE}/clinical_trials_diabetes_full.csv\")\n",
        "df2 = pd.read_csv(f\"{BASE}/clinical_trials_master_full.csv\")\n",
        "df3 = pd.read_csv(f\"{BASE}/clinical_trials_alzheimer_full.csv\")\n",
        "df4 = pd.read_csv(f\"{BASE}/clinical_trials_cancer_full.csv\")\n",
        "df5 = pd.read_csv(f\"{BASE}/clinical_trials_asthma_full.csv\")\n",
        "df6 = pd.read_csv(f\"{BASE}/clinical_trials_cardiovascular_full.csv\")\n",
        "\n",
        "df = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)\n",
        "\n",
        "df[\"status\"] = df[\"status\"].astype(str).str.strip().str.title()\n",
        "bad_status = [\"Terminated\", \"Withdrawn\", \"Suspended\", \"No Longer Available\", \"Unknown\"]\n",
        "df_clean = df[~df[\"status\"].isin(bad_status)].copy()\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Chunking\n",
        "# ---------------------------------------------\n",
        "chunks = []\n",
        "chunk_map = []\n",
        "\n",
        "for idx, row in df_clean.iterrows():\n",
        "    title = str(row.get(\"brief_title\", \"\")).strip()\n",
        "    summary = str(row.get(\"brief_summary\", \"\")).strip()\n",
        "\n",
        "    if len(summary) < 20:\n",
        "        continue\n",
        "\n",
        "    text = f\"Title: {title}\\nSummary: {summary}\"\n",
        "    chunks.append(text)\n",
        "\n",
        "    chunk_map.append({\n",
        "        \"nct_id\": row[\"nct_id\"],\n",
        "        \"title\": title,\n",
        "        \"text\": text,\n",
        "        \"status\": row[\"status\"]\n",
        "    })\n",
        "\n",
        "print(f\"Created {len(chunks)} chunks.\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Embeddings\n",
        "# ---------------------------------------------\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = embed_model.encode(chunks, batch_size=64, show_progress_bar=True)\n",
        "\n",
        "np.save(f\"{BASE}/clinical_trials_all_full_embeddings.npy\", embeddings)\n",
        "print(\"Saved clinical_trials_all_full_embeddings.npy\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Save chunk map\n",
        "# ---------------------------------------------\n",
        "with open(f\"{BASE}/clinical_trials_all_full_chunk_map.json\", \"w\") as f:\n",
        "    json.dump(chunk_map, f)\n",
        "\n",
        "print(\"Saved clinical_trials_all_full_chunk_map.json\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Build & Save FAISS\n",
        "# ---------------------------------------------\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(embeddings).astype(\"float32\"))\n",
        "faiss.write_index(index, f\"{BASE}/clinical_trials_all_full_faiss.index\")\n",
        "\n",
        "print(\"Saved clinical_trials_all_full_faiss.index\")\n",
        "print(\"‚úÖ Embedding build COMPLETE.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32A5yZO0V4VT",
        "outputId": "2b6168c6-5090-4029-8787-2e33f41f3a0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-28 00:13:26.004412: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764288806.025774    2186 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764288806.031981    2186 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764288806.047591    2186 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764288806.047617    2186 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764288806.047621    2186 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764288806.047625    2186 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Created 262660 chunks.\n",
            "modules.json: 100% 349/349 [00:00<00:00, 2.22MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 885kB/s]\n",
            "README.md: 10.5kB [00:00, 33.8MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 540kB/s]\n",
            "config.json: 100% 612/612 [00:00<00:00, 4.94MB/s]\n",
            "model.safetensors: 100% 90.9M/90.9M [00:02<00:00, 42.1MB/s]\n",
            "tokenizer_config.json: 100% 350/350 [00:00<00:00, 3.26MB/s]\n",
            "vocab.txt: 232kB [00:00, 10.1MB/s]\n",
            "tokenizer.json: 466kB [00:00, 31.4MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 1.17MB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 1.45MB/s]\n",
            "Batches: 100% 4105/4105 [08:27<00:00,  8.08it/s]\n",
            "Saved clinical_trials_all_full_embeddings.npy\n",
            "Saved clinical_trials_all_full_chunk_map.json\n",
            "Saved clinical_trials_all_full_faiss.index\n",
            "‚úÖ Embedding build COMPLETE.\n"
          ]
        }
      ],
      "source": [
        "!python build_embeddings.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PXqvXLkXaX7",
        "outputId": "8bad652c-94e1-4a69-9c2e-e481415fa719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils.py\n",
        "import json\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# --- Confidence score from distance ---\n",
        "\n",
        "def calculate_confidence_score(distance: float, normalization_factor: float = 1.0) -> float:\n",
        "    \"\"\"Inverse L2 distance score in (0,1]; closer = higher confidence.\"\"\"\n",
        "    return normalization_factor / (normalization_factor + float(distance))\n",
        "\n",
        "\n",
        "# --- Load pre-built index + chunk map ---\n",
        "\n",
        "def load_data_and_index(chunk_map_path: str, faiss_path: str):\n",
        "    \"\"\"Loads pre-built chunks and FAISS index for quick startup.\"\"\"\n",
        "    print(\"‚è≥ Loading pre-built RAG index...\")\n",
        "\n",
        "    with open(chunk_map_path, \"r\") as f:\n",
        "        chunk_map = json.load(f)\n",
        "\n",
        "    index = faiss.read_index(faiss_path)\n",
        "\n",
        "    embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    print(f\"‚úÖ RAG Index Ready: {index.ntotal} vectors loaded.\")\n",
        "    return embed_model, index, chunk_map\n",
        "\n",
        "\n",
        "# --- Provenance logging ---\n",
        "\n",
        "def log_provenance_step(agent_name: str, input_data, output_data, detail=None):\n",
        "    \"\"\"\n",
        "    Creates a detailed log entry for a single agent step.\n",
        "    \"\"\"\n",
        "    log_entry = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"agent\": agent_name,\n",
        "        \"input\": input_data,\n",
        "        \"output\": output_data,\n",
        "        \"detail\": detail or {},\n",
        "        \"model_version\": \"gemini-2.0-flash\",\n",
        "    }\n",
        "    return log_entry\n",
        "\n",
        "\n",
        "# --- Reproducibility hash ---\n",
        "\n",
        "def generate_reproducibility_hash(conversation_history, corpus_version: str = \"v1.0\"):\n",
        "    \"\"\"\n",
        "    Generates a deterministic session hash based on the conversation history.\n",
        "    \"\"\"\n",
        "    queries = [turn.get(\"query\", \"\") for turn in conversation_history]\n",
        "    raw = f\"{corpus_version}|{'|'.join(queries)}\"\n",
        "    return hashlib.md5(raw.encode(\"utf-8\")).hexdigest()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adDqKGc-piM1",
        "outputId": "00f72696-73dc-47f8-e77c-f44e2b219280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ sentence_transformers imported successfully.\n",
            "‚è≥ Loading pre-built RAG index...\n",
            "‚úÖ RAG Index Ready: 262660 vectors loaded.\n",
            "‚è≥ Loading Reranker Model (Cross-Encoder)...\n",
            "‚úÖ Reranker Loaded.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "\n",
        "# --- Updated Import: Robust Cross-Encoder Initialization ---\n",
        "CrossEncoder = None\n",
        "try:\n",
        "    from sentence_transformers import CrossEncoder\n",
        "    print(\"‚úÖ sentence_transformers imported successfully.\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è sentence_transformers not found. Reranking will be disabled.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error importing CrossEncoder: {e}. Reranking disabled.\")\n",
        "\n",
        "from utils import (\n",
        "    load_data_and_index,\n",
        "    log_provenance_step,\n",
        "    generate_reproducibility_hash,\n",
        "    calculate_confidence_score,\n",
        ")\n",
        "\n",
        "# --- CONFIG (Gemini 2.0 Flash) ---\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not API_KEY:\n",
        "    print(\"‚ùå ERROR: API Key not found. Please run the 'Secure Input' cell first.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "gemini_model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "# --- ALL-DISEASE INDEX (diabetes + cancer + Alzheimer‚Äôs + asthma + cardiovascular) ---\n",
        "BASE = \"/content/drive/.shortcut-targets-by-id/1-SiVJhXHTHtDYSrPmW_0VfuP7gSTePcj/data\"\n",
        "CHUNK_PATH = f\"{BASE}/clinical_trials_all_full_chunk_map.json\"\n",
        "FAISS_PATH = f\"{BASE}/clinical_trials_all_full_faiss.index\"\n",
        "\n",
        "# Load embedding model, FAISS index, and chunk metadata\n",
        "embed_model, faiss_index, chunk_map = load_data_and_index(CHUNK_PATH, FAISS_PATH)\n",
        "\n",
        "# --- Reranker Initialization ---\n",
        "reranker = None\n",
        "if CrossEncoder:\n",
        "    try:\n",
        "        print(\"‚è≥ Loading Reranker Model (Cross-Encoder)...\")\n",
        "        reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "        print(\"‚úÖ Reranker Loaded.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Reranker model download failed (using pure FAISS): {e}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PARSER\n",
        "# ============================================================\n",
        "class SymptomParser:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def parse(self, text: str):\n",
        "        \"\"\"\n",
        "        Enhanced parser for clinical trial search queries.\n",
        "        Decides:\n",
        "        - Are they searching for trials or just asking a question?\n",
        "        - Which disease (diabetes, cancer, Alzheimer‚Äôs, asthma, cardiovascular) is implied?\n",
        "        \"\"\"\n",
        "        prompt = (\n",
        "            \"You are a clinical trial search classifier for medical research.\\n\"\n",
        "            \"You support conditions including diabetes, cancer, Alzheimer's disease, asthma, and cardiovascular disease.\\n\\n\"\n",
        "            f\"User Input: \\\"{text}\\\"\\n\\n\"\n",
        "            \"Your tasks:\\n\"\n",
        "            \"1) Decide if the user is searching for clinical trials or just asking a general question.\\n\"\n",
        "            \"2) Detect which disease(s) they are talking about.\\n\"\n",
        "            \"3) Detect if the query is not about health or clinical trials (off_topic).\\n\\n\"\n",
        "            \"Classification Rules:\\n\"\n",
        "            \"- If the query mentions or implies trials, studies, research, clinical experiments, etc. ‚Üí intent='trial_search'\\n\"\n",
        "            \"- If the user is mainly describing themselves (age, diagnosis, comorbidities, meds) ‚Üí intent='profile_info'\\n\"\n",
        "            \"- If they ask 'what is X', 'how does Y work', etc. without asking about trials ‚Üí intent='general_question'\\n\"\n",
        "            \"- Simple greetings (hi, hello, hey) ‚Üí intent='greeting'\\n\"\n",
        "            \"- If clearly not about health or clinical research ‚Üí intent='off_topic', is_disease_related=false\\n\\n\"\n",
        "            \"You must detect disease_focus whenever possible:\\n\"\n",
        "            \"- diabetes: diabetes, blood sugar, glucose, insulin, HbA1c, metformin, GLP-1, SGLT2\\n\"\n",
        "            \"- cancer: cancer, tumor/tumour, chemotherapy, oncology, breast cancer, lung cancer, leukemia, lymphoma\\n\"\n",
        "            \"- alzheimers: Alzheimer's, dementia, memory loss, cognitive decline\\n\"\n",
        "            \"- asthma: asthma, wheezing, bronchodilator, inhaler\\n\"\n",
        "            \"- cardiovascular: heart failure, cardiovascular disease, hypertension, high blood pressure, angina,\\n\"\n",
        "            \"  myocardial infarction, coronary artery disease, stroke\\n\\n\"\n",
        "            \"Return ONLY valid JSON with this exact format:\\n\"\n",
        "            \"{\\n\"\n",
        "            \"  \\\"intent\\\": \\\"trial_search\\\" | \\\"profile_info\\\" | \\\"general_question\\\" | \\\"greeting\\\" | \\\"off_topic\\\",\\n\"\n",
        "            \"  \\\"query_type\\\": \\\"trial_query\\\" | \\\"profile_statement\\\" | \\\"knowledge_seeking\\\" | \\\"greeting\\\",\\n\"\n",
        "            \"  \\\"search_keywords\\\": [\\\"keyword1\\\", \\\"keyword2\\\"],\\n\"\n",
        "            \"  \\\"is_disease_related\\\": true or false,\\n\"\n",
        "            \"  \\\"disease_focus\\\": [\\\"diabetes\\\", \\\"cancer\\\", \\\"alzheimers\\\", \\\"asthma\\\", \\\"cardiovascular\\\"],\\n\"\n",
        "            \"  \\\"user_question\\\": \\\"the question in plain English\\\",\\n\"\n",
        "            \"  \\\"trial_interest\\\": \\\"what type of trial they want (diet, medication, technology, surgery, etc.)\\\"\\n\"\n",
        "            \"}\\n\\n\"\n",
        "            \"Examples:\\n\"\n",
        "            \"- 'What trials study liraglutide in diabetes?' ‚Üí intent='trial_search', query_type='trial_query',\\n\"\n",
        "            \"  is_disease_related=true, disease_focus=['diabetes'], search_keywords=['liraglutide']\\n\"\n",
        "            \"- 'My mom has breast cancer, are there trials?' ‚Üí intent='trial_search', disease_focus=['cancer']\\n\"\n",
        "            \"- 'I am 70 with memory loss and Alzheimer's' ‚Üí intent='profile_info', disease_focus=['alzheimers']\\n\"\n",
        "            \"- 'What is HbA1c?' ‚Üí intent='general_question', disease_focus=['diabetes']\\n\"\n",
        "            \"- 'What is the weather in Paris?' ‚Üí intent='off_topic', is_disease_related=false, disease_focus=[]\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            raw = (res.text or \"\").strip()\n",
        "            match = re.search(r\"\\{.*\\}\", raw, re.DOTALL)\n",
        "            if match:\n",
        "                parsed = json.loads(match.group(0))\n",
        "            else:\n",
        "                parsed = json.loads(raw)\n",
        "        except Exception:\n",
        "            # Fallback: simple heuristic if model fails\n",
        "            text_lower = text.lower()\n",
        "            disease_focus = []\n",
        "            if any(x in text_lower for x in [\"diabetes\", \"insulin\", \"glucose\", \"hba1c\", \"metformin\", \"glp-1\", \"sglt2\"]):\n",
        "                disease_focus.append(\"diabetes\")\n",
        "            if any(x in text_lower for x in [\"cancer\", \"tumor\", \"tumour\", \"chemo\", \"chemotherapy\", \"oncology\"]):\n",
        "                disease_focus.append(\"cancer\")\n",
        "            if any(x in text_lower for x in [\"alzheimer\", \"dementia\", \"memory loss\", \"cognitive decline\"]):\n",
        "                disease_focus.append(\"alzheimers\")\n",
        "            if \"asthma\" in text_lower or \"wheezing\" in text_lower:\n",
        "                disease_focus.append(\"asthma\")\n",
        "            if any(x in text_lower for x in [\"heart failure\", \"cardiovascular\", \"hypertension\",\n",
        "                                             \"high blood pressure\", \"angina\", \"myocardial\", \"coronary\", \"stroke\"]):\n",
        "                disease_focus.append(\"cardiovascular\")\n",
        "\n",
        "            if any(kw in text_lower for kw in [\"trial\", \"study\", \"research\", \"clinical\"]):\n",
        "                intent = \"trial_search\"\n",
        "                query_type = \"trial_query\"\n",
        "            elif any(kw in text_lower for kw in [\"hi\", \"hello\", \"hey\"]):\n",
        "                intent = \"greeting\"\n",
        "                query_type = \"greeting\"\n",
        "            else:\n",
        "                intent = \"general_question\"\n",
        "                query_type = \"knowledge_seeking\"\n",
        "\n",
        "            parsed = {\n",
        "                \"intent\": intent,\n",
        "                \"query_type\": query_type,\n",
        "                \"search_keywords\": [text] if intent == \"trial_search\" else [],\n",
        "                \"is_disease_related\": bool(disease_focus),\n",
        "                \"disease_focus\": disease_focus,\n",
        "                \"user_question\": text,\n",
        "                \"trial_interest\": \"general\",\n",
        "            }\n",
        "\n",
        "        # --- Heuristic correction layer on top of model output ---\n",
        "        text_lower = text.lower()\n",
        "        diseases = set(parsed.get(\"disease_focus\") or [])\n",
        "\n",
        "        if any(x in text_lower for x in [\"diabetes\", \"insulin\", \"glucose\", \"hba1c\", \"metformin\", \"glp-1\", \"sglt2\"]):\n",
        "            diseases.add(\"diabetes\")\n",
        "        if any(x in text_lower for x in [\"cancer\", \"tumor\", \"tumour\", \"chemo\", \"chemotherapy\", \"oncology\"]):\n",
        "            diseases.add(\"cancer\")\n",
        "        if any(x in text_lower for x in [\"alzheimer\", \"alzheimers\", \"dementia\", \"memory loss\", \"cognitive decline\"]):\n",
        "            diseases.add(\"alzheimers\")\n",
        "        if \"asthma\" in text_lower or \"wheezing\" in text_lower or \"inhaler\" in text_lower:\n",
        "            diseases.add(\"asthma\")\n",
        "        if any(x in text_lower for x in [\"heart failure\", \"cardiovascular\", \"hypertension\",\n",
        "                                         \"high blood pressure\", \"angina\", \"myocardial\", \"coronary\", \"stroke\"]):\n",
        "            diseases.add(\"cardiovascular\")\n",
        "\n",
        "        parsed[\"disease_focus\"] = list(diseases)\n",
        "\n",
        "        # Force trial_search if obvious trial keywords\n",
        "        trial_keywords = [\n",
        "            \"trial\", \"study\", \"studies\", \"research\",\n",
        "            \"clinical\", \"show me\", \"are there\", \"what trials\"\n",
        "        ]\n",
        "        if any(kw in text_lower for kw in trial_keywords):\n",
        "            parsed[\"intent\"] = \"trial_search\"\n",
        "            parsed[\"query_type\"] = \"trial_query\"\n",
        "\n",
        "        # If we detected diseases, ensure is_disease_related = True\n",
        "        if diseases and parsed.get(\"intent\") != \"off_topic\":\n",
        "            parsed[\"is_disease_related\"] = True\n",
        "        elif \"is_disease_related\" not in parsed:\n",
        "            parsed[\"is_disease_related\"] = bool(diseases)\n",
        "\n",
        "        log = log_provenance_step(\"SymptomParser\", text, parsed)\n",
        "        return parsed, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PROFILE AGENT\n",
        "# ============================================================\n",
        "class ProfileAgent:\n",
        "    def __init__(self, initial_profile: Dict[str, Any] = None):\n",
        "        if initial_profile is None:\n",
        "            initial_profile = {\n",
        "                \"user_id\": \"Patient\",\n",
        "                \"conditions\": [],          # could be filled later\n",
        "                \"extracted_conditions\": [],  # dynamic memory\n",
        "                \"history\": [],\n",
        "            }\n",
        "        self.profile = initial_profile\n",
        "\n",
        "    def update_profile(self, turn_data: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Updates history and extracts persistent medical entities.\n",
        "        \"\"\"\n",
        "        self.profile.setdefault(\"history\", []).append(turn_data)\n",
        "        self.profile.setdefault(\"extracted_conditions\", [])\n",
        "\n",
        "        parsed = turn_data.get(\"parsed\", {})\n",
        "        # optional: keep disease_focus as conditions\n",
        "        diseases = parsed.get(\"disease_focus\") or []\n",
        "        if diseases:\n",
        "            current = set(self.profile[\"extracted_conditions\"])\n",
        "            for d in diseases:\n",
        "                current.add(d)\n",
        "            self.profile[\"extracted_conditions\"] = list(current)\n",
        "\n",
        "        snapshot = {\n",
        "            \"user_id\": self.profile.get(\"user_id\", \"Patient\"),\n",
        "            \"known_conditions\": self.profile.get(\"extracted_conditions\", []),\n",
        "            \"num_turns\": len(self.profile[\"history\"]),\n",
        "        }\n",
        "        log = log_provenance_step(\"ProfileAgent\", turn_data, {\"profile_snapshot\": snapshot})\n",
        "        return log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# EVIDENCE-WEIGHTED SCORER\n",
        "# ============================================================\n",
        "class EvidenceWeightedScorer:\n",
        "    \"\"\"\n",
        "    Implements evidence-weighted scoring for clinical trials.\n",
        "    Ranks trials based on multiple quality factors beyond semantic similarity.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.status_weights = {\n",
        "            \"Completed\": 1.0,\n",
        "            \"Active, Not Recruiting\": 0.9,\n",
        "            \"Recruiting\": 0.85,\n",
        "            \"Enrolling By Invitation\": 0.8,\n",
        "            \"Not Yet Recruiting\": 0.6,\n",
        "            \"Terminated\": 0.4,\n",
        "            \"Withdrawn\": 0.3,\n",
        "            \"Suspended\": 0.3,\n",
        "            \"Unknown Status\": 0.5,\n",
        "        }\n",
        "\n",
        "        self.design_keywords = {\n",
        "            \"randomized controlled\": 1.0,\n",
        "            \"double-blind\": 0.95,\n",
        "            \"randomized\": 0.9,\n",
        "            \"controlled\": 0.85,\n",
        "            \"interventional\": 0.8,\n",
        "            \"prospective\": 0.75,\n",
        "            \"observational\": 0.6,\n",
        "            \"retrospective\": 0.5,\n",
        "        }\n",
        "\n",
        "    def calculate_weighted_score(\n",
        "        self,\n",
        "        trial: Dict[str, Any],\n",
        "        base_confidence: float,\n",
        "        query: str,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Calculate evidence-weighted score for a trial.\n",
        "        \"\"\"\n",
        "\n",
        "        # Factor 1: Base semantic match (35%)\n",
        "        match_score = base_confidence * 0.35\n",
        "\n",
        "        # Factor 2: Trial status quality (25%)\n",
        "        status = str(trial.get(\"status\", \"Unknown Status\")).strip().title()\n",
        "        status_score = self.status_weights.get(status, 0.5) * 0.25\n",
        "\n",
        "        # Factor 3: Study design quality (20%)\n",
        "        design_score = self._calculate_design_quality(trial) * 0.20\n",
        "\n",
        "        # Factor 4: Keyword density (10%)\n",
        "        keyword_score = self._calculate_keyword_density(trial, query) * 0.10\n",
        "\n",
        "        # Factor 5: Metadata completeness (10%)\n",
        "        completeness_score = self._calculate_completeness(trial) * 0.10\n",
        "\n",
        "        weighted_score = (\n",
        "            match_score +\n",
        "            status_score +\n",
        "            design_score +\n",
        "            keyword_score +\n",
        "            completeness_score\n",
        "        )\n",
        "\n",
        "        breakdown = {\n",
        "            \"base_confidence\": base_confidence,\n",
        "            \"weighted_score\": weighted_score,\n",
        "            \"factors\": {\n",
        "                \"semantic_match\": match_score,\n",
        "                \"trial_status\": status_score,\n",
        "                \"study_design\": design_score,\n",
        "                \"keyword_density\": keyword_score,\n",
        "                \"completeness\": completeness_score,\n",
        "            },\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"weighted_score\": min(weighted_score, 1.0),\n",
        "            \"breakdown\": breakdown,\n",
        "        }\n",
        "\n",
        "    def _calculate_design_quality(self, trial: Dict[str, Any]) -> float:\n",
        "        text = f\"{trial.get('title', '')} {trial.get('text', '')}\".lower()\n",
        "        max_score = 0.0\n",
        "        for keyword, weight in self.design_keywords.items():\n",
        "            if keyword in text:\n",
        "                max_score = max(max_score, weight)\n",
        "        return max_score if max_score > 0 else 0.6\n",
        "\n",
        "    def _calculate_keyword_density(self, trial: Dict[str, Any], query: str) -> float:\n",
        "        text = f\"{trial.get('title', '')} {trial.get('text', '')}\".lower()\n",
        "        stopwords = {\n",
        "            \"the\", \"a\", \"an\", \"and\", \"or\", \"for\", \"with\", \"in\", \"on\", \"at\", \"to\",\n",
        "            \"of\", \"is\", \"are\", \"what\", \"trials\", \"trial\", \"study\", \"studies\", \"clinical\"\n",
        "        }\n",
        "        query_terms = [\n",
        "            term for term in query.lower().split()\n",
        "            if term not in stopwords and len(term) > 2\n",
        "        ]\n",
        "        if not query_terms:\n",
        "            return 0.5\n",
        "        matches = sum(1 for term in query_terms if term in text)\n",
        "        density = matches / len(query_terms)\n",
        "        return min(density, 1.0)\n",
        "\n",
        "    def _calculate_completeness(self, trial: Dict[str, Any]) -> float:\n",
        "        # Our chunk_map has \"title\" and \"text\"; treat longer text as more complete\n",
        "        text = trial.get(\"text\", \"\") or \"\"\n",
        "        title = trial.get(\"title\", \"\") or \"\"\n",
        "        score = 0.0\n",
        "        if len(title) > 10:\n",
        "            score += 0.3\n",
        "        if len(text) > 200:\n",
        "            score += 0.7\n",
        "        return min(score, 1.0)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PubMed Helper (NCT ‚Üí PubMed abstract)\n",
        "# ============================================================\n",
        "def fetch_pubmed_abstract_for_nct(nct_id: str):\n",
        "    \"\"\"\n",
        "    Try to find a PubMed article linked to this NCT ID and return its abstract.\n",
        "    Returns: {\"pmid\": str, \"abstract\": str} or None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        esearch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "        params = {\n",
        "            \"db\": \"pubmed\",\n",
        "            \"term\": f\"{nct_id}[si]\",\n",
        "            \"retmode\": \"json\",\n",
        "            \"retmax\": 1,\n",
        "        }\n",
        "        r = requests.get(esearch_url, params=params, timeout=10)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        idlist = data.get(\"esearchresult\", {}).get(\"idlist\", [])\n",
        "        if not idlist:\n",
        "            return None\n",
        "\n",
        "        pmid = idlist[0]\n",
        "\n",
        "        efetch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "        params = {\n",
        "            \"db\": \"pubmed\",\n",
        "            \"id\": pmid,\n",
        "            \"rettype\": \"abstract\",\n",
        "            \"retmode\": \"text\",\n",
        "        }\n",
        "        r2 = requests.get(efetch_url, params=params, timeout=10)\n",
        "        r2.raise_for_status()\n",
        "        abstract_text = r2.text.strip()\n",
        "        if not abstract_text:\n",
        "            return None\n",
        "\n",
        "        return {\"pmid\": pmid, \"abstract\": abstract_text}\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# RETRIEVAL AGENT\n",
        "# ============================================================\n",
        "class RetrievalAgent:\n",
        "    def __init__(self, embed_model, faiss_index, chunk_map, profile_agent: ProfileAgent = None):\n",
        "        self.embed_model = embed_model\n",
        "        self.index = faiss_index\n",
        "        self.chunk_map = chunk_map\n",
        "        self.profile_agent = profile_agent\n",
        "        self.evidence_scorer = EvidenceWeightedScorer()\n",
        "\n",
        "    def retrieve(self, parsed: Dict[str, Any], top_k: int = 5):\n",
        "        FETCH_K = top_k * 3\n",
        "\n",
        "        symptoms = parsed.get(\"symptoms\") or []\n",
        "        context = parsed.get(\"context\") or \"\"\n",
        "        query = parsed.get(\"user_question\") or (\" \".join(symptoms) + \" \" + context).strip()\n",
        "\n",
        "        if not query:\n",
        "            retrieval = {\"query\": \"\", \"trials\": [], \"avg_confidence\": 0.0}\n",
        "            log = log_provenance_step(\"RetrievalAgent\", parsed, retrieval, {\"reason\": \"empty_query\"})\n",
        "            return retrieval, log\n",
        "\n",
        "        # Simple expansions (still useful across diseases)\n",
        "        EXPANSIONS = {\n",
        "            \"insulin\": \"insulin OR insulin therapy OR insulin treatment OR insulin pump\",\n",
        "            \"medication\": \"medication OR drug OR pharmaceutical OR pharmacological OR treatment\",\n",
        "            \"diet\": \"diet OR dietary OR nutrition OR nutritional OR eating\",\n",
        "            \"exercise\": \"exercise OR physical activity OR fitness OR activity\",\n",
        "            \"chemo\": \"chemotherapy OR antineoplastic OR oncology\",\n",
        "            \"cancer\": \"cancer OR tumor OR tumour OR malignancy OR oncology\",\n",
        "            \"alzheim\": \"alzheimer OR dementia OR cognitive decline OR memory loss\",\n",
        "        }\n",
        "\n",
        "        query_lower = query.lower()\n",
        "        for term, expansion in EXPANSIONS.items():\n",
        "            if term in query_lower:\n",
        "                query = f\"{query} {expansion}\"\n",
        "                break\n",
        "\n",
        "        # 1. FAISS retrieval\n",
        "        q_emb = self.embed_model.encode([query])\n",
        "        distances, indices = self.index.search(q_emb.astype(\"float32\"), FETCH_K)\n",
        "\n",
        "        initial_candidates = []\n",
        "        for rank, idx in enumerate(indices[0]):\n",
        "            if idx == -1:\n",
        "                continue\n",
        "            item = self.chunk_map[idx]\n",
        "            dist = float(distances[0][rank])\n",
        "            initial_candidates.append({\n",
        "                \"nct_id\": item[\"nct_id\"],\n",
        "                \"title\": item.get(\"title\", \"\"),\n",
        "                \"text\": item[\"text\"],\n",
        "                \"status\": item.get(\"status\", \"Unknown Status\"),\n",
        "                \"faiss_dist\": dist,\n",
        "            })\n",
        "\n",
        "        final_trials = []\n",
        "        confs = []\n",
        "\n",
        "        # 2. Optional CrossEncoder reranking\n",
        "        if reranker and initial_candidates:\n",
        "            pairs = [[query, cand[\"text\"]] for cand in initial_candidates]\n",
        "            scores = reranker.predict(pairs)\n",
        "\n",
        "            for i, cand in enumerate(initial_candidates):\n",
        "                cand[\"rerank_score\"] = float(scores[i])\n",
        "\n",
        "            initial_candidates.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                logit = item[\"rerank_score\"]\n",
        "                base_conf = 1 / (1 + np.exp(-logit))\n",
        "\n",
        "                scoring_result = self.evidence_scorer.calculate_weighted_score(\n",
        "                    trial=item,\n",
        "                    base_confidence=base_conf,\n",
        "                    query=query,\n",
        "                )\n",
        "\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"title\"],\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": base_conf,\n",
        "                    \"weighted_score\": scoring_result[\"weighted_score\"],\n",
        "                    \"score_breakdown\": scoring_result[\"breakdown\"],\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"evidence_weighted\",\n",
        "                })\n",
        "\n",
        "            final_trials.sort(key=lambda x: x[\"weighted_score\"], reverse=True)\n",
        "            for i, trial in enumerate(final_trials):\n",
        "                trial[\"rank\"] = i + 1\n",
        "\n",
        "            confs = [t[\"weighted_score\"] for t in final_trials]\n",
        "\n",
        "        else:\n",
        "            # FAISS-only path\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                base_conf = calculate_confidence_score(item[\"faiss_dist\"])\n",
        "                scoring_result = self.evidence_scorer.calculate_weighted_score(\n",
        "                    trial=item,\n",
        "                    base_confidence=base_conf,\n",
        "                    query=query,\n",
        "                )\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"title\"],\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": base_conf,\n",
        "                    \"weighted_score\": scoring_result[\"weighted_score\"],\n",
        "                    \"score_breakdown\": scoring_result[\"breakdown\"],\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"evidence_weighted_faiss\",\n",
        "                })\n",
        "\n",
        "            final_trials.sort(key=lambda x: x[\"weighted_score\"], reverse=True)\n",
        "            for i, trial in enumerate(final_trials):\n",
        "                trial[\"rank\"] = i + 1\n",
        "\n",
        "            confs = [t[\"weighted_score\"] for t in final_trials]\n",
        "\n",
        "        avg_conf = float(np.mean(confs)) if confs else 0.0\n",
        "\n",
        "        retrieval = {\n",
        "            \"query\": query,\n",
        "            \"trials\": final_trials,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "        }\n",
        "\n",
        "        detail = {\n",
        "            \"top_k\": top_k,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"num_trials\": len(final_trials),\n",
        "            \"method\": \"reranked\" if reranker else \"faiss_only\",\n",
        "        }\n",
        "\n",
        "        log = log_provenance_step(\"RetrievalAgent\", parsed, retrieval, detail)\n",
        "        return retrieval, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# DIAGNOSIS / ADVISOR\n",
        "# ============================================================\n",
        "class DiagnosisAdvisor:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def _handle_general_question(self, parsed: Dict[str, Any], retrieved: Dict[str, Any]):\n",
        "        \"\"\"Handle general medical knowledge questions.\"\"\"\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        user_question = parsed.get(\"user_question\") or \" \".join(parsed.get(\"symptoms\", []))\n",
        "\n",
        "        evidence_parts = []\n",
        "        for t in trials[:3]:\n",
        "            evidence_parts.append(f\"Trial {t['nct_id']}: {t['text'][:400]}\")\n",
        "        evidence = \"\\n\\n\".join(evidence_parts) if evidence_parts else \"No specific trials available.\"\n",
        "\n",
        "        prompt = (\n",
        "            \"You are a medical research educator. Answer the user's question clearly using reliable medical knowledge.\\n\"\n",
        "            \"The clinical trial evidence below provides real-world context - mention it if helpful.\\n\\n\"\n",
        "            f\"USER'S QUESTION: {user_question}\\n\\n\"\n",
        "            \"CLINICAL TRIAL CONTEXT (for reference only):\\n\"\n",
        "            f\"{evidence}\\n\\n\"\n",
        "            \"Instructions:\\n\"\n",
        "            \"- Answer the question directly in 3‚Äì5 sentences.\\n\"\n",
        "            \"- Be specific and educational.\\n\"\n",
        "            \"- Do NOT give diagnoses or treatment instructions.\\n\"\n",
        "            \"- End with: 'For personalized advice, please consult your healthcare provider.'\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            text = (res.text or \"\").strip()\n",
        "            if not text or len(text) < 50:\n",
        "                text = (\n",
        "                    \"I don't have enough information to answer this question accurately. \"\n",
        "                    \"For personalized guidance, please consult your healthcare provider.\"\n",
        "                )\n",
        "            return text\n",
        "        except Exception:\n",
        "            return (\n",
        "                \"I'm unable to generate a detailed answer right now. \"\n",
        "                \"For personalized guidance, please consult your healthcare provider.\"\n",
        "            )\n",
        "\n",
        "    def _handle_symptom_query(\n",
        "        self,\n",
        "        parsed: Dict[str, Any],\n",
        "        retrieved: Dict[str, Any],\n",
        "        profile: Dict[str, Any],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Generate response for clinical trial search queries with\n",
        "        readable paragraph summaries and PubMed abstracts when available.\n",
        "        \"\"\"\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        if not trials:\n",
        "            return \"No relevant trials were found. Please try refining your query.\"\n",
        "\n",
        "        formatted_trials = []\n",
        "        for t in trials[:5]:\n",
        "            title = t.get(\"title\", \"\") or t[\"text\"].split(\"\\n\")[0].replace(\"Title: \", \"\")\n",
        "            status = t.get(\"status\", \"Unknown\")\n",
        "            weighted_score = t.get(\"weighted_score\", 0.0)\n",
        "\n",
        "            # Extract the ClinicalTrials.gov summary text\n",
        "            raw_text = t.get(\"text\", \"\")\n",
        "            brief_summary = raw_text.split(\"Summary:\", 1)[-1].strip() if \"Summary:\" in raw_text else raw_text\n",
        "\n",
        "            if brief_summary:\n",
        "                # Ask Gemini to turn the CT.gov summary into a short paragraph\n",
        "                prompt = (\n",
        "                    \"Rewrite the following clinical trial description as a short, clear paragraph \"\n",
        "                    \"about what the study is testing:\\n\\n\"\n",
        "                    f\"{brief_summary}\\n\\n\"\n",
        "                    \"Guidelines:\\n\"\n",
        "                    \"- Use 2‚Äì4 sentences.\\n\"\n",
        "                    \"- Plain English, minimal jargon.\\n\"\n",
        "                    \"- Include the purpose and the main type of participant.\\n\"\n",
        "                )\n",
        "                try:\n",
        "                    res = self.model.generate_content(prompt)\n",
        "                    brief_summary = res.text.strip() if res.text else brief_summary\n",
        "                except Exception:\n",
        "                    if len(brief_summary) > 600:\n",
        "                        brief_summary = brief_summary[:600] + \"...\"\n",
        "            else:\n",
        "                brief_summary = \"No summary available.\"\n",
        "\n",
        "            # PubMed abstract lookup\n",
        "            pubmed_block = \"\"\n",
        "            pub = fetch_pubmed_abstract_for_nct(t[\"nct_id\"])\n",
        "            if pub:\n",
        "                abs_text = pub[\"abstract\"]\n",
        "                max_len = 2000\n",
        "                if len(abs_text) > max_len:\n",
        "                    abs_text = abs_text[:max_len] + \"...\"\n",
        "                pubmed_block = (\n",
        "                    f\"  PubMed abstract (PMID {pub['pmid']}):\\n\"\n",
        "                    f\"  {abs_text}\\n\\n\"\n",
        "                    f\"  PubMed link: https://pubmed.ncbi.nlm.nih.gov/{pub['pmid']}/\\n\\n\"\n",
        "                )\n",
        "\n",
        "            formatted_trials.append(\n",
        "                f\"**{t['nct_id']}** (Relevance: {weighted_score:.0%})\\n\"\n",
        "                f\"‚Ä¢ {title}\\n\"\n",
        "                f\"  Status: {status}\\n\\n\"\n",
        "                f\"  {brief_summary}\\n\\n\"\n",
        "                f\"{pubmed_block}\"\n",
        "            )\n",
        "\n",
        "        trials_text = \"\\n\\n\".join(formatted_trials)\n",
        "        num_trials = len(formatted_trials)\n",
        "\n",
        "        response = (\n",
        "            f\"I found {num_trials} clinical trial{'s' if num_trials != 1 else ''} relevant to your request:\\n\\n\"\n",
        "            f\"{trials_text}\\n\\n\"\n",
        "            \"Summary: These trials explore potential treatments or management strategies for the condition you asked about. \"\n",
        "            \"More details are available using the listed NCT IDs.\\n\\n\"\n",
        "            \"To learn more or consider participation, visit clinicaltrials.gov and search by NCT ID. \"\n",
        "            \"Always discuss clinical trial options with your healthcare provider.\"\n",
        "        )\n",
        "\n",
        "        return response\n",
        "\n",
        "    def advise(self, parsed: Dict[str, Any], retrieved: Dict[str, Any], profile: Dict[str, Any]):\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        avg_conf = retrieved.get(\"avg_confidence\", 0.0)\n",
        "        query_type = parsed.get(\"query_type\", \"trial_query\")\n",
        "        is_disease_related = parsed.get(\"is_disease_related\", True)\n",
        "\n",
        "        draft = {\n",
        "            \"recommendation\": \"\",\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"query_type\": query_type,\n",
        "        }\n",
        "\n",
        "        if not is_disease_related:\n",
        "            draft[\"recommendation\"] = (\n",
        "                \"I‚Äôm specialized in clinical trials for medical conditions (for example diabetes, cancer, \"\n",
        "                \"Alzheimer‚Äôs disease, asthma, and cardiovascular diseases). \"\n",
        "                \"Your question does not appear to be about a health condition or clinical research. \"\n",
        "                \"If you‚Äôd like, you can ask me about trials for a specific condition.\"\n",
        "            )\n",
        "            draft[\"confidence_veto\"] = True\n",
        "            log = log_provenance_step(\n",
        "                \"DiagnosisAdvisor\",\n",
        "                parsed,\n",
        "                draft,\n",
        "                {\"veto\": True, \"reason\": \"off_topic\"},\n",
        "            )\n",
        "            return draft, log\n",
        "\n",
        "        if not trials or avg_conf < 0.05:\n",
        "            draft[\"recommendation\"] = (\n",
        "                \"Based on the trials I retrieved, I don‚Äôt have strong enough evidence to answer this question directly. \"\n",
        "                \"Please consult your healthcare provider for personalized advice.\"\n",
        "            )\n",
        "            draft[\"confidence_veto\"] = True\n",
        "            log = log_provenance_step(\n",
        "                \"DiagnosisAdvisor\",\n",
        "                parsed,\n",
        "                draft,\n",
        "                {\"veto\": True, \"reason\": \"low_confidence\"},\n",
        "            )\n",
        "            return draft, log\n",
        "\n",
        "        if query_type == \"knowledge_seeking\":\n",
        "            draft[\"recommendation\"] = self._handle_general_question(parsed, retrieved)\n",
        "        else:\n",
        "            draft[\"recommendation\"] = self._handle_symptom_query(parsed, retrieved, profile)\n",
        "\n",
        "        draft[\"confidence_veto\"] = False\n",
        "        log = log_provenance_step(\"DiagnosisAdvisor\", parsed, draft)\n",
        "        return draft, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SAFETY FILTER\n",
        "# ============================================================\n",
        "class ActiveSafetyFilter:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.safety_cfg = {\n",
        "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "        }\n",
        "\n",
        "    def verify(self, advice_text: str, trials: List[Dict[str, Any]]):\n",
        "        # Skip safety check for list-type responses about trials\n",
        "        if any(marker in advice_text for marker in [\"NCT\", \"clinical trial\", \"clinicaltrials.gov\"]):\n",
        "            log = log_provenance_step(\n",
        "                \"ActiveSafetyFilter\",\n",
        "                {\"advice\": advice_text},\n",
        "                {\"final_text\": advice_text, \"status\": \"Pass (Trial Listing)\"},\n",
        "            )\n",
        "            return advice_text, \"Pass (Trial Listing)\", log\n",
        "\n",
        "        evidence_text = \"\\n\".join(t[\"text\"][:500] for t in trials[:3])\n",
        "\n",
        "        audit_prompt = (\n",
        "            \"You are a Medical Safety Officer reviewing AI-generated advice.\\n\\n\"\n",
        "            \"ADVICE:\\n\"\n",
        "            f\"{advice_text}\\n\\n\"\n",
        "            \"EVIDENCE FROM CLINICAL TRIALS (for context):\\n\"\n",
        "            f\"{evidence_text}\\n\\n\"\n",
        "            \"Check for safety issues:\\n\"\n",
        "            \"- If the advice suggests starting/stopping/changing medication without a doctor ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it gives a diagnosis ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it makes strong clinical claims not supported by evidence ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it simply lists clinical trials with neutral wording and a recommendation to talk to a doctor ‚Üí SAFE.\\n\\n\"\n",
        "            \"If the advice is acceptable, respond with exactly: SAFE\\n\"\n",
        "            \"If it is not acceptable, respond starting with: CORRECTED: <safer version>\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(audit_prompt, safety_settings=self.safety_cfg)\n",
        "            txt = (res.text or \"\").strip()\n",
        "            if txt.startswith(\"SAFE\") or \"SAFE\" in txt:\n",
        "                final_text = advice_text\n",
        "                status = \"Pass\"\n",
        "            else:\n",
        "                final_text = f\"‚ö†Ô∏è SAFETY REVISION:\\n{txt}\"\n",
        "                status = \"Revised\"\n",
        "        except Exception:\n",
        "            if \"NCT\" in advice_text or \"clinical trial\" in advice_text.lower():\n",
        "                final_text = advice_text\n",
        "                status = \"Pass (API Fallback)\"\n",
        "            else:\n",
        "                final_text = \"‚ö†Ô∏è Safety filter triggered. Please consult a doctor.\"\n",
        "                status = \"Revised (API Error)\"\n",
        "\n",
        "        log = log_provenance_step(\n",
        "            \"ActiveSafetyFilter\",\n",
        "            {\"advice\": advice_text},\n",
        "            {\"final_text\": final_text, \"status\": status},\n",
        "        )\n",
        "        return final_text, status, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# HEALTHCARE BOT (Orchestrator)\n",
        "# ============================================================\n",
        "class HealthcareBot:\n",
        "    def __init__(self, gemini_model, embed_model, faiss_index, chunk_map, initial_profile=None):\n",
        "        self.parser = SymptomParser(gemini_model)\n",
        "        self.profile_agent = ProfileAgent(initial_profile)\n",
        "        self.retriever = RetrievalAgent(embed_model, faiss_index, chunk_map, self.profile_agent)\n",
        "        self.advisor = DiagnosisAdvisor(gemini_model)\n",
        "        self.safety = ActiveSafetyFilter(gemini_model)\n",
        "\n",
        "        self.history: List[Dict[str, Any]] = []\n",
        "        self.provenance_chain: List[Dict[str, Any]] = []\n",
        "\n",
        "    def _handle_simple_greeting(self, user_input: str):\n",
        "        user_id = self.profile_agent.profile.get(\"user_id\", \"there\")\n",
        "        msg = (\n",
        "            f\"Hello {user_id}! I'm your **Clinical Trial Research Assistant**. üî¨\\n\\n\"\n",
        "            \"I can help you explore clinical trials for conditions such as:\\n\"\n",
        "            \"- Diabetes\\n\"\n",
        "            \"- Cancer\\n\"\n",
        "            \"- Alzheimer's disease\\n\"\n",
        "            \"- Asthma\\n\"\n",
        "            \"- Cardiovascular disease\\n\\n\"\n",
        "            \"I search a database of tens of thousands of real trials (e.g., from ClinicalTrials.gov).\\n\\n\"\n",
        "            \"**You can ask things like:**\\n\"\n",
        "            \"- 'What trials are studying insulin therapy in diabetes?'\\n\"\n",
        "            \"- 'Are there breast cancer trials targeting HER2?'\\n\"\n",
        "            \"- 'Trials for memory loss and Alzheimer's?'\\n\"\n",
        "            \"- 'I'm 55 with type 2 diabetes, what trials can I join?'\\n\\n\"\n",
        "            \"What condition and question would you like to explore?\"\n",
        "        )\n",
        "\n",
        "        log = log_provenance_step(\"GreetingAgent\", user_input, msg, {\"type\": \"greeting\"})\n",
        "        self.provenance_chain.append(log)\n",
        "\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "        self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": msg,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Non-RAG\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "    def _handle_off_topic(self, user_input: str, parsed: Dict[str, Any]):\n",
        "        msg = (\n",
        "            \"I‚Äôm specialized in clinical trials for medical conditions (for example diabetes, cancer, \"\n",
        "            \"Alzheimer‚Äôs disease, asthma, and cardiovascular disease). \"\n",
        "            \"Your question doesn‚Äôt seem to be about a health condition or clinical research. \"\n",
        "            \"If you‚Äôd like, you can ask me to find trials for a specific condition.\"\n",
        "        )\n",
        "        log = log_provenance_step(\"OffTopicHandler\", user_input, msg, {\"type\": \"off_topic\"})\n",
        "        self.provenance_chain.append(log)\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": msg,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Off-topic\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "    def _handle_knowledge_question(self, user_input: str, parsed: Dict[str, Any]):\n",
        "        user_question = parsed.get(\"user_question\", user_input)\n",
        "        prompt = (\n",
        "            \"You are a medical research educator. Answer this question clearly and accurately in 3‚Äì6 sentences.\\n\"\n",
        "            \"Do NOT give diagnoses or individual treatment instructions.\\n\"\n",
        "            f\"QUESTION: {user_question}\\n\"\n",
        "            \"End with: 'For personalized advice, please consult your healthcare provider.'\\n\"\n",
        "        )\n",
        "        try:\n",
        "            res = self.advisor.model.generate_content(prompt)\n",
        "            answer = (res.text or \"\").strip()\n",
        "        except Exception:\n",
        "            answer = \"I'm unable to answer this right now. For personalized advice, please consult your healthcare provider.\"\n",
        "\n",
        "        log = log_provenance_step(\"KnowledgeAgent\", user_input, answer, {\"type\": \"general_knowledge\"})\n",
        "        self.provenance_chain.append(log)\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": answer,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Knowledge-Based\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "    def _handle_generic_trial_query(self, user_input: str, parsed: Dict[str, Any]):\n",
        "        \"\"\"Handle very generic queries that need more specificity.\"\"\"\n",
        "        msg = (\n",
        "            \"That question is a bit broad. I have a large database of clinical trials across conditions like \"\n",
        "            \"diabetes, cancer, Alzheimer's, asthma, and cardiovascular disease.\\n\\n\"\n",
        "            \"To help you better, you can specify:\\n\\n\"\n",
        "            \"**Example trial searches by condition**\\n\"\n",
        "            \"- Diabetes: 'trials testing new insulin pumps', 'GLP-1 diabetes trials'\\n\"\n",
        "            \"- Cancer: 'HER2-positive breast cancer trials', 'lung cancer immunotherapy trials'\\n\"\n",
        "            \"- Alzheimer‚Äôs: 'trials for early Alzheimer‚Äôs disease', 'memory loss drug trials'\\n\"\n",
        "            \"- Asthma: 'pediatric asthma trials', 'new inhaler trials'\\n\"\n",
        "            \"- Cardiovascular: 'heart failure trials', 'hypertension drug trials'\\n\\n\"\n",
        "            \"**Or describe your situation:**\\n\"\n",
        "            \"- 'I have type 2 diabetes and obesity, what trials might fit me?'\\n\"\n",
        "            \"- 'My father has metastatic lung cancer, any trials?'\\n\\n\"\n",
        "            \"What condition and type of trial are you most interested in?\"\n",
        "        )\n",
        "\n",
        "        log = log_provenance_step(\"GenericQueryHandler\", user_input, msg, {\"type\": \"needs_refinement\"})\n",
        "        self.provenance_chain.append(log)\n",
        "\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "        self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": msg,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Refinement Needed\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "    def _handle_missing_disease(self, user_input: str, parsed: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Fallback A (your choice): If we can't detect any disease,\n",
        "        ask the user to specify the condition explicitly.\n",
        "        \"\"\"\n",
        "        msg = (\n",
        "            \"I can search clinical trials for conditions such as diabetes, cancer, Alzheimer's disease, \"\n",
        "            \"asthma, and cardiovascular disease.\\n\\n\"\n",
        "            \"I couldn‚Äôt clearly tell which condition you meant from your last message.\\n\\n\"\n",
        "            \"Please tell me which condition you‚Äôre interested in and, if you‚Äôd like, what type of trial.\\n\"\n",
        "            \"For example:\\n\"\n",
        "            \"- 'Diabetes ‚Äì trials for new insulin therapies'\\n\"\n",
        "            \"- 'Breast cancer ‚Äì HER2 targeted trials'\\n\"\n",
        "            \"- 'Alzheimer‚Äôs ‚Äì early-stage drug trials'\\n\"\n",
        "            \"- 'Asthma ‚Äì trials for severe asthma in adults'\\n\"\n",
        "        )\n",
        "        log = log_provenance_step(\"MissingDiseaseHandler\", user_input, msg, {\"type\": \"missing_disease\"})\n",
        "        self.provenance_chain.append(log)\n",
        "\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "        self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": msg,\n",
        "            \"cited_trials\": [],\n",
        "            \"safety_status\": \"Clarification Needed\",\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "    def process_query(self, user_input: str):\n",
        "        self.provenance_chain = []\n",
        "\n",
        "        # 1. Parse\n",
        "        parsed, parse_log = self.parser.parse(user_input)\n",
        "        self.provenance_chain.append(parse_log)\n",
        "\n",
        "        intent = (parsed.get(\"intent\") or \"trial_search\").lower()\n",
        "        query_type = parsed.get(\"query_type\", \"trial_query\")\n",
        "        is_disease_related = parsed.get(\"is_disease_related\", True)\n",
        "        disease_focus = parsed.get(\"disease_focus\") or []\n",
        "\n",
        "        # Greetings\n",
        "        if intent == \"greeting\":\n",
        "            return self._handle_simple_greeting(user_input)\n",
        "\n",
        "        # Off-topic\n",
        "        if intent == \"off_topic\" or not is_disease_related:\n",
        "            return self._handle_off_topic(user_input, parsed)\n",
        "\n",
        "        # Profile info\n",
        "        if intent == \"profile_info\":\n",
        "            msg = (\n",
        "                \"Thank you for sharing your information. I've noted your details conceptually. \"\n",
        "                \"What type of clinical trials would you like to explore? \"\n",
        "                \"For example: 'diabetes trials for new medications' or 'breast cancer trials for HER2-positive disease'.\"\n",
        "            )\n",
        "            log = log_provenance_step(\"ProfileAgent\", user_input, msg, {\"action\": \"profile_stored\"})\n",
        "            self.provenance_chain.append(log)\n",
        "\n",
        "            session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "            return {\n",
        "                \"recommendation\": msg,\n",
        "                \"cited_trials\": [],\n",
        "                \"safety_status\": \"Profile Update\",\n",
        "                \"session_hash\": session_hash,\n",
        "                \"provenance_chain\": self.provenance_chain,\n",
        "            }\n",
        "\n",
        "        # Pure education (no trial search)\n",
        "        if intent == \"general_question\" and query_type == \"knowledge_seeking\":\n",
        "            if \"trial\" not in user_input.lower() and \"study\" not in user_input.lower():\n",
        "                return self._handle_knowledge_question(user_input, parsed)\n",
        "\n",
        "        # Fallback A: no disease detected ‚Üí ask user to specify condition\n",
        "        if not disease_focus:\n",
        "            return self._handle_missing_disease(user_input, parsed)\n",
        "\n",
        "        # DEFAULT: trial search\n",
        "        retrieved, retrieve_log = self.retriever.retrieve(parsed)\n",
        "        self.provenance_chain.append(retrieve_log)\n",
        "\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        avg_conf = retrieved.get(\"avg_confidence\", 0.0)\n",
        "        top_score = trials[0][\"weighted_score\"] if trials else 0.0\n",
        "\n",
        "        # Generic query detection (very broad wording)\n",
        "        generic_terms = [\"new\", \"any\", \"some\", \"recent\", \"latest\", \"medications\", \"drugs\", \"treatments\", \"trials\", \"studies\"]\n",
        "        is_generic = sum(1 for term in generic_terms if term in user_input.lower()) >= 2\n",
        "\n",
        "        if is_generic and (avg_conf < 0.50 or top_score < 0.55):\n",
        "            return self._handle_generic_trial_query(user_input, parsed)\n",
        "\n",
        "        # 3. Advisor\n",
        "        draft_advice, advise_log = self.advisor.advise(parsed, retrieved, self.profile_agent.profile)\n",
        "        self.provenance_chain.append(advise_log)\n",
        "\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        if draft_advice.get(\"confidence_veto\", False) or not trials:\n",
        "            final_text = draft_advice[\"recommendation\"]\n",
        "            safety_status = \"Vetoed (Low Confidence)\"\n",
        "            evidence_list = []\n",
        "        else:\n",
        "            final_text, safety_status, safety_log = self.safety.verify(draft_advice[\"recommendation\"], trials)\n",
        "            self.provenance_chain.append(safety_log)\n",
        "            evidence_list = trials\n",
        "\n",
        "        nct_ids = [t[\"nct_id\"] for t in evidence_list]\n",
        "        session_hash = generate_reproducibility_hash(self.history + [{\"query\": user_input}])\n",
        "\n",
        "        # Update profile/history\n",
        "        turn_data = {\n",
        "            \"query\": user_input,\n",
        "            \"parsed\": parsed,\n",
        "            \"nct_ids\": nct_ids,\n",
        "            \"safety_status\": safety_status,\n",
        "            \"session_hash\": session_hash,\n",
        "        }\n",
        "        profile_log = self.profile_agent.update_profile(turn_data)\n",
        "        self.provenance_chain.append(profile_log)\n",
        "        self.history.append({\"query\": user_input, \"response_hash\": session_hash})\n",
        "\n",
        "        return {\n",
        "            \"recommendation\": final_text,\n",
        "            \"cited_trials\": nct_ids,\n",
        "            \"safety_status\": safety_status,\n",
        "            \"session_hash\": session_hash,\n",
        "            \"provenance_chain\": self.provenance_chain,\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# GLOBAL BOT INSTANCE + ENTRYPOINT\n",
        "# ============================================================\n",
        "default_profile = {\n",
        "    \"user_id\": \"Patient\",\n",
        "    \"conditions\": [],\n",
        "    \"extracted_conditions\": [],\n",
        "}\n",
        "\n",
        "_bot = HealthcareBot(gemini_model, embed_model, faiss_index, chunk_map, initial_profile=default_profile)\n",
        "\n",
        "def run_bot(user_input: str) -> Dict[str, Any]:\n",
        "    return _bot.process_query(user_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDxpjMNrCwCA"
      },
      "source": [
        "UI frontend application simple web interface\n",
        "\n",
        "https://docs.streamlit.io/develop/tutorials/chat-and-llm-apps/build-conversational-apps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EqkmxVqOkZ-",
        "outputId": "9dbd29f0-3ae7-4388-d8f0-a849dcf2d29b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import importlib\n",
        "import run_bot  # import module not function\n",
        "\n",
        "# Force reload of run_bot.py so Streamlit uses updated code\n",
        "importlib.reload(run_bot)\n",
        "\n",
        "st.title(\"Clinical Trial Health Advisor ü§ñ\")\n",
        "st.caption(\"AI for Healthcare - Clinical Trials RAG\")\n",
        "\n",
        "# API Key validation\n",
        "if \"GEMINI_API_KEY\" not in os.environ:\n",
        "    st.error(\"‚ö†Ô∏è API Key missing! Please run the 'Secure Input' cell in the notebook first.\")\n",
        "    st.stop()\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Load previous chat history\n",
        "for msg in st.session_state.messages:\n",
        "    with st.chat_message(msg[\"role\"]):\n",
        "        st.markdown(msg[\"content\"])\n",
        "\n",
        "# Chat input\n",
        "if user_input := st.chat_input(\"Describe your symptoms or ask about clinical trials...\"):\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(user_input)\n",
        "\n",
        "    with st.spinner(\"Searching clinical trials...\"):\n",
        "        # Call updated run_bot function\n",
        "        result = run_bot.run_bot(user_input)\n",
        "        reply = result.get(\"recommendation\", \"No response available.\")\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(reply)\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": reply})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5BcqHNUOklc"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 cloudflared\n",
        "!chmod +x cloudflared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZqn_TJIOkuT",
        "outputId": "c4baa821-2fb8-4384-b7ca-216588ff0a88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90m2025-11-28T00:40:08Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-11-28T00:40:08Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m |  https://lil-deployment-bit-mac.trycloudflare.com                                          |\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 991dffd8889ee9f0147b6b48933da9e4407e68ea8c6d984f55fa2d3db4bb431d)\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: b75e0fe6-5e4a-44ef-b01d-1fc843404661\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37\n",
            "2025/11/28 00:40:11 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-11-28T00:40:11Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m7106969e-30b9-4479-9af0-b1efd2ecd05d \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37 \u001b[36mlocation=\u001b[0matl12 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-11-28T00:41:36Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2025-11-28T00:41:36Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to run the datagram handler \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37\n",
            "\u001b[90m2025-11-28T00:41:36Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37\n",
            "\u001b[90m2025-11-28T00:41:36Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Serve tunnel error \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37\n",
            "\u001b[90m2025-11-28T00:41:36Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.37\n",
            "\u001b[90m2025-11-28T00:41:36Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Connection terminated \u001b[36mconnIndex=\u001b[0m0\n",
            "\u001b[90m2025-11-28T00:41:36Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2025-11-28T00:41:36Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2025-11-28T00:41:36Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ],
      "source": [
        "#AI LLM\n",
        "!streamlit run app.py &>/dev/null&\n",
        "!./cloudflared tunnel --url http://localhost:8501 --no-autoupdate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X6g_5EAH45ZG",
        "outputId": "0cd883d9-7498-4aa5-c465-c40502985d7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 596.17ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 252.85ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 203.00ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 205.07ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 205.35ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 328.83ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I found 5 clinical trials relevant to your request:\n",
            "\n",
            "**NCT04981808** (Relevance: 95%)\n",
            "‚Ä¢ Diabetes teleMonitoring of Patients in Insulin Therapy\n",
            "  Status: Completed\n",
            "\n",
            "  The trial is an open-label randomized controlled trial. Patients with T2D on insulin therapy will be randomized to a telemonitoring group (intervention) and a usual care group (control). The telemonitoring group will use various devices at home. Hospital staff will monitor their data for a period of three months.\n",
            "\n",
            "  PubMed abstract (PMID 36476605):\n",
            "  1. Trials. 2022 Dec 7;23(1):985. doi: 10.1186/s13063-022-06921-6.\n",
            "\n",
            "The Diabetes teleMonitoring of patients in insulin Therapy (DiaMonT) trial: \n",
            "study protocol for a randomized controlled trial.\n",
            "\n",
            "Hangaard S(1)(2), Kronborg T(3)(4), Hejlesen O(4), Arad√≥ttir TB(5), Kaas A(5), \n",
            "Bengtsson H(5), Vestergaard P(4)(6)(7), Jensen MH(3)(4).\n",
            "\n",
            "Author information:\n",
            "(1)Steno Diabetes Center North Denmark, M√∏lleparkvej 4, 9000, Aalborg, Denmark. \n",
            "svh@hst.aau.dk.\n",
            "(2)Department of Health Science and Technology, Aalborg University, Fredrik \n",
            "Bajers Vej 7C, 9220, Aalborg √ò, Denmark. svh@hst.aau.dk.\n",
            "(3)Steno Diabetes Center North Denmark, M√∏lleparkvej 4, 9000, Aalborg, Denmark.\n",
            "(4)Department of Health Science and Technology, Aalborg University, Fredrik \n",
            "Bajers Vej 7C, 9220, Aalborg √ò, Denmark.\n",
            "(5)Novo Nordisk A/S, Novo Alle 1, 2880, Bagsv√¶rd, Denmark.\n",
            "(6)Department of Endocrinology, Aalborg University Hospital, Aalborg, Denmark.\n",
            "(7)Department of Clinical Medicine, Aalborg University, Aalborg, Denmark.\n",
            "\n",
            "BACKGROUND: The effect of telemedicine solutions in diabetes remains \n",
            "inconclusive. However, telemedicine studies have shown a positive trend in \n",
            "regards to glycemic control. The telemedicine interventions that facilitate \n",
            "adjustment of medication seems to improve glycemic control more effectively. \n",
            "Hence, it is recommended that future telemedicine studies for patients with \n",
            "diabetes include patient-specific suggestions for changes in medicine. Hence, \n",
            "the aim of the trial is to explore the effect of telemonitoring in patients with \n",
            "type 2 diabetes (T2D) on insulin therapy.\n",
            "METHODS: The trial is an open-label randomized controlled trial with a trial \n",
            "period of 3 months conducted in two sites in Denmark. Patients with T2D on \n",
            "insulin therapy will be randomized (1:1) to a telemonitoring group \n",
            "(intervention) or a usual care group (control). The telemonitoring group will \n",
            "use a continuous glucose monitor (CGM), an insulin pen, an activity tracker, and \n",
            "smartphone applications throughout the tr...\n",
            "\n",
            "  PubMed link: https://pubmed.ncbi.nlm.nih.gov/36476605/\n",
            "\n",
            "\n",
            "\n",
            "**NCT00115973** (Relevance: 88%)\n",
            "‚Ä¢ A Study of the Treatment of Type 2 Diabetes With an Insulin Infusion Pump\n",
            "  Status: Completed\n",
            "\n",
            "  This trial is conducted in the United States of America (USA). This is an in-patient trial investigating stepwise dose increase in a period of up to 3-weeks followed by a 10-week out-patient maintenance period. A telephone contact visit is scheduled as a follow-up for the final clinic visit. A subject's participation in this trial would be expected to be up to 16 weeks.\n",
            "\n",
            "\n",
            "\n",
            "**NCT00115973** (Relevance: 88%)\n",
            "‚Ä¢ A Study of the Treatment of Type 2 Diabetes With an Insulin Infusion Pump\n",
            "  Status: Completed\n",
            "\n",
            "  This trial is conducted in the United States of America (USA). This is an in-patient trial investigating stepwise dose increase in a period of up to 3-weeks followed by a 10-week out-patient maintenance period. A telephone contact visit is scheduled as a follow-up for the final clinic visit. A subject's participation in this trial would be expected to be up to 16 weeks.\n",
            "\n",
            "\n",
            "\n",
            "**NCT00841919** (Relevance: 84%)\n",
            "‚Ä¢ Insulin Therapy in the Hospital Comparing Two Protocols\n",
            "  Status: Completed\n",
            "\n",
            "  The purpose of this study is to determine if by using insulin analog (Glargine and lispro insulin) with an insulin pen the investigators are able to obtain a higher rate of correct timing of insulin and food administration as when compared to the usual therapy (insulin NPH and regular) with syringes.\n",
            "\n",
            "  PubMed abstract (PMID 21454236):\n",
            "  1. Endocr Pract. 2011 Sep-Oct;17(5):737-46. doi: 10.4158/EP10358.OR.\n",
            "\n",
            "Insulin injections in relation to meals in the hospital medicine ward: \n",
            "comparison of 2 protocols.\n",
            "\n",
            "Guerra YS(1), Lacuesta EA, Yrastorza R, Miernik J, Shakya N, Fogelfeld L.\n",
            "\n",
            "Author information:\n",
            "(1)Division of Endocrinology, John H. Stroger Jr, Hospital of Cook County, \n",
            "Chicago, Illinois, USA. yannis_guerra@yahoo.com\n",
            "\n",
            "OBJECTIVE: To investigate whether changing the prandial regular insulin to \n",
            "rapid-acting insulin analogue in hospital medicine wards improves the timing of \n",
            "insulin delivery in relation to meals and improves patient safety and glucose \n",
            "control.\n",
            "METHODS: This open-label randomized controlled trial in type 2 diabetic patients \n",
            "compared insulin lispro with meals and basal insulin glargine (intervention) vs \n",
            "regular insulin before meals and basal neutral protamine Hagedorn insulin twice \n",
            "daily (control). The primary endpoint was the rate of targeted timing of insulin \n",
            "to meals (target time). In the intervention group, target time was defined as \n",
            "insulin administered from 15 minutes before to 15 minutes after the patient \n",
            "started a meal. For the control group, target time was defined as insulin \n",
            "administered from 30 minutes before to 30 minutes after the patient started a \n",
            "meal. Hypoglycemic, hyperglycemic, and severe hyperglycemic patient-days were \n",
            "compared between groups.\n",
            "RESULTS: Twenty-seven patients in the intervention group and thirty-three \n",
            "patients in the control group were studied. The percentage of times that the \n",
            "insulin was given within target time was significantly higher in the \n",
            "intervention group as a whole (88.9% vs 70.1%, P<.001) and was higher for lunch \n",
            "and the evening meal (90% vs 66.7% and 94.7% vs 70.1%, P<.001). The rate of \n",
            "hypoglycemia was lower in the intervention group (1.85% vs 15%, P<.001). The \n",
            "rate of hyperglycemia was similar in both groups (68.2% vs 59.8%, P = .224), but \n",
            "the intervention group had a higher rate of severe hyperglycemia (28.9% vs \n",
            "12.9%, P...\n",
            "\n",
            "  PubMed link: https://pubmed.ncbi.nlm.nih.gov/21454236/\n",
            "\n",
            "\n",
            "\n",
            "**NCT00841919** (Relevance: 84%)\n",
            "‚Ä¢ Insulin Therapy in the Hospital Comparing Two Protocols\n",
            "  Status: Completed\n",
            "\n",
            "  The purpose of this study is to determine if by using insulin analog (Glargine and lispro insulin) with an insulin pen the investigators are able to obtain a higher rate of correct timing of insulin and food administration as when compared to the usual therapy (insulin NPH and regular) with syringes.\n",
            "\n",
            "\n",
            "\n",
            "Summary: These trials explore potential treatments or management strategies for the condition you asked about. More details are available using the listed NCT IDs.\n",
            "\n",
            "To learn more or consider participation, visit clinicaltrials.gov and search by NCT ID. Always discuss clinical trial options with your healthcare provider.\n"
          ]
        }
      ],
      "source": [
        "response = run_bot(\"What trials are studying insulin therapy?\")\n",
        "print(response[\"recommendation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n0YC3I_p5u2n",
        "outputId": "08b2545d-17f4-4723-e2b8-14f4b333a0a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 607.47ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 202.57ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 202.71ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 177.81ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 278.80ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 202.91ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I found 5 clinical trials relevant to your request:\n",
            "\n",
            "**NCT00214526** (Relevance: 93%)\n",
            "‚Ä¢ Asthma Intervention Research (AIR) Trial\n",
            "  Status: Completed\n",
            "\n",
            "  The purpose of this study is to demonstrate the effectiveness and safety of the Alair System for the treatment of asthma.\n",
            "\n",
            "This will be a multicenter, randomized controlled study comparing the effects of treatment with the Alair System to standard drug therapy. One-hundred and ten subjects will be randomized 1:1 to either the Alair Group (Medical management + Alair treatment),or Control Group (Medical management only).\n",
            "\n",
            "  PubMed abstract (PMID 17392302):\n",
            "  1. N Engl J Med. 2007 Mar 29;356(13):1327-37. doi: 10.1056/NEJMoa064707.\n",
            "\n",
            "Asthma control during the year after bronchial thermoplasty.\n",
            "\n",
            "Cox G(1), Thomson NC, Rubin AS, Niven RM, Corris PA, Siersted HC, Olivenstein R, \n",
            "Pavord ID, McCormack D, Chaudhuri R, Miller JD, Laviolette M; AIR Trial Study \n",
            "Group.\n",
            "\n",
            "Author information:\n",
            "(1)St. Joseph's Healthcare, McMaster University, Hamilton, ON, Canada. \n",
            "coxp@mcmaster.ca\n",
            "\n",
            "Comment in\n",
            "    N Engl J Med. 2007 Mar 29;356(13):1367-9. doi: 10.1056/NEJMe078005.\n",
            "    N Engl J Med. 2007 Jun 28;356(26):2744; author reply 2745. doi: \n",
            "10.1056/NEJMc071166.\n",
            "    N Engl J Med. 2007 Jun 28;356(26):2745; author reply 2745.\n",
            "    N Engl J Med. 2007 Jun 28;356(26):2744; author reply 2745.\n",
            "\n",
            "BACKGROUND: Bronchial thermoplasty is a bronchoscopic procedure to reduce the \n",
            "mass of airway smooth muscle and attenuate bronchoconstriction. We examined the \n",
            "effect of bronchial thermoplasty on the control of moderate or severe persistent \n",
            "asthma.\n",
            "METHODS: We randomly assigned 112 subjects who had been treated with inhaled \n",
            "corticosteroids and long-acting beta2-adrenergic agonists (LABA) and in whom \n",
            "asthma control was impaired when the LABA were withdrawn to either bronchial \n",
            "thermoplasty or a control group. The primary outcome was the frequency of mild \n",
            "exacerbations, calculated during three scheduled 2-week periods of abstinence \n",
            "from LABA at 3, 6, and 12 months. Airflow, airway responsiveness, asthma \n",
            "symptoms, the number of symptom-free days, use of rescue medication, and scores \n",
            "on the Asthma Quality of Life Questionnaire (AQLQ) and the Asthma Control \n",
            "Questionnaire (ACQ) were also assessed.\n",
            "RESULTS: The mean rate of mild exacerbations, as compared with baseline, was \n",
            "reduced in the bronchial-thermoplasty group but was unchanged in the control \n",
            "group (change in frequency per subject per week, -0.16+/-0.37 vs. 0.04+/-0.29; \n",
            "P=0.005). At 12 months, there were significantly greater improvements in the \n",
            "bronchial-thermoplasty group than in the control group in ...\n",
            "\n",
            "  PubMed link: https://pubmed.ncbi.nlm.nih.gov/17392302/\n",
            "\n",
            "\n",
            "\n",
            "**NCT00214526** (Relevance: 93%)\n",
            "‚Ä¢ Asthma Intervention Research (AIR) Trial\n",
            "  Status: Completed\n",
            "\n",
            "  The purpose of this study is to demonstrate the effectiveness and safety of the Alair System for the treatment of asthma.\n",
            "\n",
            "This will be a multicenter, randomized controlled study comparing the effects of treatment with the Alair System to standard drug therapy. One-hundred and ten subjects will be randomized 1:1 to either the Alair Group (Medical management + Alair treatment),or Control Group (Medical management only).\n",
            "\n",
            "\n",
            "\n",
            "**NCT06388460** (Relevance: 87%)\n",
            "‚Ä¢ Asthma Link Effectiveness Trial\n",
            "  Status: Recruiting\n",
            "\n",
            "  The goal of this cluster Randomized Control Trial is to determine the effectiveness of Asthma Link, a school supervised asthma therapy program, compared with an educational asthma workbook, in improving asthma symptoms for children with poorly controlled asthma aged 5-14.\n",
            "\n",
            "\n",
            "\n",
            "**NCT06388460** (Relevance: 87%)\n",
            "‚Ä¢ Asthma Link Effectiveness Trial\n",
            "  Status: Recruiting\n",
            "\n",
            "  The goal of this cluster Randomized Control Trial is to determine the effectiveness of Asthma Link, a school supervised asthma therapy program, compared with an educational asthma workbook, in improving asthma symptoms for children with poorly controlled asthma aged 5-14.\n",
            "\n",
            "\n",
            "\n",
            "**NCT00272441** (Relevance: 85%)\n",
            "‚Ä¢ Prevention of Early Asthma in Kids (PEAK)\n",
            "  Status: Completed\n",
            "\n",
            "  To evaluate current and novel therapies and management strategies for children with asthma. The emphasis is on clinical trials that help identify optimal therapy for children with different asthma phenotypes, genotypes, and ethnic backgrounds and children at different developmental stages.\n",
            "\n",
            "  PubMed abstract (PMID 16687711):\n",
            "  1. N Engl J Med. 2006 May 11;354(19):1985-97. doi: 10.1056/NEJMoa051378.\n",
            "\n",
            "Long-term inhaled corticosteroids in preschool children at high risk for asthma.\n",
            "\n",
            "Guilbert TW(1), Morgan WJ, Zeiger RS, Mauger DT, Boehmer SJ, Szefler SJ, \n",
            "Bacharier LB, Lemanske RF Jr, Strunk RC, Allen DB, Bloomberg GR, Heldt G, \n",
            "Krawiec M, Larsen G, Liu AH, Chinchilli VM, Sorkness CA, Taussig LM, Martinez \n",
            "FD.\n",
            "\n",
            "Author information:\n",
            "(1)Division of Pediatric Pulmonary Medicine, Arizona Respiratory Center, \n",
            "University of Arizona, Tucson, AZ 85724, USA. guilbert@arc.arizona.edu\n",
            "\n",
            "Comment in\n",
            "    N Engl J Med. 2006 May 11;354(19):2058-60. doi: 10.1056/NEJMe068058.\n",
            "    N Engl J Med. 2006 Aug 10;355(6):624; author reply 625-6. doi: \n",
            "10.1056/NEJMc061553.\n",
            "    J Pediatr. 2006 Nov;149(5):728-9. doi: 10.1016/j.jpeds.2006.08.040.\n",
            "    Evid Based Med. 2006 Dec;11(6):174. doi: 10.1136/ebm.11.6.174.\n",
            "\n",
            "BACKGROUND: It is unknown whether inhaled corticosteroids can modify the \n",
            "subsequent development of asthma in preschool children at high risk for asthma.\n",
            "METHODS: We randomly assigned 285 participants two or three years of age with a \n",
            "positive asthma predictive index to treatment with fluticasone propionate (at a \n",
            "dose of 88 mug twice daily) or masked placebo for two years, followed by a \n",
            "one-year period without study medication. The primary outcome was the proportion \n",
            "of episode-free days during the observation year.\n",
            "RESULTS: During the observation year, no significant differences were seen \n",
            "between the two groups in the proportion of episode-free days, the number of \n",
            "exacerbations, or lung function. During the treatment period, as compared with \n",
            "placebo use, use of the inhaled corticosteroid was associated with a greater \n",
            "proportion of episode-free days (P=0.006) and a lower rate of exacerbations \n",
            "(P<0.001) and of supplementary use of controller medication (P<0.001). In the \n",
            "inhaled-corticosteroid group, as compared with the placebo group, the mean \n",
            "increase in height was 1.1 cm less at 24 months (P<0.001), but b...\n",
            "\n",
            "  PubMed link: https://pubmed.ncbi.nlm.nih.gov/16687711/\n",
            "\n",
            "\n",
            "\n",
            "Summary: These trials explore potential treatments or management strategies for the condition you asked about. More details are available using the listed NCT IDs.\n",
            "\n",
            "To learn more or consider participation, visit clinicaltrials.gov and search by NCT ID. Always discuss clinical trial options with your healthcare provider.\n"
          ]
        }
      ],
      "source": [
        "response = run_bot(\"What trials are studying asthma prevention?\")\n",
        "print(response[\"recommendation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "Eh9vcQTa6Kxb",
        "outputId": "41c374b3-39e2-4d92-832e-00c40532675c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 232.04ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello Patient! I'm your **Clinical Trial Research Assistant**. üî¨\n",
            "\n",
            "I can help you explore clinical trials for conditions such as:\n",
            "- Diabetes\n",
            "- Cancer\n",
            "- Alzheimer's disease\n",
            "- Asthma\n",
            "- Cardiovascular disease\n",
            "\n",
            "I search a database of tens of thousands of real trials (e.g., from ClinicalTrials.gov).\n",
            "\n",
            "**You can ask things like:**\n",
            "- 'What trials are studying insulin therapy in diabetes?'\n",
            "- 'Are there breast cancer trials targeting HER2?'\n",
            "- 'Trials for memory loss and Alzheimer's?'\n",
            "- 'I'm 55 with type 2 diabetes, what trials can I join?'\n",
            "\n",
            "What condition and question would you like to explore?\n"
          ]
        }
      ],
      "source": [
        "response = run_bot(\"hi?\")\n",
        "print(response[\"recommendation\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
