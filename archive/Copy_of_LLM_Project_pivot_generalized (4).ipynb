{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keVc9VWJI9ZI"
      },
      "source": [
        "Qdrant"
      ]
    },
   
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "vk3hdJJ4Bpg8",
        "outputId": "b185ab94-a6e0-40ab-c65c-37c08115e56e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîë Enter your Qdrant API Key (input will be hidden):\n",
            "Qdrant API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ API Key captured securely\n"
          ]
        },
        {
          "ename": "UnexpectedResponse",
          "evalue": "Unexpected Response: 409 (Conflict)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Collection `clinical_trials` already exists!\"},\"time\":0.038894767}'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnexpectedResponse\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2140676068.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Create collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m client.create_collection(\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"clinical_trials\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mvectors_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVectorParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOSINE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/qdrant_client.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, collection_name, vectors_config, sparse_vectors_config, shard_number, sharding_method, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, timeout, strict_mode_config, metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Unknown arguments: {list(kwargs.keys())}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m         return self._client.create_collection(\n\u001b[0m\u001b[1;32m   1704\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m             \u001b[0mvectors_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectors_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/qdrant_remote.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, collection_name, vectors_config, shard_number, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, timeout, sparse_vectors_config, sharding_method, strict_mode_config, metadata, **kwargs)\u001b[0m\n\u001b[1;32m   2037\u001b[0m         )\n\u001b[1;32m   2038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2039\u001b[0;31m         result: Optional[bool] = self.http.collections_api.create_collection(\n\u001b[0m\u001b[1;32m   2040\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m             \u001b[0mcreate_collection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_collection_request\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api/collections_api.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, collection_name, timeout, create_collection)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mcollection\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \"\"\"\n\u001b[0;32m--> 294\u001b[0;31m         return self._build_for_create_collection(\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api/collections_api.py\u001b[0m in \u001b[0;36m_build_for_create_collection\u001b[0;34m(self, collection_name, timeout, create_collection)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"Content-Type\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         return self.api_client.request(\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mtype_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInlineResponse200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"PUT\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, type_, method, url, path_params, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qdrant_client/http/api_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, type_)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValidationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mResponseHandlingException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mUnexpectedResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnexpectedResponse\u001b[0m: Unexpected Response: 409 (Conflict)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Collection `clinical_trials` already exists!\"},\"time\":0.038894767}'"
          ]
        }
      ],
      "source": [
        "# # Install Qdrant client\n",
        "# !pip install qdrant-client -q\n",
        "\n",
        "# from qdrant_client import QdrantClient\n",
        "# from qdrant_client.models import Distance, VectorParams\n",
        "# import getpass\n",
        "\n",
        "# # üîë Secure API Key Input (invisible)\n",
        "# print(\"üîë Enter your Qdrant API Key (input will be hidden):\")\n",
        "# qdrant_api_key = getpass.getpass(\"Qdrant API Key: \")\n",
        "\n",
        "# # Verify key format\n",
        "# if qdrant_api_key and len(qdrant_api_key) > 10:\n",
        "#     print(\"‚úÖ API Key captured securely\")\n",
        "# else:\n",
        "#     print(\"‚ö†Ô∏è API Key seems invalid\")\n",
        "\n",
        "# # Connect to your cluster\n",
        "# client = QdrantClient(\n",
        "#     url=\"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\",\n",
        "#     api_key=qdrant_api_key\n",
        "# )\n",
        "\n",
        "# # Create collection\n",
        "# client.create_collection(\n",
        "#     collection_name=\"clinical_trials\",\n",
        "#     vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
        "# )\n",
        "\n",
        "# print(\"‚úÖ Collection 'clinical_trials' created successfully!\")\n",
        "\n",
        "# # Verify\n",
        "# collections = client.get_collections()\n",
        "# print(f\"\\nüìä Collections: {collections}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34p7QlZPD7O6",
        "outputId": "00393c14-01d7-44f7-d5d3-263bade3f329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni15p_feDbUn",
        "outputId": "d217654a-ca5c-4500-e11b-9570fced2601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Checking if files exist in Drive:\n",
            "\n",
            "‚úÖ clinical_trials_all_full_embeddings.npy: EXISTS (384.8 MB)\n",
            "‚úÖ clinical_trials_all_full_chunk_map.json: EXISTS (230.6 MB)\n",
            "‚úÖ clinical_trials_all_full_faiss.index: EXISTS (384.8 MB)\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "\n",
        "# BASE = \"/content/drive/.shortcut-targets-by-id/1-SiVJhXHTHtDYSrPmW_0VfuP7gSTePcj/data\"\n",
        "\n",
        "# # Check if files exist\n",
        "# files_to_check = [\n",
        "#     \"clinical_trials_all_full_embeddings.npy\",\n",
        "#     \"clinical_trials_all_full_chunk_map.json\",\n",
        "#     \"clinical_trials_all_full_faiss.index\"\n",
        "# ]\n",
        "\n",
        "# print(\"üìÅ Checking if files exist in Drive:\\n\")\n",
        "# for filename in files_to_check:\n",
        "#     filepath = f\"{BASE}/{filename}\"\n",
        "#     exists = os.path.exists(filepath)\n",
        "#     if exists:\n",
        "#         size_mb = os.path.getsize(filepath) / (1024*1024)\n",
        "#         print(f\"‚úÖ {filename}: EXISTS ({size_mb:.1f} MB)\")\n",
        "#     else:\n",
        "#         print(f\"‚ùå {filename}: NOT FOUND\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QncCxftPETth"
      },
      "source": [
        "Load Data and Upload to Qdrant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGUCNt3vCS7i",
        "outputId": "6816c37a-1ae7-4d6b-8dc5-2de2546b7082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Loading embeddings and chunk map from Drive...\n",
            "‚úÖ Loaded 262660 embeddings (shape: (262660, 384))\n",
            "‚úÖ Loaded 262660 chunks of metadata\n",
            "‚úÖ Data verified: 262660 vectors ready to upload\n"
          ]
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import json\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# BASE = \"/content/drive/.shortcut-targets-by-id/1-SiVJhXHTHtDYSrPmW_0VfuP7gSTePcj/data\"\n",
        "\n",
        "# print(\"‚è≥ Loading embeddings and chunk map from Drive...\")\n",
        "\n",
        "# # Load embeddings (384.8 MB)\n",
        "# embeddings = np.load(f\"{BASE}/clinical_trials_all_full_embeddings.npy\")\n",
        "# print(f\"‚úÖ Loaded {len(embeddings)} embeddings (shape: {embeddings.shape})\")\n",
        "\n",
        "# # Load chunk map (metadata - 230.6 MB)\n",
        "# with open(f\"{BASE}/clinical_trials_all_full_chunk_map.json\", \"r\") as f:\n",
        "#     chunk_map = json.load(f)\n",
        "# print(f\"‚úÖ Loaded {len(chunk_map)} chunks of metadata\")\n",
        "\n",
        "# # Verify sizes match\n",
        "# if len(embeddings) == len(chunk_map):\n",
        "#     print(f\"‚úÖ Data verified: {len(embeddings)} vectors ready to upload\")\n",
        "# else:\n",
        "#     print(f\"‚ö†Ô∏è WARNING: Mismatch! {len(embeddings)} embeddings vs {len(chunk_map)} chunks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-ced4uTCTHh",
        "outputId": "aa6fe6e1-6ab4-47b8-d82b-0636e029215f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîë Enter your Qdrant API Key again:\n",
            "Qdrant API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ Connected to Qdrant\n",
            "\n",
            "‚è≥ Uploading vectors to Qdrant...\n",
            "‚ö†Ô∏è This will take 5-10 minutes for 262K vectors. Please wait...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2627/2627 [13:20<00:00,  3.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Successfully uploaded 262660 vectors to Qdrant!\n",
            "\n",
            "üìä Final Collection Stats:\n",
            "   ‚úÖ Total vectors: 262,660\n",
            "   ‚úÖ Vector dimension: 384\n",
            "   ‚úÖ Distance metric: Cosine\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# from qdrant_client.models import PointStruct\n",
        "# import getpass\n",
        "\n",
        "# # Reconnect to Qdrant (in case session expired)\n",
        "# print(\"\\nüîë Enter your Qdrant API Key again:\")\n",
        "# qdrant_api_key = getpass.getpass(\"Qdrant API Key: \")\n",
        "\n",
        "# from qdrant_client import QdrantClient\n",
        "\n",
        "# client = QdrantClient(\n",
        "#     url=\"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\",\n",
        "#     api_key=qdrant_api_key\n",
        "# )\n",
        "# print(\"‚úÖ Connected to Qdrant\")\n",
        "\n",
        "# print(\"\\n‚è≥ Uploading vectors to Qdrant...\")\n",
        "# print(\"‚ö†Ô∏è This will take 5-10 minutes for 262K vectors. Please wait...\\n\")\n",
        "\n",
        "# # Batch upload (100 vectors at a time)\n",
        "# batch_size = 100\n",
        "# total_batches = (len(embeddings) + batch_size - 1) // batch_size\n",
        "\n",
        "# for i in tqdm(range(0, len(embeddings), batch_size), desc=\"Uploading\", total=total_batches):\n",
        "#     batch_end = min(i + batch_size, len(embeddings))\n",
        "\n",
        "#     points = []\n",
        "#     for idx in range(i, batch_end):\n",
        "#         points.append(\n",
        "#             PointStruct(\n",
        "#                 id=idx,\n",
        "#                 vector=embeddings[idx].tolist(),\n",
        "#                 payload={\n",
        "#                     \"nct_id\": chunk_map[idx][\"nct_id\"],\n",
        "#                     \"title\": chunk_map[idx][\"title\"],\n",
        "#                     \"text\": chunk_map[idx][\"text\"],\n",
        "#                     \"status\": chunk_map[idx][\"status\"]\n",
        "#                 }\n",
        "#             )\n",
        "#         )\n",
        "\n",
        "#     # Upload batch\n",
        "#     client.upsert(\n",
        "#         collection_name=\"clinical_trials\",\n",
        "#         points=points\n",
        "#     )\n",
        "\n",
        "# print(f\"\\n‚úÖ Successfully uploaded {len(embeddings)} vectors to Qdrant!\")\n",
        "\n",
        "# # Verify upload\n",
        "# collection_info = client.get_collection(\"clinical_trials\")\n",
        "# print(f\"\\nüìä Final Collection Stats:\")\n",
        "# print(f\"   ‚úÖ Total vectors: {collection_info.points_count:,}\")\n",
        "# print(f\"   ‚úÖ Vector dimension: {collection_info.config.params.vectors.size}\")\n",
        "# print(f\"   ‚úÖ Distance metric: {collection_info.config.params.vectors.distance}\")\n"
      ]
    },
   
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFc_1ye4kHbN"
      },
      "source": [
        "Data in Qdrant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdd96FO0kcDd",
        "outputId": "3246ad11-123b-4bf7-a3cb-b30c0639b028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvziMQpXhY_J",
        "outputId": "e4fc3094-63e6-4cf2-93ef-9be73951e838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting update_qdrant_auto.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile update_qdrant_auto.py\n",
        "\"\"\"\n",
        "Automatically finds ALL CSV files in Drive folder and uploads to Qdrant\n",
        "No manual file listing needed!\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import PointStruct, Distance, VectorParams\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import glob\n",
        "\n",
        "class QdrantAutoPipeline:\n",
        "    def __init__(self, qdrant_url, qdrant_api_key):\n",
        "        self.client = QdrantClient(url=qdrant_url, api_key=qdrant_api_key)\n",
        "        self.embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "        self.collection_name = \"clinical_trials\"\n",
        "\n",
        "    def find_all_csv_files(self, drive_folder_path):\n",
        "        \"\"\"Automatically find all CSV files in Drive folder\"\"\"\n",
        "        print(f\"üîç Searching for CSV files in: {drive_folder_path}\")\n",
        "\n",
        "        # Find all CSV files\n",
        "        csv_files = glob.glob(f\"{drive_folder_path}/*.csv\")\n",
        "\n",
        "        if not csv_files:\n",
        "            print(\"‚ùå No CSV files found!\")\n",
        "            return []\n",
        "\n",
        "        print(f\"‚úÖ Found {len(csv_files)} CSV files:\")\n",
        "        for csv_file in csv_files:\n",
        "            filename = os.path.basename(csv_file)\n",
        "            size_mb = os.path.getsize(csv_file) / (1024 * 1024)\n",
        "            print(f\"   - {filename} ({size_mb:.1f} MB)\")\n",
        "\n",
        "        return csv_files\n",
        "\n",
        "    def load_and_filter_csvs(self, csv_files):\n",
        "        \"\"\"Load all CSV files and filter\"\"\"\n",
        "        print(\"\\nüìÇ Loading CSV files...\")\n",
        "\n",
        "        dfs = []\n",
        "        for csv_path in csv_files:\n",
        "            filename = os.path.basename(csv_path)\n",
        "            print(f\"   Loading {filename}...\")\n",
        "            try:\n",
        "                df = pd.read_csv(csv_path)\n",
        "                dfs.append(df)\n",
        "                print(f\"      ‚úÖ {len(df)} rows\")\n",
        "            except Exception as e:\n",
        "                print(f\"      ‚ö†Ô∏è Error loading {filename}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not dfs:\n",
        "            print(\"‚ùå No data loaded!\")\n",
        "            return None\n",
        "\n",
        "        # Concatenate all\n",
        "        df_all = pd.concat(dfs, ignore_index=True)\n",
        "        print(f\"\\n‚úÖ Total trials loaded: {len(df_all):,}\")\n",
        "\n",
        "        # Remove duplicates by NCT ID\n",
        "        initial_count = len(df_all)\n",
        "        df_all = df_all.drop_duplicates(subset=['nct_id'], keep='first')\n",
        "        duplicates_removed = initial_count - len(df_all)\n",
        "        if duplicates_removed > 0:\n",
        "            print(f\"üóëÔ∏è Removed {duplicates_removed:,} duplicate trials\")\n",
        "\n",
        "        # Filter bad statuses\n",
        "        df_all[\"status\"] = df_all[\"status\"].astype(str).str.strip().str.title()\n",
        "        bad_status = [\"Terminated\", \"Withdrawn\", \"Suspended\", \"No Longer Available\", \"Unknown\"]\n",
        "        df_clean = df_all[~df_all[\"status\"].isin(bad_status)].copy()\n",
        "\n",
        "        filtered_out = len(df_all) - len(df_clean)\n",
        "        print(f\"üóëÔ∏è Filtered out {filtered_out:,} trials with bad status\")\n",
        "        print(f\"‚úÖ Final clean dataset: {len(df_clean):,} trials\")\n",
        "\n",
        "        return df_clean\n",
        "\n",
        "    def create_chunks(self, df_clean):\n",
        "        \"\"\"Create text chunks from DataFrame\"\"\"\n",
        "        print(\"\\nüìù Creating chunks...\")\n",
        "\n",
        "        chunks = []\n",
        "        skipped = 0\n",
        "\n",
        "        for idx, row in tqdm(df_clean.iterrows(), total=len(df_clean), desc=\"Processing\"):\n",
        "            title = str(row.get(\"brief_title\", \"\")).strip()\n",
        "            summary = str(row.get(\"brief_summary\", \"\")).strip()\n",
        "\n",
        "            if len(summary) < 20:\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            text = f\"Title: {title}\\nSummary: {summary}\"\n",
        "\n",
        "            chunks.append({\n",
        "                \"nct_id\": row[\"nct_id\"],\n",
        "                \"title\": title,\n",
        "                \"text\": text,\n",
        "                \"status\": row[\"status\"]\n",
        "            })\n",
        "\n",
        "        if skipped > 0:\n",
        "            print(f\"‚ö†Ô∏è Skipped {skipped:,} trials with insufficient summary\")\n",
        "        print(f\"‚úÖ Created {len(chunks):,} chunks\")\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def generate_embeddings(self, chunks):\n",
        "        \"\"\"Generate embeddings for all chunks\"\"\"\n",
        "        print(\"\\nüß† Generating embeddings...\")\n",
        "        print(\"‚è≥ This may take several minutes for large datasets...\")\n",
        "\n",
        "        texts = [c[\"text\"] for c in chunks]\n",
        "        embeddings = self.embed_model.encode(\n",
        "            texts,\n",
        "            batch_size=64,\n",
        "            show_progress_bar=True,\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "        print(f\"‚úÖ Generated {len(embeddings):,} embeddings (shape: {embeddings.shape})\")\n",
        "        return embeddings\n",
        "\n",
        "    def upload_to_qdrant(self, embeddings, chunks, mode=\"refresh\"):\n",
        "        \"\"\"Upload data to Qdrant\"\"\"\n",
        "\n",
        "        if mode == \"refresh\":\n",
        "            print(\"\\nüóëÔ∏è Deleting old collection...\")\n",
        "            try:\n",
        "                self.client.delete_collection(self.collection_name)\n",
        "                print(\"‚úÖ Old collection deleted\")\n",
        "            except:\n",
        "                print(\"‚ö†Ô∏è No existing collection to delete\")\n",
        "\n",
        "            print(\"üì¶ Creating fresh collection...\")\n",
        "            self.client.create_collection(\n",
        "                collection_name=self.collection_name,\n",
        "                vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
        "            )\n",
        "            print(\"‚úÖ Collection created\")\n",
        "            start_id = 0\n",
        "        else:  # mode == \"add\"\n",
        "            collection_info = self.client.get_collection(self.collection_name)\n",
        "            start_id = collection_info.points_count\n",
        "            print(f\"\\nüìä Adding to existing data, starting from ID: {start_id:,}\")\n",
        "\n",
        "        print(f\"\\n‚è≥ Uploading {len(embeddings):,} vectors to Qdrant...\")\n",
        "\n",
        "        batch_size = 100\n",
        "        total_batches = (len(embeddings) + batch_size - 1) // batch_size\n",
        "\n",
        "        for i in tqdm(range(0, len(embeddings), batch_size), total=total_batches, desc=\"Uploading\"):\n",
        "            batch_end = min(i + batch_size, len(embeddings))\n",
        "\n",
        "            points = []\n",
        "            for idx in range(i, batch_end):\n",
        "                points.append(PointStruct(\n",
        "                    id=start_id + idx,\n",
        "                    vector=embeddings[idx].tolist(),\n",
        "                    payload=chunks[idx]\n",
        "                ))\n",
        "\n",
        "            self.client.upsert(\n",
        "                collection_name=self.collection_name,\n",
        "                points=points\n",
        "            )\n",
        "\n",
        "        # Verify\n",
        "        final_count = self.client.get_collection(self.collection_name).points_count\n",
        "        print(f\"\\n‚úÖ Upload complete!\")\n",
        "        print(f\"üìä Total vectors in Qdrant: {final_count:,}\")\n",
        "\n",
        "    def run_auto_pipeline(self, drive_folder_path, mode=\"refresh\"):\n",
        "        \"\"\"Complete auto pipeline: Auto-find CSVs ‚Üí Qdrant\"\"\"\n",
        "        print(\"=\"*60)\n",
        "        print(\"üöÄ QDRANT AUTO-UPDATE PIPELINE\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Step 1: Auto-find all CSV files\n",
        "        csv_files = self.find_all_csv_files(drive_folder_path)\n",
        "        if not csv_files:\n",
        "            print(\"‚ùå No CSV files found. Exiting.\")\n",
        "            return\n",
        "\n",
        "        # Step 2: Load and filter CSVs\n",
        "        df_clean = self.load_and_filter_csvs(csv_files)\n",
        "        if df_clean is None or len(df_clean) == 0:\n",
        "            print(\"‚ùå No data to process. Exiting.\")\n",
        "            return\n",
        "\n",
        "        # Step 3: Create chunks\n",
        "        chunks = self.create_chunks(df_clean)\n",
        "        if not chunks:\n",
        "            print(\"‚ùå No chunks created. Exiting.\")\n",
        "            return\n",
        "\n",
        "        # Step 4: Generate embeddings\n",
        "        embeddings = self.generate_embeddings(chunks)\n",
        "\n",
        "        # Step 5: Upload to Qdrant\n",
        "        self.upload_to_qdrant(embeddings, chunks, mode=mode)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"‚úÖ PIPELINE COMPLETE!\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"üìä Your app now has access to {len(chunks):,} clinical trials\")\n",
        "        print(\"üîÑ No code changes needed - just reload your app!\")\n",
        "\n",
        "\n",
        "# Usage\n",
        "if __name__ == \"__main__\":\n",
        "    import getpass\n",
        "\n",
        "    # Configuration\n",
        "    DRIVE_FOLDER = \"/content/drive/MyDrive/LLM_Based_GenAI_Sem1/data\"\n",
        "    QDRANT_URL = \"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\"\n",
        "\n",
        "    print(\"üîê Qdrant Configuration\")\n",
        "    qdrant_key = getpass.getpass(\"Enter Qdrant API Key: \")\n",
        "\n",
        "    print(\"\\nüìã Update Mode:\")\n",
        "    print(\"1. refresh - Delete all old data and upload fresh\")\n",
        "    print(\"2. add - Keep existing data and add new data\")\n",
        "    mode_choice = input(\"Choose mode (1 or 2): \").strip()\n",
        "    mode = \"refresh\" if mode_choice == \"1\" else \"add\"\n",
        "\n",
        "    # Run pipeline\n",
        "    pipeline = QdrantAutoPipeline(QDRANT_URL, qdrant_key)\n",
        "    pipeline.run_auto_pipeline(DRIVE_FOLDER, mode=mode)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv4FcQnIhZDz",
        "outputId": "98a687ca-31f8-448e-d342-202d57817675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-30 16:26:56.042066: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764520016.065483   41049 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764520016.075744   41049 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764520016.097559   41049 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764520016.097585   41049 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764520016.097591   41049 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764520016.097604   41049 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "üîê Qdrant Configuration\n",
            "Enter Qdrant API Key: \n",
            "\n",
            "üìã Update Mode:\n",
            "1. refresh - Delete all old data and upload fresh\n",
            "2. add - Keep existing data and add new data\n",
            "Choose mode (1 or 2): 1\n",
            "============================================================\n",
            "üöÄ QDRANT AUTO-UPDATE PIPELINE\n",
            "============================================================\n",
            "üîç Searching for CSV files in: /content/drive/MyDrive/LLM_Based_GenAI_Sem1/data\n",
            "‚úÖ Found 6 CSV files:\n",
            "   - clinical_trials_cardiovascular_full.csv (136.0 MB)\n",
            "   - clinical_trials_diabetes_full.csv (49.9 MB)\n",
            "   - clinical_trials_asthma_full.csv (12.4 MB)\n",
            "   - clinical_trials_alzheimer_full.csv (10.1 MB)\n",
            "   - clinical_trials_master_full.csv (564.1 MB)\n",
            "   - clinical_trials_cancer_full.csv (355.6 MB)\n",
            "\n",
            "üìÇ Loading CSV files...\n",
            "   Loading clinical_trials_cardiovascular_full.csv...\n",
            "      ‚úÖ 63192 rows\n",
            "   Loading clinical_trials_diabetes_full.csv...\n",
            "      ‚úÖ 22868 rows\n",
            "   Loading clinical_trials_asthma_full.csv...\n",
            "      ‚úÖ 5038 rows\n",
            "   Loading clinical_trials_alzheimer_full.csv...\n",
            "      ‚úÖ 3761 rows\n",
            "   Loading clinical_trials_master_full.csv...\n",
            "      ‚úÖ 209693 rows\n",
            "   Loading clinical_trials_cancer_full.csv...\n",
            "      ‚úÖ 114834 rows\n",
            "\n",
            "‚úÖ Total trials loaded: 419,386\n",
            "üóëÔ∏è Removed 220,634 duplicate trials\n",
            "üóëÔ∏è Filtered out 52,156 trials with bad status\n",
            "‚úÖ Final clean dataset: 146,596 trials\n",
            "\n",
            "üìù Creating chunks...\n",
            "Processing: 100% 146596/146596 [00:07<00:00, 19539.39it/s]\n",
            "‚ö†Ô∏è Skipped 3 trials with insufficient summary\n",
            "‚úÖ Created 146,593 chunks\n",
            "\n",
            "üß† Generating embeddings...\n",
            "‚è≥ This may take several minutes for large datasets...\n",
            "Batches: 100% 2291/2291 [04:37<00:00,  8.25it/s]\n",
            "‚úÖ Generated 146,593 embeddings (shape: (146593, 384))\n",
            "\n",
            "üóëÔ∏è Deleting old collection...\n",
            "‚úÖ Old collection deleted\n",
            "üì¶ Creating fresh collection...\n",
            "‚úÖ Collection created\n",
            "\n",
            "‚è≥ Uploading 146,593 vectors to Qdrant...\n",
            "Uploading: 100% 1466/1466 [07:12<00:00,  3.39it/s]\n",
            "\n",
            "‚úÖ Upload complete!\n",
            "üìä Total vectors in Qdrant: 146,593\n",
            "\n",
            "============================================================\n",
            "‚úÖ PIPELINE COMPLETE!\n",
            "============================================================\n",
            "üìä Your app now has access to 146,593 clinical trials\n",
            "üîÑ No code changes needed - just reload your app!\n"
          ]
        }
      ],
      "source": [
        "!python update_qdrant_auto.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sxhAfqnnS-R",
        "outputId": "6e2b2ff9-85cf-4799-b3ad-9645fb7a925a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total rows: 419,386\n",
            "Unique NCT IDs: 198,752\n",
            "Duplicates: 220,634\n",
            "\n",
            "üìã Example duplicate NCT IDs:\n",
            "nct_id\n",
            "NCT00000105    Vaccination With Tetanus and KLH to Assess Imm...\n",
            "NCT00000107    Body Water Content in Cyanotic Congenital Hear...\n",
            "NCT00000108    Effects of Training Intensity on the CHD Risk ...\n",
            "NCT00000112    Prevalence of Carbohydrate Intolerance in Lean...\n",
            "NCT00000124           Collaborative Ocular Melanoma Study (COMS)\n",
            "Name: brief_title, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/LLM_Based_GenAI_Sem1/data\"\n",
        "\n",
        "df1 = pd.read_csv(f\"{BASE}/clinical_trials_diabetes_full.csv\")\n",
        "df2 = pd.read_csv(f\"{BASE}/clinical_trials_cancer_full.csv\")\n",
        "df3 = pd.read_csv(f\"{BASE}/clinical_trials_alzheimer_full.csv\")\n",
        "df4 = pd.read_csv(f\"{BASE}/clinical_trials_asthma_full.csv\")\n",
        "df5 = pd.read_csv(f\"{BASE}/clinical_trials_cardiovascular_full.csv\")\n",
        "df6 = pd.read_csv(f\"{BASE}/clinical_trials_master_full.csv\")\n",
        "\n",
        "# Check for duplicates\n",
        "df_all = pd.concat([df1, df2, df3, df4, df5, df6], ignore_index=True)\n",
        "\n",
        "print(f\"Total rows: {len(df_all):,}\")\n",
        "print(f\"Unique NCT IDs: {df_all['nct_id'].nunique():,}\")\n",
        "print(f\"Duplicates: {len(df_all) - df_all['nct_id'].nunique():,}\")\n",
        "\n",
        "# Show example duplicates\n",
        "duplicates = df_all[df_all.duplicated(subset=['nct_id'], keep=False)]\n",
        "if len(duplicates) > 0:\n",
        "    print(f\"\\nüìã Example duplicate NCT IDs:\")\n",
        "    print(duplicates.groupby('nct_id')['brief_title'].first().head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQpdvAiNITvP"
      },
      "source": [
        "Update Code to Use Qdrant Instead of FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzgNJNuFCTNh",
        "outputId": "7313d68f-cfb0-484b-99bf-cb1d4b61cc00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting utils_qdrant.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils_qdrant.py\n",
        "import json\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "from qdrant_client import QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# --- Confidence score from distance ---\n",
        "\n",
        "def calculate_confidence_score(distance: float, normalization_factor: float = 1.0) -> float:\n",
        "    \"\"\"Inverse L2 distance score in (0,1]; closer = higher confidence.\"\"\"\n",
        "    return normalization_factor / (normalization_factor + float(distance))\n",
        "\n",
        "\n",
        "# --- Load Qdrant client + embedding model ---\n",
        "\n",
        "def load_qdrant_and_model(qdrant_url: str, qdrant_api_key: str):\n",
        "    \"\"\"Loads Qdrant client and embedding model.\"\"\"\n",
        "    print(\"‚è≥ Connecting to Qdrant...\")\n",
        "\n",
        "    client = QdrantClient(url=qdrant_url, api_key=qdrant_api_key)\n",
        "\n",
        "    # Verify connection\n",
        "    collection_info = client.get_collection(\"clinical_trials\")\n",
        "    print(f\"‚úÖ Connected to Qdrant: {collection_info.points_count:,} vectors ready\")\n",
        "\n",
        "    # Load embedding model (same as before)\n",
        "    embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    print(\"‚úÖ Embedding model loaded\")\n",
        "\n",
        "    return client, embed_model\n",
        "\n",
        "\n",
        "# --- Provenance logging (unchanged) ---\n",
        "\n",
        "def log_provenance_step(agent_name: str, input_data, output_data, detail=None):\n",
        "    \"\"\"Creates a detailed log entry for a single agent step.\"\"\"\n",
        "    log_entry = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"agent\": agent_name,\n",
        "        \"input\": input_data,\n",
        "        \"output\": output_data,\n",
        "        \"detail\": detail or {},\n",
        "        \"model_version\": \"gemini-2.0-flash\",\n",
        "    }\n",
        "    return log_entry\n",
        "\n",
        "\n",
        "# --- Reproducibility hash (unchanged) ---\n",
        "\n",
        "def generate_reproducibility_hash(conversation_history, corpus_version: str = \"v1.0\"):\n",
        "    \"\"\"Generates a deterministic session hash based on conversation history.\"\"\"\n",
        "    queries = [turn.get(\"query\", \"\") for turn in conversation_history]\n",
        "    raw = f\"{corpus_version}|{'|'.join(queries)}\"\n",
        "    return hashlib.md5(raw.encode(\"utf-8\")).hexdigest()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM4rCpCCJQVJ",
        "outputId": "74d1fb67-a6e9-46e7-e93e-c63b3192fbc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîë Qdrant API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Available search methods:\n",
            "['_resolve_query', '_resolve_query_batch_request', '_resolve_query_request', '_scored_points_to_query_responses', 'query', 'query_batch', 'query_batch_points', 'query_points', 'query_points_groups', 'search_matrix_offsets', 'search_matrix_pairs']\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "from qdrant_client import QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Get API key\n",
        "qdrant_api_key = getpass.getpass(\"üîë Qdrant API Key: \")\n",
        "\n",
        "# Connect\n",
        "qdrant_client = QdrantClient(\n",
        "    url=\"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\",\n",
        "    api_key=qdrant_api_key\n",
        ")\n",
        "\n",
        "# Check what methods are available\n",
        "print(\"Available search methods:\")\n",
        "print([m for m in dir(qdrant_client) if 'search' in m.lower() or 'query' in m.lower()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGBG0m7XIcUi",
        "outputId": "883a9d8e-346a-4cef-bd4e-a4d549be2d6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîë Qdrant API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Test Query: 'diabetes insulin therapy trials'\n",
            "\n",
            "üìä Top 3 Results:\n",
            "\n",
            "1. NCT ID: NCT00151697\n",
            "   Score: 0.752\n",
            "   Title: LANN-study: Lantus, Amaryl, Novorapid, Novomix Study...\n",
            "\n",
            "2. NCT ID: NCT02192424\n",
            "   Score: 0.697\n",
            "   Title: Early Intermittent Intensive Insulin Therapy as an Effective Treatment of Type 2...\n",
            "\n",
            "3. NCT ID: NCT02846233\n",
            "   Score: 0.697\n",
            "   Title: Stepping-down Approach in Patients With Chronic Poorly-controlled Diabetes on Ad...\n",
            "\n",
            "‚úÖ Qdrant search working!\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "from qdrant_client import QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Get API key\n",
        "qdrant_api_key = getpass.getpass(\"üîë Qdrant API Key: \")\n",
        "\n",
        "# Connect\n",
        "qdrant_client = QdrantClient(\n",
        "    url=\"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\",\n",
        "    api_key=qdrant_api_key\n",
        ")\n",
        "\n",
        "# Load model\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Test search\n",
        "test_query = \"diabetes insulin therapy trials\"\n",
        "q_emb = embed_model.encode([test_query])[0]\n",
        "\n",
        "# Use query_points (correct method)\n",
        "results = qdrant_client.query_points(\n",
        "    collection_name=\"clinical_trials\",\n",
        "    query=q_emb.tolist(),\n",
        "    limit=3\n",
        ")\n",
        "\n",
        "print(f\"\\nüîç Test Query: '{test_query}'\")\n",
        "print(f\"\\nüìä Top 3 Results:\\n\")\n",
        "\n",
        "for i, point in enumerate(results.points, 1):\n",
        "    print(f\"{i}. NCT ID: {point.payload['nct_id']}\")\n",
        "    print(f\"   Score: {point.score:.3f}\")\n",
        "    print(f\"   Title: {point.payload['title'][:80]}...\")\n",
        "    print()\n",
        "\n",
        "print(\"‚úÖ Qdrant search working!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wbqFEilJxIZ"
      },
      "source": [
        "Fix RetrievalAgent to Use query_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIjl0L_BIcZu",
        "outputId": "60013a40-43b9-469e-a9fb-256ec96a39e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting retrieval_agent_qdrant.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile retrieval_agent_qdrant.py\n",
        "import numpy as np\n",
        "from typing import Dict, Any\n",
        "from qdrant_client import QdrantClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Import scoring from your existing code\n",
        "from utils_qdrant import calculate_confidence_score, log_provenance_step\n",
        "\n",
        "# Try to import reranker\n",
        "CrossEncoder = None\n",
        "try:\n",
        "    from sentence_transformers import CrossEncoder\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "\n",
        "class RetrievalAgentQdrant:\n",
        "    \"\"\"Retrieval agent using Qdrant instead of FAISS.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        qdrant_client: QdrantClient,\n",
        "        embed_model: SentenceTransformer,\n",
        "        evidence_scorer,\n",
        "        profile_agent=None\n",
        "    ):\n",
        "        self.client = qdrant_client\n",
        "        self.embed_model = embed_model\n",
        "        self.evidence_scorer = evidence_scorer\n",
        "        self.profile_agent = profile_agent\n",
        "\n",
        "        # Optional: Load reranker\n",
        "        self.reranker = None\n",
        "        if CrossEncoder:\n",
        "            try:\n",
        "                print(\"‚è≥ Loading Cross-Encoder reranker...\")\n",
        "                self.reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "                print(\"‚úÖ Reranker loaded\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Reranker failed to load: {e}\")\n",
        "\n",
        "    def retrieve(self, parsed: Dict[str, Any], top_k: int = 5):\n",
        "        \"\"\"Retrieve trials from Qdrant.\"\"\"\n",
        "        FETCH_K = top_k * 3\n",
        "\n",
        "        symptoms = parsed.get(\"symptoms\") or []\n",
        "        context = parsed.get(\"context\") or \"\"\n",
        "        query = parsed.get(\"user_question\") or (\" \".join(symptoms) + \" \" + context).strip()\n",
        "\n",
        "        if not query:\n",
        "            retrieval = {\"query\": \"\", \"trials\": [], \"avg_confidence\": 0.0}\n",
        "            log = log_provenance_step(\"RetrievalAgentQdrant\", parsed, retrieval, {\"reason\": \"empty_query\"})\n",
        "            return retrieval, log\n",
        "\n",
        "        # Query expansion (same as before)\n",
        "        EXPANSIONS = {\n",
        "            \"insulin\": \"insulin OR insulin therapy OR insulin treatment OR insulin pump\",\n",
        "            \"medication\": \"medication OR drug OR pharmaceutical OR pharmacological OR treatment\",\n",
        "            \"diet\": \"diet OR dietary OR nutrition OR nutritional OR eating\",\n",
        "            \"exercise\": \"exercise OR physical activity OR fitness OR activity\",\n",
        "            \"chemo\": \"chemotherapy OR antineoplastic OR oncology\",\n",
        "            \"cancer\": \"cancer OR tumor OR tumour OR malignancy OR oncology\",\n",
        "            \"alzheim\": \"alzheimer OR dementia OR cognitive decline OR memory loss\",\n",
        "        }\n",
        "\n",
        "        query_lower = query.lower()\n",
        "        for term, expansion in EXPANSIONS.items():\n",
        "            if term in query_lower:\n",
        "                query = f\"{query} {expansion}\"\n",
        "                break\n",
        "\n",
        "        # 1. Generate query embedding\n",
        "        q_emb = self.embed_model.encode([query])[0]\n",
        "\n",
        "        # 2. Search Qdrant (FIXED: use query_points)\n",
        "        search_results = self.client.query_points(\n",
        "            collection_name=\"clinical_trials\",\n",
        "            query=q_emb.tolist(),\n",
        "            limit=FETCH_K\n",
        "        )\n",
        "\n",
        "        # 3. Convert to candidate format\n",
        "        initial_candidates = []\n",
        "        for point in search_results.points:\n",
        "            initial_candidates.append({\n",
        "                \"nct_id\": point.payload[\"nct_id\"],\n",
        "                \"title\": point.payload.get(\"title\", \"\"),\n",
        "                \"text\": point.payload[\"text\"],\n",
        "                \"status\": point.payload.get(\"status\", \"Unknown Status\"),\n",
        "                \"qdrant_score\": point.score,  # Cosine similarity (higher = better)\n",
        "            })\n",
        "\n",
        "        final_trials = []\n",
        "\n",
        "        # 4. Optional CrossEncoder reranking\n",
        "        if self.reranker and initial_candidates:\n",
        "            pairs = [[query, cand[\"text\"]] for cand in initial_candidates]\n",
        "            scores = self.reranker.predict(pairs)\n",
        "\n",
        "            for i, cand in enumerate(initial_candidates):\n",
        "                cand[\"rerank_score\"] = float(scores[i])\n",
        "\n",
        "            initial_candidates.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                logit = item[\"rerank_score\"]\n",
        "                base_conf = 1 / (1 + np.exp(-logit))\n",
        "\n",
        "                scoring_result = self.evidence_scorer.calculate_weighted_score(\n",
        "                    trial=item,\n",
        "                    base_confidence=base_conf,\n",
        "                    query=query,\n",
        "                )\n",
        "\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"title\"],\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": base_conf,\n",
        "                    \"weighted_score\": scoring_result[\"weighted_score\"],\n",
        "                    \"score_breakdown\": scoring_result[\"breakdown\"],\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"qdrant_evidence_weighted\",\n",
        "                })\n",
        "        else:\n",
        "            # Qdrant-only path (no reranking)\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                # Qdrant uses cosine similarity (0-1, higher = better)\n",
        "                base_conf = item[\"qdrant_score\"]\n",
        "\n",
        "                scoring_result = self.evidence_scorer.calculate_weighted_score(\n",
        "                    trial=item,\n",
        "                    base_confidence=base_conf,\n",
        "                    query=query,\n",
        "                )\n",
        "\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"title\"],\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": base_conf,\n",
        "                    \"weighted_score\": scoring_result[\"weighted_score\"],\n",
        "                    \"score_breakdown\": scoring_result[\"breakdown\"],\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"qdrant_evidence_weighted\",\n",
        "                })\n",
        "\n",
        "        # Sort by weighted score\n",
        "        final_trials.sort(key=lambda x: x[\"weighted_score\"], reverse=True)\n",
        "        for i, trial in enumerate(final_trials):\n",
        "            trial[\"rank\"] = i + 1\n",
        "\n",
        "        confs = [t[\"weighted_score\"] for t in final_trials]\n",
        "        avg_conf = float(np.mean(confs)) if confs else 0.0\n",
        "\n",
        "        retrieval = {\n",
        "            \"query\": query,\n",
        "            \"trials\": final_trials,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "        }\n",
        "\n",
        "        detail = {\n",
        "            \"top_k\": top_k,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"num_trials\": len(final_trials),\n",
        "            \"method\": \"qdrant_reranked\" if self.reranker else \"qdrant_only\",\n",
        "        }\n",
        "\n",
        "        log = log_provenance_step(\"RetrievalAgentQdrant\", parsed, retrieval, detail)\n",
        "        return retrieval, log\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXknHDeuKZMY"
      },
      "source": [
        "Update Main Bot Code to Use Qdrant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pxoihznCTRf",
        "outputId": "9d49b58d-41b4-4353-9297-f212eab44d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting run_bot_qdrant.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile run_bot_qdrant.py\n",
        "\"\"\"\n",
        "Updated HealthcareBot using Qdrant instead of FAISS\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "from typing import List, Dict, Any\n",
        "import numpy as np\n",
        "import requests\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "\n",
        "# Import utilities\n",
        "from utils_qdrant import (\n",
        "    load_qdrant_and_model,\n",
        "    log_provenance_step,\n",
        "    generate_reproducibility_hash,\n",
        ")\n",
        "\n",
        "from retrieval_agent_qdrant import RetrievalAgentQdrant\n",
        "\n",
        "# CrossEncoder\n",
        "CrossEncoder = None\n",
        "try:\n",
        "    from sentence_transformers import CrossEncoder\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PARSER\n",
        "# ============================================================\n",
        "class SymptomParser:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def parse(self, text: str):\n",
        "        \"\"\"\n",
        "        Enhanced parser for clinical trial search queries.\n",
        "        Decides:\n",
        "        - Are they searching for trials or just asking a question?\n",
        "        - Which disease (diabetes, cancer, Alzheimer‚Äôs, asthma, cardiovascular) is implied?\n",
        "        \"\"\"\n",
        "        prompt = (\n",
        "            \"You are a clinical trial search classifier for medical research.\\n\"\n",
        "            \"You support conditions including diabetes, cancer, Alzheimer's disease, asthma, and cardiovascular disease.\\n\\n\"\n",
        "            f\"User Input: \\\"{text}\\\"\\n\\n\"\n",
        "            \"Your tasks:\\n\"\n",
        "            \"1) Decide if the user is searching for clinical trials or just asking a general question.\\n\"\n",
        "            \"2) Detect which disease(s) they are talking about.\\n\"\n",
        "            \"3) Detect if the query is not about health or clinical trials (off_topic).\\n\\n\"\n",
        "            \"Classification Rules:\\n\"\n",
        "            \"- If the query mentions or implies trials, studies, research, clinical experiments, etc. ‚Üí intent='trial_search'\\n\"\n",
        "            \"- If the user is mainly describing themselves (age, diagnosis, comorbidities, meds) ‚Üí intent='profile_info'\\n\"\n",
        "            \"- If they ask 'what is X', 'how does Y work', etc. without asking about trials ‚Üí intent='general_question'\\n\"\n",
        "            \"- Simple greetings (hi, hello, hey) ‚Üí intent='greeting'\\n\"\n",
        "            \"- If clearly not about health or clinical research ‚Üí intent='off_topic', is_disease_related=false\\n\\n\"\n",
        "            \"You must detect disease_focus whenever possible:\\n\"\n",
        "            \"- diabetes: diabetes, blood sugar, glucose, insulin, HbA1c, metformin, GLP-1, SGLT2\\n\"\n",
        "            \"- cancer: cancer, tumor/tumour, chemotherapy, oncology, breast cancer, lung cancer, leukemia, lymphoma\\n\"\n",
        "            \"- alzheimers: Alzheimer's, dementia, memory loss, cognitive decline\\n\"\n",
        "            \"- asthma: asthma, wheezing, bronchodilator, inhaler\\n\"\n",
        "            \"- cardiovascular: heart failure, cardiovascular disease, hypertension, high blood pressure, angina,\\n\"\n",
        "            \"  myocardial infarction, coronary artery disease, stroke\\n\\n\"\n",
        "            \"Return ONLY valid JSON with this exact format:\\n\"\n",
        "            \"{\\n\"\n",
        "            \"  \\\"intent\\\": \\\"trial_search\\\" | \\\"profile_info\\\" | \\\"general_question\\\" | \\\"greeting\\\" | \\\"off_topic\\\",\\n\"\n",
        "            \"  \\\"query_type\\\": \\\"trial_query\\\" | \\\"profile_statement\\\" | \\\"knowledge_seeking\\\" | \\\"greeting\\\",\\n\"\n",
        "            \"  \\\"search_keywords\\\": [\\\"keyword1\\\", \\\"keyword2\\\"],\\n\"\n",
        "            \"  \\\"is_disease_related\\\": true or false,\\n\"\n",
        "            \"  \\\"disease_focus\\\": [\\\"diabetes\\\", \\\"cancer\\\", \\\"alzheimers\\\", \\\"asthma\\\", \\\"cardiovascular\\\"],\\n\"\n",
        "            \"  \\\"user_question\\\": \\\"the question in plain English\\\",\\n\"\n",
        "            \"  \\\"trial_interest\\\": \\\"what type of trial they want (diet, medication, technology, surgery, etc.)\\\"\\n\"\n",
        "            \"}\\n\\n\"\n",
        "            \"Examples:\\n\"\n",
        "            \"- 'What trials study liraglutide in diabetes?' ‚Üí intent='trial_search', query_type='trial_query',\\n\"\n",
        "            \"  is_disease_related=true, disease_focus=['diabetes'], search_keywords=['liraglutide']\\n\"\n",
        "            \"- 'My mom has breast cancer, are there trials?' ‚Üí intent='trial_search', disease_focus=['cancer']\\n\"\n",
        "            \"- 'I am 70 with memory loss and Alzheimer's' ‚Üí intent='profile_info', disease_focus=['alzheimers']\\n\"\n",
        "            \"- 'What is HbA1c?' ‚Üí intent='general_question', disease_focus=['diabetes']\\n\"\n",
        "            \"- 'What is the weather in Paris?' ‚Üí intent='off_topic', is_disease_related=false, disease_focus=[]\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            raw = (res.text or \"\").strip()\n",
        "            match = re.search(r\"\\{.*\\}\", raw, re.DOTALL)\n",
        "            if match:\n",
        "                parsed = json.loads(match.group(0))\n",
        "            else:\n",
        "                parsed = json.loads(raw)\n",
        "        except Exception:\n",
        "            # Fallback: simple heuristic if model fails\n",
        "            text_lower = text.lower()\n",
        "            disease_focus = []\n",
        "            if any(x in text_lower for x in [\"diabetes\", \"insulin\", \"glucose\", \"hba1c\", \"metformin\", \"glp-1\", \"sglt2\"]):\n",
        "                disease_focus.append(\"diabetes\")\n",
        "            if any(x in text_lower for x in [\"cancer\", \"tumor\", \"tumour\", \"chemo\", \"chemotherapy\", \"oncology\"]):\n",
        "                disease_focus.append(\"cancer\")\n",
        "            if any(x in text_lower for x in [\"alzheimer\", \"dementia\", \"memory loss\", \"cognitive decline\"]):\n",
        "                disease_focus.append(\"alzheimers\")\n",
        "            if \"asthma\" in text_lower or \"wheezing\" in text_lower:\n",
        "                disease_focus.append(\"asthma\")\n",
        "            if any(x in text_lower for x in [\"heart failure\", \"cardiovascular\", \"hypertension\",\n",
        "                                             \"high blood pressure\", \"angina\", \"myocardial\", \"coronary\", \"stroke\"]):\n",
        "                disease_focus.append(\"cardiovascular\")\n",
        "\n",
        "            if any(kw in text_lower for kw in [\"trial\", \"study\", \"research\", \"clinical\"]):\n",
        "                intent = \"trial_search\"\n",
        "                query_type = \"trial_query\"\n",
        "            elif any(kw in text_lower for kw in [\"hi\", \"hello\", \"hey\"]):\n",
        "                intent = \"greeting\"\n",
        "                query_type = \"greeting\"\n",
        "            else:\n",
        "                intent = \"general_question\"\n",
        "                query_type = \"knowledge_seeking\"\n",
        "\n",
        "            parsed = {\n",
        "                \"intent\": intent,\n",
        "                \"query_type\": query_type,\n",
        "                \"search_keywords\": [text] if intent == \"trial_search\" else [],\n",
        "                \"is_disease_related\": bool(disease_focus),\n",
        "                \"disease_focus\": disease_focus,\n",
        "                \"user_question\": text,\n",
        "                \"trial_interest\": \"general\",\n",
        "            }\n",
        "\n",
        "        # --- Heuristic correction layer on top of model output ---\n",
        "        text_lower = text.lower()\n",
        "        diseases = set(parsed.get(\"disease_focus\") or [])\n",
        "\n",
        "        if any(x in text_lower for x in [\"diabetes\", \"insulin\", \"glucose\", \"hba1c\", \"metformin\", \"glp-1\", \"sglt2\"]):\n",
        "            diseases.add(\"diabetes\")\n",
        "        if any(x in text_lower for x in [\"cancer\", \"tumor\", \"tumour\", \"chemo\", \"chemotherapy\", \"oncology\"]):\n",
        "            diseases.add(\"cancer\")\n",
        "        if any(x in text_lower for x in [\"alzheimer\", \"alzheimers\", \"dementia\", \"memory loss\", \"cognitive decline\"]):\n",
        "            diseases.add(\"alzheimers\")\n",
        "        if \"asthma\" in text_lower or \"wheezing\" in text_lower or \"inhaler\" in text_lower:\n",
        "            diseases.add(\"asthma\")\n",
        "        if any(x in text_lower for x in [\"heart failure\", \"cardiovascular\", \"hypertension\",\n",
        "                                         \"high blood pressure\", \"angina\", \"myocardial\", \"coronary\", \"stroke\"]):\n",
        "            diseases.add(\"cardiovascular\")\n",
        "\n",
        "        parsed[\"disease_focus\"] = list(diseases)\n",
        "\n",
        "        # Force trial_search if obvious trial keywords\n",
        "        trial_keywords = [\n",
        "            \"trial\", \"study\", \"studies\", \"research\",\n",
        "            \"clinical\", \"show me\", \"are there\", \"what trials\"\n",
        "        ]\n",
        "        if any(kw in text_lower for kw in trial_keywords):\n",
        "            parsed[\"intent\"] = \"trial_search\"\n",
        "            parsed[\"query_type\"] = \"trial_query\"\n",
        "\n",
        "        # If we detected diseases, ensure is_disease_related = True\n",
        "        if diseases and parsed.get(\"intent\") != \"off_topic\":\n",
        "            parsed[\"is_disease_related\"] = True\n",
        "        elif \"is_disease_related\" not in parsed:\n",
        "            parsed[\"is_disease_related\"] = bool(diseases)\n",
        "\n",
        "        log = log_provenance_step(\"SymptomParser\", text, parsed)\n",
        "        return parsed, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PROFILE AGENT\n",
        "# ============================================================\n",
        "class ProfileAgent:\n",
        "    def __init__(self, initial_profile: Dict[str, Any] = None):\n",
        "        if initial_profile is None:\n",
        "            initial_profile = {\n",
        "                \"user_id\": \"Patient\",\n",
        "                \"conditions\": [],          # could be filled later\n",
        "                \"extracted_conditions\": [],  # dynamic memory\n",
        "                \"history\": [],\n",
        "            }\n",
        "        self.profile = initial_profile\n",
        "\n",
        "    def update_profile(self, turn_data: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Updates history and extracts persistent medical entities.\n",
        "        \"\"\"\n",
        "        self.profile.setdefault(\"history\", []).append(turn_data)\n",
        "        self.profile.setdefault(\"extracted_conditions\", [])\n",
        "\n",
        "        parsed = turn_data.get(\"parsed\", {})\n",
        "        # optional: keep disease_focus as conditions\n",
        "        diseases = parsed.get(\"disease_focus\") or []\n",
        "        if diseases:\n",
        "            current = set(self.profile[\"extracted_conditions\"])\n",
        "            for d in diseases:\n",
        "                current.add(d)\n",
        "            self.profile[\"extracted_conditions\"] = list(current)\n",
        "\n",
        "        snapshot = {\n",
        "            \"user_id\": self.profile.get(\"user_id\", \"Patient\"),\n",
        "            \"known_conditions\": self.profile.get(\"extracted_conditions\", []),\n",
        "            \"num_turns\": len(self.profile[\"history\"]),\n",
        "        }\n",
        "        log = log_provenance_step(\"ProfileAgent\", turn_data, {\"profile_snapshot\": snapshot})\n",
        "        return log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# EVIDENCE-WEIGHTED SCORER\n",
        "# ============================================================\n",
        "class EvidenceWeightedScorer:\n",
        "    \"\"\"\n",
        "    Implements evidence-weighted scoring for clinical trials.\n",
        "    Ranks trials based on multiple quality factors beyond semantic similarity.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.status_weights = {\n",
        "            \"Completed\": 1.0,\n",
        "            \"Active, Not Recruiting\": 0.9,\n",
        "            \"Recruiting\": 0.85,\n",
        "            \"Enrolling By Invitation\": 0.8,\n",
        "            \"Not Yet Recruiting\": 0.6,\n",
        "            \"Terminated\": 0.4,\n",
        "            \"Withdrawn\": 0.3,\n",
        "            \"Suspended\": 0.3,\n",
        "            \"Unknown Status\": 0.5,\n",
        "        }\n",
        "\n",
        "        self.design_keywords = {\n",
        "            \"randomized controlled\": 1.0,\n",
        "            \"double-blind\": 0.95,\n",
        "            \"randomized\": 0.9,\n",
        "            \"controlled\": 0.85,\n",
        "            \"interventional\": 0.8,\n",
        "            \"prospective\": 0.75,\n",
        "            \"observational\": 0.6,\n",
        "            \"retrospective\": 0.5,\n",
        "        }\n",
        "\n",
        "    def calculate_weighted_score(\n",
        "        self,\n",
        "        trial: Dict[str, Any],\n",
        "        base_confidence: float,\n",
        "        query: str,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Calculate evidence-weighted score for a trial.\n",
        "        \"\"\"\n",
        "\n",
        "        # Factor 1: Base semantic match (35%)\n",
        "        match_score = base_confidence * 0.35\n",
        "\n",
        "        # Factor 2: Trial status quality (25%)\n",
        "        status = str(trial.get(\"status\", \"Unknown Status\")).strip().title()\n",
        "        status_score = self.status_weights.get(status, 0.5) * 0.25\n",
        "\n",
        "        # Factor 3: Study design quality (20%)\n",
        "        design_score = self._calculate_design_quality(trial) * 0.20\n",
        "\n",
        "        # Factor 4: Keyword density (10%)\n",
        "        keyword_score = self._calculate_keyword_density(trial, query) * 0.10\n",
        "\n",
        "        # Factor 5: Metadata completeness (10%)\n",
        "        completeness_score = self._calculate_completeness(trial) * 0.10\n",
        "\n",
        "        weighted_score = (\n",
        "            match_score +\n",
        "            status_score +\n",
        "            design_score +\n",
        "            keyword_score +\n",
        "            completeness_score\n",
        "        )\n",
        "\n",
        "        breakdown = {\n",
        "            \"base_confidence\": base_confidence,\n",
        "            \"weighted_score\": weighted_score,\n",
        "            \"factors\": {\n",
        "                \"semantic_match\": match_score,\n",
        "                \"trial_status\": status_score,\n",
        "                \"study_design\": design_score,\n",
        "                \"keyword_density\": keyword_score,\n",
        "                \"completeness\": completeness_score,\n",
        "            },\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"weighted_score\": min(weighted_score, 1.0),\n",
        "            \"breakdown\": breakdown,\n",
        "        }\n",
        "\n",
        "    def _calculate_design_quality(self, trial: Dict[str, Any]) -> float:\n",
        "        text = f\"{trial.get('title', '')} {trial.get('text', '')}\".lower()\n",
        "        max_score = 0.0\n",
        "        for keyword, weight in self.design_keywords.items():\n",
        "            if keyword in text:\n",
        "                max_score = max(max_score, weight)\n",
        "        return max_score if max_score > 0 else 0.6\n",
        "\n",
        "    def _calculate_keyword_density(self, trial: Dict[str, Any], query: str) -> float:\n",
        "        text = f\"{trial.get('title', '')} {trial.get('text', '')}\".lower()\n",
        "        stopwords = {\n",
        "            \"the\", \"a\", \"an\", \"and\", \"or\", \"for\", \"with\", \"in\", \"on\", \"at\", \"to\",\n",
        "            \"of\", \"is\", \"are\", \"what\", \"trials\", \"trial\", \"study\", \"studies\", \"clinical\"\n",
        "        }\n",
        "        query_terms = [\n",
        "            term for term in query.lower().split()\n",
        "            if term not in stopwords and len(term) > 2\n",
        "        ]\n",
        "        if not query_terms:\n",
        "            return 0.5\n",
        "        matches = sum(1 for term in query_terms if term in text)\n",
        "        density = matches / len(query_terms)\n",
        "        return min(density, 1.0)\n",
        "\n",
        "    def _calculate_completeness(self, trial: Dict[str, Any]) -> float:\n",
        "        # Our chunk_map has \"title\" and \"text\"; treat longer text as more complete\n",
        "        text = trial.get(\"text\", \"\") or \"\"\n",
        "        title = trial.get(\"title\", \"\") or \"\"\n",
        "        score = 0.0\n",
        "        if len(title) > 10:\n",
        "            score += 0.3\n",
        "        if len(text) > 200:\n",
        "            score += 0.7\n",
        "        return min(score, 1.0)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PubMed Helper (NCT ‚Üí PubMed abstract)\n",
        "# ============================================================\n",
        "def fetch_pubmed_abstract_for_nct(nct_id: str):\n",
        "    \"\"\"\n",
        "    Try to find a PubMed article linked to this NCT ID and return its abstract.\n",
        "    Returns: {\"pmid\": str, \"abstract\": str} or None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        esearch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "        params = {\n",
        "            \"db\": \"pubmed\",\n",
        "            \"term\": f\"{nct_id}[si]\",\n",
        "            \"retmode\": \"json\",\n",
        "            \"retmax\": 1,\n",
        "        }\n",
        "        r = requests.get(esearch_url, params=params, timeout=10)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        idlist = data.get(\"esearchresult\", {}).get(\"idlist\", [])\n",
        "        if not idlist:\n",
        "            return None\n",
        "\n",
        "        pmid = idlist[0]\n",
        "\n",
        "        efetch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "        params = {\n",
        "            \"db\": \"pubmed\",\n",
        "            \"id\": pmid,\n",
        "            \"rettype\": \"abstract\",\n",
        "            \"retmode\": \"text\",\n",
        "        }\n",
        "        r2 = requests.get(efetch_url, params=params, timeout=10)\n",
        "        r2.raise_for_status()\n",
        "        abstract_text = r2.text.strip()\n",
        "        if not abstract_text:\n",
        "            return None\n",
        "\n",
        "        return {\"pmid\": pmid, \"abstract\": abstract_text}\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# RETRIEVAL AGENT\n",
        "# ============================================================\n",
        "class RetrievalAgent:\n",
        "    def __init__(self, embed_model, faiss_index, chunk_map, profile_agent: ProfileAgent = None):\n",
        "        self.embed_model = embed_model\n",
        "        self.index = faiss_index\n",
        "        self.chunk_map = chunk_map\n",
        "        self.profile_agent = profile_agent\n",
        "        self.evidence_scorer = EvidenceWeightedScorer()\n",
        "\n",
        "    def retrieve(self, parsed: Dict[str, Any], top_k: int = 5):\n",
        "        FETCH_K = top_k * 3\n",
        "\n",
        "        symptoms = parsed.get(\"symptoms\") or []\n",
        "        context = parsed.get(\"context\") or \"\"\n",
        "        query = parsed.get(\"user_question\") or (\" \".join(symptoms) + \" \" + context).strip()\n",
        "\n",
        "        if not query:\n",
        "            retrieval = {\"query\": \"\", \"trials\": [], \"avg_confidence\": 0.0}\n",
        "            log = log_provenance_step(\"RetrievalAgent\", parsed, retrieval, {\"reason\": \"empty_query\"})\n",
        "            return retrieval, log\n",
        "\n",
        "        # Simple expansions (still useful across diseases)\n",
        "        EXPANSIONS = {\n",
        "            \"insulin\": \"insulin OR insulin therapy OR insulin treatment OR insulin pump\",\n",
        "            \"medication\": \"medication OR drug OR pharmaceutical OR pharmacological OR treatment\",\n",
        "            \"diet\": \"diet OR dietary OR nutrition OR nutritional OR eating\",\n",
        "            \"exercise\": \"exercise OR physical activity OR fitness OR activity\",\n",
        "            \"chemo\": \"chemotherapy OR antineoplastic OR oncology\",\n",
        "            \"cancer\": \"cancer OR tumor OR tumour OR malignancy OR oncology\",\n",
        "            \"alzheim\": \"alzheimer OR dementia OR cognitive decline OR memory loss\",\n",
        "        }\n",
        "\n",
        "        query_lower = query.lower()\n",
        "        for term, expansion in EXPANSIONS.items():\n",
        "            if term in query_lower:\n",
        "                query = f\"{query} {expansion}\"\n",
        "                break\n",
        "\n",
        "        # 1. FAISS retrieval\n",
        "        q_emb = self.embed_model.encode([query])\n",
        "        distances, indices = self.index.search(q_emb.astype(\"float32\"), FETCH_K)\n",
        "\n",
        "        initial_candidates = []\n",
        "        for rank, idx in enumerate(indices[0]):\n",
        "            if idx == -1:\n",
        "                continue\n",
        "            item = self.chunk_map[idx]\n",
        "            dist = float(distances[0][rank])\n",
        "            initial_candidates.append({\n",
        "                \"nct_id\": item[\"nct_id\"],\n",
        "                \"title\": item.get(\"title\", \"\"),\n",
        "                \"text\": item[\"text\"],\n",
        "                \"status\": item.get(\"status\", \"Unknown Status\"),\n",
        "                \"faiss_dist\": dist,\n",
        "            })\n",
        "\n",
        "        final_trials = []\n",
        "        confs = []\n",
        "\n",
        "        # 2. Optional CrossEncoder reranking\n",
        "        if reranker and initial_candidates:\n",
        "            pairs = [[query, cand[\"text\"]] for cand in initial_candidates]\n",
        "            scores = reranker.predict(pairs)\n",
        "\n",
        "            for i, cand in enumerate(initial_candidates):\n",
        "                cand[\"rerank_score\"] = float(scores[i])\n",
        "\n",
        "            initial_candidates.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                logit = item[\"rerank_score\"]\n",
        "                base_conf = 1 / (1 + np.exp(-logit))\n",
        "\n",
        "                scoring_result = self.evidence_scorer.calculate_weighted_score(\n",
        "                    trial=item,\n",
        "                    base_confidence=base_conf,\n",
        "                    query=query,\n",
        "                )\n",
        "\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"title\"],\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": base_conf,\n",
        "                    \"weighted_score\": scoring_result[\"weighted_score\"],\n",
        "                    \"score_breakdown\": scoring_result[\"breakdown\"],\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"evidence_weighted\",\n",
        "                })\n",
        "\n",
        "            final_trials.sort(key=lambda x: x[\"weighted_score\"], reverse=True)\n",
        "            for i, trial in enumerate(final_trials):\n",
        "                trial[\"rank\"] = i + 1\n",
        "\n",
        "            confs = [t[\"weighted_score\"] for t in final_trials]\n",
        "\n",
        "        else:\n",
        "            # FAISS-only path\n",
        "            top_hits = initial_candidates[:top_k]\n",
        "            for rank, item in enumerate(top_hits):\n",
        "                base_conf = calculate_confidence_score(item[\"faiss_dist\"])\n",
        "                scoring_result = self.evidence_scorer.calculate_weighted_score(\n",
        "                    trial=item,\n",
        "                    base_confidence=base_conf,\n",
        "                    query=query,\n",
        "                )\n",
        "                final_trials.append({\n",
        "                    \"nct_id\": item[\"nct_id\"],\n",
        "                    \"title\": item[\"title\"],\n",
        "                    \"text\": item[\"text\"],\n",
        "                    \"status\": item[\"status\"],\n",
        "                    \"confidence\": base_conf,\n",
        "                    \"weighted_score\": scoring_result[\"weighted_score\"],\n",
        "                    \"score_breakdown\": scoring_result[\"breakdown\"],\n",
        "                    \"rank\": rank + 1,\n",
        "                    \"method\": \"evidence_weighted_faiss\",\n",
        "                })\n",
        "\n",
        "            final_trials.sort(key=lambda x: x[\"weighted_score\"], reverse=True)\n",
        "            for i, trial in enumerate(final_trials):\n",
        "                trial[\"rank\"] = i + 1\n",
        "\n",
        "            confs = [t[\"weighted_score\"] for t in final_trials]\n",
        "\n",
        "        avg_conf = float(np.mean(confs)) if confs else 0.0\n",
        "\n",
        "        retrieval = {\n",
        "            \"query\": query,\n",
        "            \"trials\": final_trials,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "        }\n",
        "\n",
        "        detail = {\n",
        "            \"top_k\": top_k,\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"num_trials\": len(final_trials),\n",
        "            \"method\": \"reranked\" if reranker else \"faiss_only\",\n",
        "        }\n",
        "\n",
        "        log = log_provenance_step(\"RetrievalAgent\", parsed, retrieval, detail)\n",
        "        return retrieval, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# DIAGNOSIS / ADVISOR\n",
        "# ============================================================\n",
        "class DiagnosisAdvisor:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def _handle_general_question(self, parsed: Dict[str, Any], retrieved: Dict[str, Any]):\n",
        "        \"\"\"Handle general medical knowledge questions.\"\"\"\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        user_question = parsed.get(\"user_question\") or \" \".join(parsed.get(\"symptoms\", []))\n",
        "\n",
        "        evidence_parts = []\n",
        "        for t in trials[:3]:\n",
        "            evidence_parts.append(f\"Trial {t['nct_id']}: {t['text'][:400]}\")\n",
        "        evidence = \"\\n\\n\".join(evidence_parts) if evidence_parts else \"No specific trials available.\"\n",
        "\n",
        "        prompt = (\n",
        "            \"You are a medical research educator. Answer the user's question clearly using reliable medical knowledge.\\n\"\n",
        "            \"The clinical trial evidence below provides real-world context - mention it if helpful.\\n\\n\"\n",
        "            f\"USER'S QUESTION: {user_question}\\n\\n\"\n",
        "            \"CLINICAL TRIAL CONTEXT (for reference only):\\n\"\n",
        "            f\"{evidence}\\n\\n\"\n",
        "            \"Instructions:\\n\"\n",
        "            \"- Answer the question directly in 3‚Äì5 sentences.\\n\"\n",
        "            \"- Be specific and educational.\\n\"\n",
        "            \"- Do NOT give diagnoses or treatment instructions.\\n\"\n",
        "            \"- End with: 'For personalized advice, please consult your healthcare provider.'\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(prompt)\n",
        "            text = (res.text or \"\").strip()\n",
        "            if not text or len(text) < 50:\n",
        "                text = (\n",
        "                    \"I don't have enough information to answer this question accurately. \"\n",
        "                    \"For personalized guidance, please consult your healthcare provider.\"\n",
        "                )\n",
        "            return text\n",
        "        except Exception:\n",
        "            return (\n",
        "                \"I'm unable to generate a detailed answer right now. \"\n",
        "                \"For personalized guidance, please consult your healthcare provider.\"\n",
        "            )\n",
        "\n",
        "    def _handle_symptom_query(\n",
        "        self,\n",
        "        parsed: Dict[str, Any],\n",
        "        retrieved: Dict[str, Any],\n",
        "        profile: Dict[str, Any],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Generate response for clinical trial search queries with\n",
        "        readable paragraph summaries and PubMed abstracts when available.\n",
        "        \"\"\"\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        if not trials:\n",
        "            return \"No relevant trials were found. Please try refining your query.\"\n",
        "\n",
        "        formatted_trials = []\n",
        "        for t in trials[:5]:\n",
        "            title = t.get(\"title\", \"\") or t[\"text\"].split(\"\\n\")[0].replace(\"Title: \", \"\")\n",
        "            status = t.get(\"status\", \"Unknown\")\n",
        "            weighted_score = t.get(\"weighted_score\", 0.0)\n",
        "\n",
        "            # Extract the ClinicalTrials.gov summary text\n",
        "            raw_text = t.get(\"text\", \"\")\n",
        "            brief_summary = raw_text.split(\"Summary:\", 1)[-1].strip() if \"Summary:\" in raw_text else raw_text\n",
        "\n",
        "            if brief_summary:\n",
        "                # Ask Gemini to turn the CT.gov summary into a short paragraph\n",
        "                prompt = (\n",
        "                    \"Rewrite the following clinical trial description as a short, clear paragraph \"\n",
        "                    \"about what the study is testing:\\n\\n\"\n",
        "                    f\"{brief_summary}\\n\\n\"\n",
        "                    \"Guidelines:\\n\"\n",
        "                    \"- Use 2‚Äì4 sentences.\\n\"\n",
        "                    \"- Plain English, minimal jargon.\\n\"\n",
        "                    \"- Include the purpose and the main type of participant.\\n\"\n",
        "                )\n",
        "                try:\n",
        "                    res = self.model.generate_content(prompt)\n",
        "                    brief_summary = res.text.strip() if res.text else brief_summary\n",
        "                except Exception:\n",
        "                    if len(brief_summary) > 600:\n",
        "                        brief_summary = brief_summary[:600] + \"...\"\n",
        "            else:\n",
        "                brief_summary = \"No summary available.\"\n",
        "\n",
        "            # PubMed abstract lookup\n",
        "            pubmed_block = \"\"\n",
        "            pub = fetch_pubmed_abstract_for_nct(t[\"nct_id\"])\n",
        "            if pub:\n",
        "                abs_text = pub[\"abstract\"]\n",
        "                max_len = 2000\n",
        "                if len(abs_text) > max_len:\n",
        "                    abs_text = abs_text[:max_len] + \"...\"\n",
        "                pubmed_block = (\n",
        "                    f\"  PubMed abstract (PMID {pub['pmid']}):\\n\"\n",
        "                    f\"  {abs_text}\\n\\n\"\n",
        "                    f\"  PubMed link: https://pubmed.ncbi.nlm.nih.gov/{pub['pmid']}/\\n\\n\"\n",
        "                )\n",
        "\n",
        "            formatted_trials.append(\n",
        "                f\"**{t['nct_id']}** (Relevance: {weighted_score:.0%})\\n\"\n",
        "                f\"‚Ä¢ {title}\\n\"\n",
        "                f\"  Status: {status}\\n\\n\"\n",
        "                f\"  {brief_summary}\\n\\n\"\n",
        "                f\"{pubmed_block}\"\n",
        "            )\n",
        "\n",
        "        trials_text = \"\\n\\n\".join(formatted_trials)\n",
        "        num_trials = len(formatted_trials)\n",
        "\n",
        "        response = (\n",
        "            f\"I found {num_trials} clinical trial{'s' if num_trials != 1 else ''} relevant to your request:\\n\\n\"\n",
        "            f\"{trials_text}\\n\\n\"\n",
        "            \"Summary: These trials explore potential treatments or management strategies for the condition you asked about. \"\n",
        "            \"More details are available using the listed NCT IDs.\\n\\n\"\n",
        "            \"To learn more or consider participation, visit clinicaltrials.gov and search by NCT ID. \"\n",
        "            \"Always discuss clinical trial options with your healthcare provider.\"\n",
        "        )\n",
        "\n",
        "        return response\n",
        "\n",
        "    def advise(self, parsed: Dict[str, Any], retrieved: Dict[str, Any], profile: Dict[str, Any]):\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "        avg_conf = retrieved.get(\"avg_confidence\", 0.0)\n",
        "        query_type = parsed.get(\"query_type\", \"trial_query\")\n",
        "        is_disease_related = parsed.get(\"is_disease_related\", True)\n",
        "\n",
        "        draft = {\n",
        "            \"recommendation\": \"\",\n",
        "            \"avg_confidence\": avg_conf,\n",
        "            \"query_type\": query_type,\n",
        "        }\n",
        "\n",
        "        if not is_disease_related:\n",
        "            draft[\"recommendation\"] = (\n",
        "                \"I‚Äôm specialized in clinical trials for medical conditions (for example diabetes, cancer, \"\n",
        "                \"Alzheimer‚Äôs disease, asthma, and cardiovascular diseases). \"\n",
        "                \"Your question does not appear to be about a health condition or clinical research. \"\n",
        "                \"If you‚Äôd like, you can ask me about trials for a specific condition.\"\n",
        "            )\n",
        "            draft[\"confidence_veto\"] = True\n",
        "            log = log_provenance_step(\n",
        "                \"DiagnosisAdvisor\",\n",
        "                parsed,\n",
        "                draft,\n",
        "                {\"veto\": True, \"reason\": \"off_topic\"},\n",
        "            )\n",
        "            return draft, log\n",
        "\n",
        "        if not trials or avg_conf < 0.05:\n",
        "            draft[\"recommendation\"] = (\n",
        "                \"Based on the trials I retrieved, I don‚Äôt have strong enough evidence to answer this question directly. \"\n",
        "                \"Please consult your healthcare provider for personalized advice.\"\n",
        "            )\n",
        "            draft[\"confidence_veto\"] = True\n",
        "            log = log_provenance_step(\n",
        "                \"DiagnosisAdvisor\",\n",
        "                parsed,\n",
        "                draft,\n",
        "                {\"veto\": True, \"reason\": \"low_confidence\"},\n",
        "            )\n",
        "            return draft, log\n",
        "\n",
        "        if query_type == \"knowledge_seeking\":\n",
        "            draft[\"recommendation\"] = self._handle_general_question(parsed, retrieved)\n",
        "        else:\n",
        "            draft[\"recommendation\"] = self._handle_symptom_query(parsed, retrieved, profile)\n",
        "\n",
        "        draft[\"confidence_veto\"] = False\n",
        "        log = log_provenance_step(\"DiagnosisAdvisor\", parsed, draft)\n",
        "        return draft, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SAFETY FILTER\n",
        "# ============================================================\n",
        "class ActiveSafetyFilter:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.safety_cfg = {\n",
        "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "        }\n",
        "\n",
        "    def verify(self, advice_text: str, trials: List[Dict[str, Any]]):\n",
        "        # Skip safety check for list-type responses about trials\n",
        "        if any(marker in advice_text for marker in [\"NCT\", \"clinical trial\", \"clinicaltrials.gov\"]):\n",
        "            log = log_provenance_step(\n",
        "                \"ActiveSafetyFilter\",\n",
        "                {\"advice\": advice_text},\n",
        "                {\"final_text\": advice_text, \"status\": \"Pass (Trial Listing)\"},\n",
        "            )\n",
        "            return advice_text, \"Pass (Trial Listing)\", log\n",
        "\n",
        "        evidence_text = \"\\n\".join(t[\"text\"][:500] for t in trials[:3])\n",
        "\n",
        "        audit_prompt = (\n",
        "            \"You are a Medical Safety Officer reviewing AI-generated advice.\\n\\n\"\n",
        "            \"ADVICE:\\n\"\n",
        "            f\"{advice_text}\\n\\n\"\n",
        "            \"EVIDENCE FROM CLINICAL TRIALS (for context):\\n\"\n",
        "            f\"{evidence_text}\\n\\n\"\n",
        "            \"Check for safety issues:\\n\"\n",
        "            \"- If the advice suggests starting/stopping/changing medication without a doctor ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it gives a diagnosis ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it makes strong clinical claims not supported by evidence ‚Üí UNSAFE.\\n\"\n",
        "            \"- If it simply lists clinical trials with neutral wording and a recommendation to talk to a doctor ‚Üí SAFE.\\n\\n\"\n",
        "            \"If the advice is acceptable, respond with exactly: SAFE\\n\"\n",
        "            \"If it is not acceptable, respond starting with: CORRECTED: <safer version>\\n\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            res = self.model.generate_content(audit_prompt, safety_settings=self.safety_cfg)\n",
        "            txt = (res.text or \"\").strip()\n",
        "            if txt.startswith(\"SAFE\") or \"SAFE\" in txt:\n",
        "                final_text = advice_text\n",
        "                status = \"Pass\"\n",
        "            else:\n",
        "                final_text = f\"‚ö†Ô∏è SAFETY REVISION:\\n{txt}\"\n",
        "                status = \"Revised\"\n",
        "        except Exception:\n",
        "            if \"NCT\" in advice_text or \"clinical trial\" in advice_text.lower():\n",
        "                final_text = advice_text\n",
        "                status = \"Pass (API Fallback)\"\n",
        "            else:\n",
        "                final_text = \"‚ö†Ô∏è Safety filter triggered. Please consult a doctor.\"\n",
        "                status = \"Revised (API Error)\"\n",
        "\n",
        "        log = log_provenance_step(\n",
        "            \"ActiveSafetyFilter\",\n",
        "            {\"advice\": advice_text},\n",
        "            {\"final_text\": final_text, \"status\": status},\n",
        "        )\n",
        "        return final_text, status, log\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# HEALTHCAREBOT - Updated to use Qdrant\n",
        "# ============================================================\n",
        "\n",
        "class HealthcareBot:\n",
        "    def __init__(self, qdrant_client, embed_model, gemini_model, initial_profile=None):\n",
        "        self.parser = SymptomParser(gemini_model)\n",
        "        self.profile_agent = ProfileAgent(initial_profile)\n",
        "        self.evidence_scorer = EvidenceWeightedScorer()\n",
        "\n",
        "        # NEW: Use Qdrant retrieval agent\n",
        "        self.retrieval = RetrievalAgentQdrant(\n",
        "            qdrant_client=qdrant_client,\n",
        "            embed_model=embed_model,\n",
        "            evidence_scorer=self.evidence_scorer,\n",
        "            profile_agent=self.profile_agent\n",
        "        )\n",
        "\n",
        "        self.advisor = DiagnosisAdvisor(gemini_model)\n",
        "        self.safety_filter = ActiveSafetyFilter(gemini_model)\n",
        "        self.conversation_history = []\n",
        "        self.provenance_log = []\n",
        "\n",
        "\n",
        "    def chat(self, user_input: str) -> Dict[str, Any]:\n",
        "        \"\"\"Process user input through the pipeline.\"\"\"\n",
        "\n",
        "        # Parse intent\n",
        "        parsed, parse_log = self.parser.parse(user_input)\n",
        "        self.provenance_log.append(parse_log)\n",
        "\n",
        "        # Update profile\n",
        "        turn_data = {\"query\": user_input, \"parsed\": parsed}\n",
        "        profile_log = self.profile_agent.update_profile(turn_data)\n",
        "        self.provenance_log.append(profile_log)\n",
        "\n",
        "        # Retrieve trials (now from Qdrant!)\n",
        "        retrieved, retrieval_log = self.retrieval.retrieve(parsed, top_k=5)\n",
        "        self.provenance_log.append(retrieval_log)\n",
        "\n",
        "        # Generate response\n",
        "        profile_snapshot = {\n",
        "            \"user_id\": self.profile_agent.profile.get(\"user_id\", \"Patient\"),\n",
        "            \"known_conditions\": self.profile_agent.profile.get(\"extracted_conditions\", []),\n",
        "        }\n",
        "\n",
        "\n",
        "        draft, advisor_log = self.advisor.advise(parsed, retrieved, profile_snapshot)\n",
        "        self.provenance_log.append(advisor_log)\n",
        "\n",
        "        # Safety filter - FIXED: verify() returns (text, status, log)\n",
        "        advice_text = draft.get(\"recommendation\", \"\") if isinstance(draft, dict) else str(draft)\n",
        "        trials = retrieved.get(\"trials\", [])\n",
        "\n",
        "        final_response, safety_status, safety_log = self.safety_filter.verify(advice_text, trials)\n",
        "        self.provenance_log.append(safety_log)\n",
        "\n",
        "        # Save turn\n",
        "        full_turn = {\n",
        "            \"query\": user_input,\n",
        "            \"parsed\": parsed,\n",
        "            \"retrieved\": retrieved,\n",
        "            \"response\": final_response,\n",
        "            \"timestamp\": parse_log[\"timestamp\"],\n",
        "        }\n",
        "        self.conversation_history.append(full_turn)\n",
        "\n",
        "        return {\n",
        "            \"response\": final_response,\n",
        "            \"avg_confidence\": retrieved.get(\"avg_confidence\", 0.0),\n",
        "            \"num_trials\": len(retrieved.get(\"trials\", [])),\n",
        "            \"provenance\": self.provenance_log[-5:],\n",
        "            \"session_hash\": generate_reproducibility_hash(self.conversation_history),\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "def run_bot(user_input: str, qdrant_client, embed_model, gemini_model) -> Dict[str, Any]:\n",
        "    \"\"\"Convenience wrapper for single queries.\"\"\"\n",
        "    bot = HealthcareBot(qdrant_client, embed_model, gemini_model)\n",
        "    return bot.chat(user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilWN6ecnKaR8",
        "outputId": "a0f16414-17d7-45d3-95c2-6f48f348e32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(self, advice_text: str, trials: List[Dict[str, Any]])\n"
          ]
        }
      ],
      "source": [
        "# # Quick check - what does verify expect?\n",
        "# import inspect\n",
        "# from run_bot_qdrant import ActiveSafetyFilter\n",
        "\n",
        "# print(inspect.signature(ActiveSafetyFilter.verify))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKelNxetKaW6",
        "outputId": "fd424dfc-682d-472d-e79e-0671338d21e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        # Safety filter - FIXED: verify() returns (text, status, log)\n",
            "        advice_text = draft.get(\"recommendation\", \"\") if isinstance(draft, dict) else str(draft)\n",
            "        trials = retrieved.get(\"trials\", [])\n",
            "\n",
            "        final_response, safety_status, safety_log = self.safety_filter.verify(advice_text, trials)\n",
            "        self.provenance_log.append(safety_log)\n",
            "\n",
            "        # Save turn\n"
          ]
        }
      ],
      "source": [
        "# !sed -n '805,812p' /content/run_bot_qdrant.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "w4AX_Q9xKach",
        "outputId": "f4f4a77b-9205-447c-9709-52966151a7a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Loading Cross-Encoder reranker...\n",
            "‚úÖ Reranker loaded\n"
          ]
        }
      ],
      "source": [
        "# # Force reload the module\n",
        "# import sys\n",
        "# if 'run_bot_qdrant' in sys.modules:\n",
        "#     del sys.modules['run_bot_qdrant']\n",
        "\n",
        "# # Now import fresh\n",
        "# from run_bot_qdrant import run_bot\n",
        "\n",
        "# # Test again\n",
        "# result = run_bot(\n",
        "#     \"What trials are studying insulin therapy for diabetes?\",\n",
        "#     qdrant_client,\n",
        "#     embed_model,\n",
        "#     gemini_model\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLR9-TISTbCa",
        "outputId": "ae443e13-f84c-4ca5-e6de-93d465b72c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    def verify(self, advice_text: str, trials: List[Dict[str, Any]]):\n",
            "        # Skip safety check for list-type responses about trials\n",
            "        if any(marker in advice_text for marker in [\"NCT\", \"clinical trial\", \"clinicaltrials.gov\"]):\n",
            "            log = log_provenance_step(\n",
            "                \"ActiveSafetyFilter\",\n",
            "                {\"advice\": advice_text},\n",
            "                {\"final_text\": advice_text, \"status\": \"Pass (Trial Listing)\"},\n",
            "            )\n",
            "            return advice_text, \"Pass (Trial Listing)\", log\n",
            "\n",
            "        evidence_text = \"\\n\".join(t[\"text\"][:500] for t in trials[:3])\n",
            "\n",
            "        audit_prompt = (\n",
            "            \"You are a Medical Safety Officer reviewing AI-generated advice.\\n\\n\"\n",
            "            \"ADVICE:\\n\"\n",
            "            f\"{advice_text}\\n\\n\"\n",
            "            \"EVIDENCE FROM CLINICAL TRIALS (for context):\\n\"\n",
            "            f\"{evidence_text}\\n\\n\"\n",
            "            \"Check for safety issues:\\n\"\n",
            "            \"- If the advice suggests starting/stopping/changing medication without a doctor ‚Üí UNSAFE.\\n\"\n",
            "            \"- If it gives a diagnosis ‚Üí UNSAFE.\\n\"\n",
            "            \"- If it makes strong clinical claims not supported by evidence ‚Üí UNSAFE.\\n\"\n",
            "            \"- If it simply lists clinical trials with neutral wording and a recommendation to talk to a doctor ‚Üí SAFE.\\n\\n\"\n",
            "            \"If the advice is acceptable, respond with exactly: SAFE\\n\"\n",
            "            \"If it is not acceptable, respond starting with: CORRECTED: <safer version>\\n\"\n",
            "        )\n",
            "\n",
            "        try:\n",
            "            res = self.model.generate_content(audit_prompt, safety_settings=self.safety_cfg)\n",
            "            txt = (res.text or \"\").strip()\n",
            "            if txt.startswith(\"SAFE\") or \"SAFE\" in txt:\n",
            "                final_text = advice_text\n",
            "                status = \"Pass\"\n",
            "            else:\n",
            "                final_text = f\"‚ö†Ô∏è SAFETY REVISION:\\n{txt}\"\n",
            "                status = \"Revised\"\n",
            "        except Exception:\n",
            "            if \"NCT\" in advice_text or \"clinical trial\" in advice_text.lower():\n",
            "                final_text = advice_text\n",
            "                status = \"Pass (API Fallback)\"\n",
            "            else:\n",
            "                final_text = \"‚ö†Ô∏è Safety filter triggered. Please consult a doctor.\"\n",
            "                status = \"Revised (API Error)\"\n",
            "\n",
            "        log = log_provenance_step(\n",
            "            \"ActiveSafetyFilter\",\n",
            "            {\"advice\": advice_text},\n",
            "            {\"final_text\": final_text, \"status\": status},\n",
            "        )\n",
            "        return final_text, status, log\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# import inspect\n",
        "# from run_bot_qdrant import ActiveSafetyFilter\n",
        "\n",
        "# # Show the FULL source code of verify\n",
        "# print(inspect.getsource(ActiveSafetyFilter.verify))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcktXAO0TbFZ",
        "outputId": "6c587226-96ba-4c8f-c1c6-068853ef91d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Modules cleared\n"
          ]
        }
      ],
      "source": [
        "# # Kill all cached modules\n",
        "# import sys\n",
        "# for key in list(sys.modules.keys()):\n",
        "#     if any(x in key for x in ['run_bot', 'utils_qdrant', 'retrieval_agent']):\n",
        "#         del sys.modules[key]\n",
        "\n",
        "# print(\"‚úÖ Modules cleared\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JBicUGwwTbJN",
        "outputId": "d4d4b67f-8372-4dce-b6b2-541b9910650d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîë Gemini API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "üîë Qdrant API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚è≥ Connecting to Qdrant...\n",
            "‚úÖ Connected to Qdrant: 146,593 vectors ready\n",
            "‚úÖ Embedding model loaded\n",
            "\n",
            "ü§ñ Testing bot...\n",
            "\n",
            "‚è≥ Loading Cross-Encoder reranker...\n",
            "‚úÖ Reranker loaded\n",
            "I found 5 clinical trials relevant to your request:\n",
            "\n",
            "**NCT04981808** (Relevance: 96%)\n",
            "‚Ä¢ Diabetes teleMonitoring of Patients in Insulin Therapy\n",
            "  Status: Completed\n",
            "\n",
            "  This study is testing whether monitoring patients with type 2 diabetes at home using electronic devices can improve their health. Participants who are already using insulin will be randomly assigned to either a group that uses home monitoring or a group that receives standard care. For three months, the health data from the home monitoring group will be tracked by hospital staff.\n",
            "\n",
            "  PubMed abstract (PMID 36476605):\n",
            "  1. Trials. 2022 Dec 7;23(1):985. doi: 10.1186/s13063-022-06921-6.\n",
            "\n",
            "The Diabetes teleMonitoring of patients in insulin Therapy (DiaMonT) trial: \n",
            "study protocol for a randomized controlled trial.\n",
            "\n",
            "Hangaard S(1)(2), Kronborg T(3)(4), Hejlesen O(4), Arad√≥ttir TB(5), Kaas A(5), \n",
            "Bengtsson H(5), Vestergaard P(4)(6)(7), Jensen MH(3)(4).\n",
            "\n",
            "Author information:\n",
            "(1)Steno Diabetes Center North Denmark, M√∏lleparkvej 4, 9000, Aalborg, Denmark. \n",
            "svh@hst.aau.dk.\n",
            "(2)Department of Health Science and Technology, Aalborg University, Fredrik \n",
            "Bajers Vej 7C, 9220, Aalborg √ò, Denmark. svh@hst.aau.dk.\n",
            "(3)Steno Diabetes Center North Denmark, M√∏lleparkvej 4, 9000, Aalborg, Denmark.\n",
            "(4)Department of Health Science and Technology, Aalborg University, Fredrik \n",
            "Bajers Vej 7C, 9220, Aalborg √ò, Denmark.\n",
            "(5)Novo Nordisk A/S, Novo Alle 1, 2880, Bagsv√¶rd, Denmark.\n",
            "(6)Department of Endocrinology, Aalborg University Hospital, Aalborg, Denmark.\n",
            "(7)Department of Clinical Medicine, Aalborg University, Aalborg, Denmark.\n",
            "\n",
            "BACKGROUND: The effect of telemedicine solutions in diabetes remains \n",
            "inconclusive. However, telemedicine studies have shown a positive trend in \n",
            "regards to glycemic control. The telemedicine interventions that facilitate \n",
            "adjustment of medication seems to improve glycemic control more effectively. \n",
            "Hence, it is recommended that future telemedicine studies for patients with \n",
            "diabetes include patient-specific suggestions for changes in medicine. Hence, \n",
            "the aim of the trial is to explore the effect of telemonitoring in patients with \n",
            "type 2 diabetes (T2D) on insulin therapy.\n",
            "METHODS: The trial is an open-label randomized controlled trial with a trial \n",
            "period of 3 months conducted in two sites in Denmark. Patients with T2D on \n",
            "insulin therapy will be randomized (1:1) to a telemonitoring group \n",
            "(intervention) or a usual care group (control). The telemonitoring group will \n",
            "use a continuous glucose monitor (CGM), an insulin pen, an activity tracker, and \n",
            "smartphone applications throughout the tr...\n",
            "\n",
            "  PubMed link: https://pubmed.ncbi.nlm.nih.gov/36476605/\n",
            "\n",
            "\n",
            "\n",
            "**NCT00806936** (Relevance: 91%)\n",
            "‚Ä¢ Observational Study to Investigate the Efficacy and Safety of Human Insulin or Insulin Analogue Treatments in Type 2 Diabetes Subjects\n",
            "  Status: Completed\n",
            "\n",
            "  This study in Asia aims to determine how well people with type 2 diabetes in China can control their blood sugar using either human insulin or newer insulin medicines. The study will observe people who are already taking two or more oral diabetes medications that aren't working well enough. Researchers will also monitor the safety of each type of insulin.\n",
            "\n",
            "\n",
            "\n",
            "**NCT00922649** (Relevance: 88%)\n",
            "‚Ä¢ Pilot Study Assessing Insulin Pump Therapy in Type 2 Diabetes\n",
            "  Status: Completed\n",
            "\n",
            "  This pilot study is testing the effectiveness of using an insulin pump to manage blood sugar in people with type 2 diabetes who haven't previously used one. The study will enroll participants whose blood sugar control is not adequate with oral medications alone, basal insulin with or without oral medications, or basal-bolus insulin with or without oral medications. All participants will begin using an insulin pump with rapid-acting insulin for 16 weeks to see if it improves their blood sugar levels.\n",
            "\n",
            "  PubMed abstract (PMID 21355725):\n",
            "  1. Diabetes Technol Ther. 2011 Apr;13(4):471-6. doi: 10.1089/dia.2010.0167. Epub \n",
            "2011 Feb 28.\n",
            "\n",
            "Associations between improved glucose control and patient-reported outcomes \n",
            "after initiation of insulin pump therapy in patients with type 2 diabetes \n",
            "mellitus.\n",
            "\n",
            "Peyrot M(1), Rubin RR, Chen X, Frias JP.\n",
            "\n",
            "Author information:\n",
            "(1)Loyola University Maryland, Baltimore, Maryland, USA. Mark.peyrot@gmail.com\n",
            "\n",
            "BACKGROUND: This study assessed the relationship between changes in glucose \n",
            "control and changes in patient-reported outcomes (PRO)--health-related quality \n",
            "of life (HR-QoL) and treatment satisfaction (TxSat)--in patients with type 2 \n",
            "diabetes initiating insulin pump therapy.\n",
            "METHODS: Patients (n = 54) initiating insulin pump therapy (Animas(¬Æ) 2020, \n",
            "Animas Corp., West Chester, PA) were studied for 16 weeks. Glucose control was \n",
            "measured with patient-blinded continuous glucose monitoring (CGM) (SEVEN(‚Ñ¢), \n",
            "DexCom, San Diego, CA) and unblinded glycosylated hemoglobin (A1C) and \n",
            "seven-point self-monitored blood glucose (SMBG) profiles. HR-QoL was measured \n",
            "using the Diabetes Symptom Checklist-Revised (DSC-R) and the EuroQol-5 \n",
            "Dimensions (EQ-5D). TxSat was measured using the Insulin Delivery System Rating \n",
            "Questionnaire (IDSRQ) clinical efficacy and treatment preference scales. \n",
            "Bivariate correlations assessed associations between measures of change from \n",
            "baseline.\n",
            "RESULTS: Decreased A1C was associated only with improvement in IDSRQ clinical \n",
            "efficacy. For CGM and SMBG, reductions in mean glucose concentrations were \n",
            "associated with decreased DSC-R symptoms, improved EQ-5D health utility, and \n",
            "increased IDSRQ perceived clinical efficacy and treatment preference. Reduced \n",
            "glycemic variability was associated with improved EQ-5D health utility and \n",
            "increased IDSRQ treatment preference. CGM and SMBG readings from different times \n",
            "of day/night were differentially associated with all PRO.\n",
            "CONCLUSIONS: Findings suggest that A1C, representing an \"average\" of both high \n",
            "and low blood...\n",
            "\n",
            "  PubMed link: https://pubmed.ncbi.nlm.nih.gov/21355725/\n",
            "\n",
            "\n",
            "\n",
            "**NCT00115973** (Relevance: 88%)\n",
            "‚Ä¢ A Study of the Treatment of Type 2 Diabetes With an Insulin Infusion Pump\n",
            "  Status: Completed\n",
            "\n",
            "  This U.S. study tests how safe and effective increasing doses of a drug are over a 3-week period for patients who are staying at a hospital. Following this initial phase, participants will continue the treatment as outpatients for 10 weeks, with a follow-up phone call after their final clinic visit. The study will monitor participants for a total of about 16 weeks.\n",
            "\n",
            "\n",
            "\n",
            "**NCT00537303** (Relevance: 86%)\n",
            "‚Ä¢ Comparison of the Blood Sugar Lowering Effect and Safety of Two Insulin Treatments in Type 2 Diabetes\n",
            "  Status: Completed\n",
            "\n",
            "  This international study compares the safety and effectiveness of two different insulin treatments for people with type 2 diabetes. Researchers are testing a \"basic\" insulin treatment against an \"advanced\" treatment option. The goal is to determine which treatment works better and is safer for managing blood sugar in adults with type 2 diabetes.\n",
            "\n",
            "  PubMed abstract (PMID 21550957):\n",
            "  1. Endocr Pract. 2011 Sep-Oct;17(5):727-36. doi: 10.4158/EP10367.OR.\n",
            "\n",
            "Comparison of 2 intensification regimens with rapid-acting insulin aspart in \n",
            "type 2 diabetes mellitus inadequately controlled by once-daily insulin detemir \n",
            "and oral antidiabetes drugs: the step-wise randomized study.\n",
            "\n",
            "Meneghini L(1), Mersebach H, Kumar S, Svendsen AL, Hermansen K.\n",
            "\n",
            "Author information:\n",
            "(1)Division of Endocrinology, Diabetes, and Metabolism, University of Miami \n",
            "Miller School of Medicine, Miami, Florida, USA. Lmeneghi@med.miami.edu\n",
            "\n",
            "OBJECTIVE: To compare the efficacy and safety of 2 intensification strategies \n",
            "for stepwise addition of prandial insulin aspart in patients with type 2 \n",
            "diabetes mellitus treated with insulin detemir.\n",
            "METHODS: This randomized, controlled, parallel-group, open-label, 48-week trial \n",
            "compared the stepwise addition of insulin aspart to either the largest meal \n",
            "(titration based on premeal glucose values [SimpleSTEP]) or to the meal with the \n",
            "largest prandial glucose increment (titration based on postmeal glucose values \n",
            "[ExtraSTEP]) in patients with type 2 diabetes inadequately controlled on basal \n",
            "insulin and oral antidiabetes drugs. After 12 weeks of basal insulin detemir \n",
            "dosage optimization, participants with a hemoglobin A1c level of 7% or greater \n",
            "entered three 12-week treatment periods with stepwise addition of a first \n",
            "insulin aspart bolus, then a second, and then a third, if hemoglobin A1c \n",
            "remained at 7% or greater after 12 and 24 weeks of treatment, respectively. \n",
            "Endpoints included hemoglobin A1c (primary endpoint), fasting plasma glucose, \n",
            "self-measured plasma glucose, adverse events, and hypoglycemia.\n",
            "RESULTS: Two hundred ninety-six patients were randomly assigned to treatment \n",
            "with insulin aspart in the SimpleSTEP (n = 150) and ExtraSTEP (n = 146) groups. \n",
            "Hemoglobin A1c decreased by approximately 1.2% in both groups, to 7.5 ¬± 1.1% \n",
            "(Simple-STEP) and 7.7 ¬± 1.2% (ExtraSTEP) at end of trial (estimated treatment \n",
            "difference, SimpleSTEP - ExtraST...\n",
            "\n",
            "  PubMed link: https://pubmed.ncbi.nlm.nih.gov/21550957/\n",
            "\n",
            "\n",
            "\n",
            "Summary: These trials explore potential treatments or management strategies for the condition you asked about. More details are available using the listed NCT IDs.\n",
            "\n",
            "To learn more or consider participation, visit clinicaltrials.gov and search by NCT ID. Always discuss clinical trial options with your healthcare provider.\n",
            "\n",
            "üìä Found 5 trials\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Setup keys\n",
        "gemini_key = getpass.getpass(\"üîë Gemini API Key: \")\n",
        "os.environ[\"GEMINI_API_KEY\"] = gemini_key\n",
        "\n",
        "qdrant_api_key = getpass.getpass(\"üîë Qdrant API Key: \")\n",
        "\n",
        "# Setup clients\n",
        "genai.configure(api_key=gemini_key)\n",
        "gemini_model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "from utils_qdrant import load_qdrant_and_model\n",
        "qdrant_url = \"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\"\n",
        "qdrant_client, embed_model = load_qdrant_and_model(qdrant_url, qdrant_api_key)\n",
        "\n",
        "# Import and test\n",
        "from run_bot_qdrant import run_bot\n",
        "\n",
        "print(\"\\nü§ñ Testing bot...\\n\")\n",
        "result = run_bot(\n",
        "    \"What trials are studying insulin therapy for diabetes?\",\n",
        "    qdrant_client,\n",
        "    embed_model,\n",
        "    gemini_model\n",
        ")\n",
        "\n",
        "print(result[\"response\"])\n",
        "print(f\"\\nüìä Found {result['num_trials']} trials\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUcIBKF0ZHer"
      },
      "source": [
        "Update Streamlit App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkcOXJy8Kajv",
        "outputId": "53cb39e2-df1d-4edd-a3d6-323a1b5b2d07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\"\"\"\n",
        "Streamlit UI for HealthcareBot with Qdrant backend\n",
        "\"\"\"\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "from typing import Dict, Any\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Import Qdrant utilities and bot\n",
        "from utils_qdrant import load_qdrant_and_model\n",
        "from run_bot_qdrant import HealthcareBot\n",
        "\n",
        "# Page config\n",
        "st.set_page_config(\n",
        "    page_title=\"Clinical Trials Search Assistant\",\n",
        "    page_icon=\"üè•\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# Title\n",
        "st.title(\"üè• Clinical Trials Search Assistant\")\n",
        "st.markdown(\"**Powered by Qdrant + Gemini 2.0 Flash**\")\n",
        "st.markdown(\"Search across 262,000+ clinical trials for diabetes, cancer, Alzheimer's, asthma, and cardiovascular disease.\")\n",
        "\n",
        "# Sidebar for API keys\n",
        "with st.sidebar:\n",
        "    st.header(\"‚öôÔ∏è Configuration\")\n",
        "\n",
        "    # Gemini API Key\n",
        "    gemini_key = st.text_input(\n",
        "        \"Gemini API Key\",\n",
        "        type=\"password\",\n",
        "        help=\"Enter your Gemini API key\"\n",
        "    )\n",
        "\n",
        "    # Qdrant API Key\n",
        "    qdrant_key = st.text_input(\n",
        "        \"Qdrant API Key\",\n",
        "        type=\"password\",\n",
        "        help=\"Enter your Qdrant API key\"\n",
        "    )\n",
        "\n",
        "    # Qdrant URL (pre-filled)\n",
        "    qdrant_url = st.text_input(\n",
        "        \"Qdrant Cluster URL\",\n",
        "        value=\"https://215ec69e-fa22-4f38-bcf3-941e73901a68.us-east4-0.gcp.cloud.qdrant.io\",\n",
        "        help=\"Your Qdrant cluster URL\"\n",
        "    )\n",
        "\n",
        "    st.divider()\n",
        "\n",
        "    # Info\n",
        "    st.markdown(\"### üìä System Status\")\n",
        "    if gemini_key and qdrant_key:\n",
        "        st.success(\"‚úÖ Keys configured\")\n",
        "    else:\n",
        "        st.warning(\"‚ö†Ô∏è Enter API keys to start\")\n",
        "\n",
        "# Initialize session state\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "if \"bot\" not in st.session_state:\n",
        "    st.session_state.bot = None\n",
        "\n",
        "if \"qdrant_client\" not in st.session_state:\n",
        "    st.session_state.qdrant_client = None\n",
        "\n",
        "if \"embed_model\" not in st.session_state:\n",
        "    st.session_state.embed_model = None\n",
        "\n",
        "# Initialize bot when keys are provided\n",
        "if gemini_key and qdrant_key and st.session_state.bot is None:\n",
        "    with st.spinner(\"üîÑ Initializing system...\"):\n",
        "        try:\n",
        "            # Setup Gemini\n",
        "            os.environ[\"GEMINI_API_KEY\"] = gemini_key\n",
        "            genai.configure(api_key=gemini_key)\n",
        "            gemini_model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "            # Setup Qdrant\n",
        "            qdrant_client, embed_model = load_qdrant_and_model(qdrant_url, qdrant_key)\n",
        "\n",
        "            # Store in session\n",
        "            st.session_state.qdrant_client = qdrant_client\n",
        "            st.session_state.embed_model = embed_model\n",
        "\n",
        "            # Initialize bot\n",
        "            st.session_state.bot = HealthcareBot(\n",
        "                qdrant_client=qdrant_client,\n",
        "                embed_model=embed_model,\n",
        "                gemini_model=gemini_model\n",
        "            )\n",
        "\n",
        "            st.success(\"‚úÖ System ready!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"‚ùå Initialization failed: {str(e)}\")\n",
        "\n",
        "# Display chat messages\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "        # Show metadata for assistant messages\n",
        "        if message[\"role\"] == \"assistant\" and \"metadata\" in message:\n",
        "            with st.expander(\"üìä Details\"):\n",
        "                col1, col2 = st.columns(2)\n",
        "                with col1:\n",
        "                    st.metric(\"Trials Found\", message[\"metadata\"][\"num_trials\"])\n",
        "                with col2:\n",
        "                    st.metric(\"Confidence\", f\"{message['metadata']['avg_confidence']:.0%}\")\n",
        "\n",
        "# Chat input\n",
        "if prompt := st.chat_input(\"Ask about clinical trials...\"):\n",
        "\n",
        "    # Check if bot is initialized\n",
        "    if st.session_state.bot is None:\n",
        "        st.error(\"‚ö†Ô∏è Please enter your API keys in the sidebar first!\")\n",
        "    else:\n",
        "        # Add user message\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "        # Get bot response\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            with st.spinner(\"üîç Searching clinical trials...\"):\n",
        "                try:\n",
        "                    result = st.session_state.bot.chat(prompt)\n",
        "\n",
        "                    response = result[\"response\"]\n",
        "\n",
        "                    # Display response\n",
        "                    st.markdown(response)\n",
        "\n",
        "                    # Show metadata\n",
        "                    with st.expander(\"üìä Details\"):\n",
        "                        col1, col2, col3 = st.columns(3)\n",
        "                        with col1:\n",
        "                            st.metric(\"Trials Found\", result[\"num_trials\"])\n",
        "                        with col2:\n",
        "                            st.metric(\"Avg Confidence\", f\"{result['avg_confidence']:.0%}\")\n",
        "                        with col3:\n",
        "                            st.metric(\"Session Hash\", result[\"session_hash\"][:8])\n",
        "\n",
        "                    # Add to messages\n",
        "                    st.session_state.messages.append({\n",
        "                        \"role\": \"assistant\",\n",
        "                        \"content\": response,\n",
        "                        \"metadata\": {\n",
        "                            \"num_trials\": result[\"num_trials\"],\n",
        "                            \"avg_confidence\": result[\"avg_confidence\"]\n",
        "                        }\n",
        "                    })\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"‚ùå Error: {str(e)}\")\n",
        "                    st.exception(e)\n",
        "\n",
        "# Sidebar examples\n",
        "with st.sidebar:\n",
        "    st.divider()\n",
        "    st.markdown(\"### üí° Example Queries\")\n",
        "\n",
        "    examples = [\n",
        "        \"What trials study insulin therapy for diabetes?\",\n",
        "        \"Show me cancer immunotherapy trials\",\n",
        "        \"Are there trials for Alzheimer's disease?\",\n",
        "        \"What trials are recruiting for asthma?\",\n",
        "        \"Find cardiovascular disease trials\"\n",
        "    ]\n",
        "\n",
        "    for example in examples:\n",
        "        if st.button(example, key=example):\n",
        "            st.session_state.messages.append({\"role\": \"user\", \"content\": example})\n",
        "            st.rerun()\n",
        "\n",
        "# Footer\n",
        "st.divider()\n",
        "st.markdown(\"\"\"\n",
        "<div style='text-align: center; color: gray; font-size: 0.9em;'>\n",
        "    üî¨ Powered by Qdrant Vector Database + Gemini 2.0 Flash<br>\n",
        "    üìä Searching 262,660+ clinical trials across 5 disease areas\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jAd8XzdZeXV",
        "outputId": "d41529d1-e335-4096-e606-404a030891b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Packages installed!\n"
          ]
        }
      ],
      "source": [
        "# Install Streamlit and pyngrok\n",
        "!pip install -q streamlit pyngrok\n",
        "\n",
        "print(\"‚úÖ Packages installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5h7FMHpyZGtT"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 cloudflared\n",
        "!chmod +x cloudflared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NMIxuy2ZGxo",
        "outputId": "fe9fd311-77d5-45a1-94c8-e9ec08a85f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90m2025-11-30T17:14:34Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-11-30T17:14:34Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m |  https://css-delhi-skilled-babies.trycloudflare.com                                        |\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 991dffd8889ee9f0147b6b48933da9e4407e68ea8c6d984f55fa2d3db4bb431d)\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 3fa2b39b-adf3-457a-8658-ee8545c08742\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-11-30T17:14:37Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.67\n",
            "2025/11/30 17:14:37 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-11-30T17:14:38Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m3c77d2ea-09a3-4e08-af83-04303df33ea8 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.67 \u001b[36mlocation=\u001b[0mhkg09 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-11-30T17:21:14Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#AI LLM\n",
        "!streamlit run app.py &>/dev/null&\n",
        "!./cloudflared tunnel --url http://localhost:8501 --no-autoupdate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTN6OuTUZG5E",
        "outputId": "1c68d6f6-6c21-4317-90c8-93133b099c77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "eKEi7YkmcMKu",
        "outputId": "0bb6a1cf-dbdd-4f70-c0b8-d68bbf531727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Downloading app.py...\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_1bb7a8dd-8ce6-47a4-ad33-180bf73b73a0\", \"app.py\", 6018)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Downloading run_bot_qdrant.py...\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f0949646-ad50-4913-958c-2faa22c4b3b7\", \"run_bot_qdrant.py\", 34620)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Downloading utils_qdrant.py...\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_db90b398-9858-4e26-b4cb-26ce6cc6a59e\", \"utils_qdrant.py\", 1896)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Downloading retrieval_agent_qdrant.py...\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_063e90a7-0e9d-4844-b79f-d7fd2abe0e6f\", \"retrieval_agent_qdrant.py\", 6578)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ All files downloaded!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Create a list of files to download\n",
        "files_to_download = [\n",
        "    'app.py',\n",
        "    'run_bot_qdrant.py',\n",
        "    'utils_qdrant.py',\n",
        "    'retrieval_agent_qdrant.py'\n",
        "]\n",
        "\n",
        "# Download each file\n",
        "for file in files_to_download:\n",
        "    if os.path.exists(f'/content/{file}'):\n",
        "        print(f\"üì• Downloading {file}...\")\n",
        "        files.download(f'/content/{file}')\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è {file} not found!\")\n",
        "\n",
        "print(\"\\n‚úÖ All files downloaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4m1qboex6ub",
        "outputId": "65437265-5680-4380-e20c-28702c70dc23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "streamlit==1.31.0\n",
        "pandas==2.1.4\n",
        "numpy==1.26.3\n",
        "sentence-transformers==2.3.1\n",
        "qdrant-client==1.7.0\n",
        "google-generativeai==0.3.2\n",
        "requests==2.31.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "e9b3g-mAylRm",
        "outputId": "30087ac8-3515-4a04-e196-a978ec5dd35e"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_c594df15-6579-4de7-a3d7-d7b88e27c69c\", \"requirements.txt\", 140)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download('/content/requirements.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcrfLYnpynPx",
        "outputId": "64c9c8ba-9577-460c-961e-fde84a94936d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting .dockerignore\n"
          ]
        }
      ],
      "source": [
        "%%writefile .dockerignore\n",
        "__pycache__/\n",
        "*.pyc\n",
        "*.pyo\n",
        "*.pyd\n",
        ".Python\n",
        "*.egg-info/\n",
        ".env\n",
        ".venv\n",
        "venv/\n",
        "*.log\n",
        ".DS_Store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iL1WqVqeyxRW",
        "outputId": "ddc72ae7-4fd2-48cf-81ec-9ba72c313df0"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_8c757237-6a3c-451a-9abf-4d969cbc9474\", \".dockerignore\", 84)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download('/content/.dockerignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI1N07ayyyyj",
        "outputId": "ed1ef257-5183-44c6-a63b-37dad914e1dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing Dockerfile\n"
          ]
        }
      ],
      "source": [
        "%%writefile Dockerfile\n",
        "# Use Python 3.11 slim image\n",
        "FROM python:3.11-slim\n",
        "\n",
        "# Set working directory\n",
        "WORKDIR /app\n",
        "\n",
        "# Install system dependencies\n",
        "RUN apt-get update && apt-get install -y \\\n",
        "    build-essential \\\n",
        "    curl \\\n",
        "    && rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "# Copy requirements first (for caching)\n",
        "COPY requirements.txt .\n",
        "\n",
        "# Install Python dependencies\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# Copy application files\n",
        "COPY . .\n",
        "\n",
        "# Expose port 8080 (Cloud Run requirement)\n",
        "EXPOSE 8080\n",
        "\n",
        "# Health check\n",
        "HEALTHCHECK CMD curl --fail http://localhost:8080/_stcore/health || exit 1\n",
        "\n",
        "# Run Streamlit\n",
        "CMD streamlit run app.py \\\n",
        "    --server.port=8080 \\\n",
        "    --server.address=0.0.0.0 \\\n",
        "    --server.headless=true \\\n",
        "    --server.enableCORS=false \\\n",
        "    --server.enableXsrfProtection=false\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "fMg-OIo6zFlC",
        "outputId": "7984423b-ae98-48cc-94b2-6b70917028a5"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_dabc8676-d006-4b27-9077-cec690524c4f\", \"Dockerfile\", 761)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download('/content/Dockerfile')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
